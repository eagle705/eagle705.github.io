<!doctype html>
<html lang="ko"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>SELF-INSTRUCT Aligning Language Model with Self Generated Instructions - Luke&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Luke&#039;s Blog"><meta name="msapplication-TileImage" content="/img/favicon.ico"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Luke&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Note code: https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;yizhongw&amp;#x2F;self-instruct slide: SELF-INSTRUCT.pdf ì—¬ê¸° ìˆëŠ” Instructionì€ NLP taskìª½ì´ë¼ê¸°ë³´ë‹¤ InstructGPTì—ì„œì˜ promptì¤‘ì— ëª…ë ¹ê´€ë ¨ í‘œí˜„ì„ ì˜ë¯¸í•˜ëŠ” ë“¯ Instructionë¿ë§Œ ì•„ë‹ˆë¼ Instanceë„ ìƒì„±í•˜ê¸° ë•Œë¬¸ì— challengeí•˜ê³ "><meta property="og:type" content="blog"><meta property="og:title" content="SELF-INSTRUCT Aligning Language Model with Self Generated Instructions"><meta property="og:url" content="https://eagle705.github.io/SELF-INSTRUCT%20Aligning%20Language%20Model%20with%20Self%20Generated%20Instructions/"><meta property="og:site_name" content="Luke&#039;s Blog"><meta property="og:description" content="Note code: https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;yizhongw&amp;#x2F;self-instruct slide: SELF-INSTRUCT.pdf ì—¬ê¸° ìˆëŠ” Instructionì€ NLP taskìª½ì´ë¼ê¸°ë³´ë‹¤ InstructGPTì—ì„œì˜ promptì¤‘ì— ëª…ë ¹ê´€ë ¨ í‘œí˜„ì„ ì˜ë¯¸í•˜ëŠ” ë“¯ Instructionë¿ë§Œ ì•„ë‹ˆë¼ Instanceë„ ìƒì„±í•˜ê¸° ë•Œë¬¸ì— challengeí•˜ê³ "><meta property="og:locale" content="ko_KR"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/217453282-8fc30591-2633-473a-b157-e08abb47596d.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/217465744-c1fcb396-cbc1-468b-86e4-d72d5d005e9d.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/217397748-39ba069e-3340-4097-b2eb-62d82ea2919b.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/217401805-22f50a46-5f53-4479-8cbf-dbbbb292e7b8.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/217404161-42aa1a13-c2f6-45e1-bb30-53636a934584.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/217404363-b1431caf-9783-4c96-9f8c-3f2aee0ff834.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/217408758-b5b4d0ac-bf4e-41cf-b0de-4a8e275ab807.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/217408964-38a48fa4-4b4d-403e-8519-1099be76a128.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/217441947-92bc2db5-e4b5-4557-8fe9-0bd371b13e07.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/217443597-167b1253-8bcc-4f26-806a-77340386a197.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/217444425-31b57ce0-218d-4eae-9ccc-4b49c13c71ad.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/217444909-40bb116f-f83e-4fb1-a7fd-cb94901cc2f1.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/217446692-81194509-260e-46be-8025-b898ba5546df.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/217448842-58240b5e-462e-4cc2-bfea-acca63e524f0.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/217449345-45bcfda6-550d-4715-bc01-7fdc2037cafa.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/218369215-fb32ffdb-aea1-4145-9372-ab2c8a5fd195.gif"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/218369298-1e5e132d-007a-4a5e-9262-88e1f00f8022.gif"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/218369186-12b83069-7e59-4149-9277-83e7d7aa1259.gif"><meta property="article:published_time" content="2023-02-13T04:18:48.000Z"><meta property="article:modified_time" content="2023-02-13T04:19:27.901Z"><meta property="article:author" content="Joosung Yoon"><meta property="article:tag" content="nlp"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://user-images.githubusercontent.com/7252598/217453282-8fc30591-2633-473a-b157-e08abb47596d.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://eagle705.github.io/SELF-INSTRUCT%20Aligning%20Language%20Model%20with%20Self%20Generated%20Instructions/"},"headline":"SELF-INSTRUCT Aligning Language Model with Self Generated Instructions","image":["https://user-images.githubusercontent.com/7252598/217453282-8fc30591-2633-473a-b157-e08abb47596d.png","https://user-images.githubusercontent.com/7252598/217465744-c1fcb396-cbc1-468b-86e4-d72d5d005e9d.png","https://user-images.githubusercontent.com/7252598/217397748-39ba069e-3340-4097-b2eb-62d82ea2919b.png","https://user-images.githubusercontent.com/7252598/217401805-22f50a46-5f53-4479-8cbf-dbbbb292e7b8.png","https://user-images.githubusercontent.com/7252598/217404161-42aa1a13-c2f6-45e1-bb30-53636a934584.png","https://user-images.githubusercontent.com/7252598/217404363-b1431caf-9783-4c96-9f8c-3f2aee0ff834.png","https://user-images.githubusercontent.com/7252598/217408758-b5b4d0ac-bf4e-41cf-b0de-4a8e275ab807.png","https://user-images.githubusercontent.com/7252598/217408964-38a48fa4-4b4d-403e-8519-1099be76a128.png","https://user-images.githubusercontent.com/7252598/217441947-92bc2db5-e4b5-4557-8fe9-0bd371b13e07.png","https://user-images.githubusercontent.com/7252598/217443597-167b1253-8bcc-4f26-806a-77340386a197.png","https://user-images.githubusercontent.com/7252598/217444425-31b57ce0-218d-4eae-9ccc-4b49c13c71ad.png","https://user-images.githubusercontent.com/7252598/217444909-40bb116f-f83e-4fb1-a7fd-cb94901cc2f1.png","https://user-images.githubusercontent.com/7252598/217446692-81194509-260e-46be-8025-b898ba5546df.png","https://user-images.githubusercontent.com/7252598/217448842-58240b5e-462e-4cc2-bfea-acca63e524f0.png","https://user-images.githubusercontent.com/7252598/217449345-45bcfda6-550d-4715-bc01-7fdc2037cafa.png","https://user-images.githubusercontent.com/7252598/218369215-fb32ffdb-aea1-4145-9372-ab2c8a5fd195.gif","https://user-images.githubusercontent.com/7252598/218369298-1e5e132d-007a-4a5e-9262-88e1f00f8022.gif","https://user-images.githubusercontent.com/7252598/218369186-12b83069-7e59-4149-9277-83e7d7aa1259.gif"],"datePublished":"2023-02-13T04:18:48.000Z","dateModified":"2023-02-13T04:19:27.901Z","author":{"@type":"Person","name":"Joosung Yoon"},"publisher":{"@type":"Organization","name":"Luke's Blog","logo":{"@type":"ImageObject","url":"https://eagle705.github.io/img/eagle705-logo.png"}},"description":"Note code: https:&#x2F;&#x2F;github.com&#x2F;yizhongw&#x2F;self-instruct slide: SELF-INSTRUCT.pdf ì—¬ê¸° ìˆëŠ” Instructionì€ NLP taskìª½ì´ë¼ê¸°ë³´ë‹¤ InstructGPTì—ì„œì˜ promptì¤‘ì— ëª…ë ¹ê´€ë ¨ í‘œí˜„ì„ ì˜ë¯¸í•˜ëŠ” ë“¯ Instructionë¿ë§Œ ì•„ë‹ˆë¼ Instanceë„ ìƒì„±í•˜ê¸° ë•Œë¬¸ì— challengeí•˜ê³ "}</script><link rel="canonical" href="https://eagle705.github.io/SELF-INSTRUCT%20Aligning%20Language%20Model%20with%20Self%20Generated%20Instructions/"><link rel="icon" href="/img/favicon.ico"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/monokai.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-110980734-1" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-110980734-1');</script><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><script data-ad-client="ca-pub-2655870716902046" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" async></script><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/eagle705-logo.png" alt="Luke&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="ì¹´íƒˆë¡œê·¸" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="ê²€ìƒ‰" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-02-13T04:18:48.000Z" title="2/13/2023, 1:18:48â€¯PM">2023-02-13</time>&nbsp;ê²Œì‹œ ë¨</span><span class="level-item"><time dateTime="2023-02-13T04:19:27.901Z" title="2/13/2023, 1:19:27â€¯PM">2023-02-13</time>&nbsp;ì—…ë°ì´íŠ¸ ë¨</span><span class="level-item"><a class="link-muted" href="/categories/paper/">paper</a></span><span class="level-item">20ë¶„ì•ˆì— ì½ê¸° (ì•½ 3026 ë‹¨ì–´)</span></div></div><h1 class="title is-3 is-size-4-mobile">SELF-INSTRUCT Aligning Language Model with Self Generated Instructions</h1><div class="content"><h1 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h1><ul>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/yizhongw/self-instruct">https://github.com/yizhongw/self-instruct</a></li>
<li>slide: <a target="_blank" rel="noopener" href="https://github.com/eagle705/presentation/files/10718545/SELF-INSTRUCT.pdf">SELF-INSTRUCT.pdf</a></li>
<li>ì—¬ê¸° ìˆëŠ” Instructionì€ NLP taskìª½ì´ë¼ê¸°ë³´ë‹¤ InstructGPTì—ì„œì˜ promptì¤‘ì— ëª…ë ¹ê´€ë ¨ í‘œí˜„ì„ ì˜ë¯¸í•˜ëŠ” ë“¯</li>
<li>Instructionë¿ë§Œ ì•„ë‹ˆë¼ Instanceë„ ìƒì„±í•˜ê¸° ë•Œë¬¸ì— challengeí•˜ê³ , LLMì— ë‚´ì¬ë˜ì–´ìˆëŠ” ëŠ¥ë ¥ì„ êº¼ë‚´ë˜ êº¼ë‚¸ ì»¨í…ì¸ ë„ LLMì•ˆì— ìˆëŠ”ê±°ë¼ì„œ, humanì˜ ê°œì…ì´ ì˜ì•ˆë“¤ì–´ê°„ self-Instruct+Instanceë¼ê³  í•  ìˆ˜ ìˆì„ë“¯<ul>
<li>Because of SELF-INSTRUCTâ€™s dependence on the inductive biases extracted from LMs</li>
</ul>
</li>
<li>InstructGPT_001 ì •ë„ì˜ ëª¨ë¸ì„ íœ´ë¨¼ë¦¬ì†ŒìŠ¤ ì ê²Œí•´ì„œ ë§Œë“œëŠ” ë°©ë²•</li>
<li><a target="_blank" rel="noopener" href="https://github.com/yizhongw/self-instruct/blob/main/data/seed_tasks.jsonl">175ê°œ ì‹œë“œ í…œí”Œë¦¿</a></li>
</ul>
<table>
<thead>
<tr>
<th>ì˜ˆì‹œ1</th>
<th>ì˜ˆì‹œ2</th>
</tr>
</thead>
<tbody><tr>
<td><img src="https://user-images.githubusercontent.com/7252598/217453282-8fc30591-2633-473a-b157-e08abb47596d.png" alt="image"></td>
<td><img src="https://user-images.githubusercontent.com/7252598/217465744-c1fcb396-cbc1-468b-86e4-d72d5d005e9d.png" alt="ë‘ë²ˆì§¸ì˜ˆì‹œ"></td>
</tr>
</tbody></table>
<h1 id="Author"><a href="#Author" class="headerlink" title="Author"></a>Author</h1><ul>
<li>Yizhong Wangâ™£ Yeganeh Kordiâ™¢ Swaroop Mishraâ™¡ Alisa Liuâ™£ Noah A. Smithâ™£+ Daniel Khashabiâ™  Hannaneh Hajishirziâ™£+ </li>
<li>â™£University of Washington â™¢Tehran Polytechnic â™¡Arizona State University â™ Johns Hopkins University +Allen Institute for AI</li>
</ul>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul>
<li>Large â€œinstruction-tunedâ€ language models (finetuned to respond to instructions) have demonstrated a remarkable ability to generalize zero-shot to new tasks.<ul>
<li>Nevertheless, they depend heavily on human-written instruction data that is limited in quantity, diversity, and creativity, therefore hindering the generality of the tuned model.</li>
</ul>
</li>
<li>We introduce SELF-INSTRUCT, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off its own generations.</li>
<li>Our pipeline <ul>
<li>generates <ul>
<li>instruction, </li>
<li>input, and </li>
<li>output samples</li>
</ul>
</li>
<li>from a language model, then prunes them before using them to finetune the original model.</li>
</ul>
</li>
<li>Applying our method to vanilla GPT3, we demonstrate a 33% absolute improvement over the original model on SUPERNATURALINSTRUCTIONS, on par with the performance of InstructGPT001</li>
<li>we curate a set of expert-written instructions for novel tasks, and show through human evaluation that tuning GPT3 with SELF-INSTRUCT outperforms using existing public instruction datasets by a large margin, leaving only a 5% absolute gap behind InstructGPT001</li>
<li>SELF-INSTRUCT provides an almost annotation-free method for aligning pretrained language models with instructions, and we <a target="_blank" rel="noopener" href="https://github.com/yizhongw/self-instruct">release our large synthetic dataset to facilitate future studies on instruction tuning</a>.</li>
</ul>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><ul>
<li>These developments are powered by two key components: large pre-trained language models (LM) and human-written instruction data. <strong>PROMPTSOURCE</strong> (Bach et al., 2022) and <strong>SUPERNATURALINSTRUCTIONS</strong> (Wang et al., 2022) are two notable recent datasets that use extensive manual annotation for collecting instructions to construct T0 and Tğ‘˜-INSTRUCT</li>
<li>However, this process is costly and often suffers limited diversity given that most human generations tend to be popular NLP tasks, <strong>falling short of covering a true variety of tasks and different ways to describe them</strong>.</li>
<li>In this work, we introduce SELF-INSTRUCT, a semi-automated process for instruction-tuning a pretrained LM using instructional signals from the model itself.</li>
<li>The overall process is an <strong>iterative bootstrapping algorithm</strong> (see Figure 1), which starts off with a limited (e.g., 175 in our study) seed set of manually-written instructions that are used to guide the overall generation.<ul>
<li>In the first phase, the model is prompted to generate instructions for new tasks<ul>
<li>This step leverages the existing collection of instructions to create more broad-coverage instructions that define (often new) tasks</li>
</ul>
</li>
<li>Given the newly-generated set of instructions, the framework also creates input-output instances for them, which can be later used for supervising the instruction tuning.</li>
<li>Finally, <strong>various measures</strong> are used to prune low-quality and repeated instructions, before adding them to the task pool.  (ì–´ë–¤ measureë¥¼ ì“°ëŠ”ê±´ì§€ ë´ì•¼ê² êµ°)<ul>
<li>This process can be repeated for many interactions until reaching a large number of tasks.<br><img src="https://user-images.githubusercontent.com/7252598/217397748-39ba069e-3340-4097-b2eb-62d82ea2919b.png" alt="image"></li>
</ul>
</li>
</ul>
</li>
<li>The iterative SELF INSTRUCT process on this model leads to about <code>52k instructions</code>, <code>paired with about 82K instance inputs and target outputs</code>.<ul>
<li>ì¸ìŠ¤í„°ëŸ­ì…˜ì´ 5ë§Œ2ì²œê°œê³ , ì‹¤ì œ ë°ì´í„°ëŠ” 8ë§Œ2ì²œê°œë¼ëŠ”ê±°ì§€?</li>
</ul>
</li>
<li>provides a diverse range of creative tasks and over 50% of them have less than 0.3 ROUGE- L overlaps with the seed instructions (Â§4.2)<ul>
<li>rouge-l ê¸°ì¤€ 0.3ë³´ë‹¤ ë‚®ì•„ì„œ ì•ˆê²¹ì¹œë‹¤ëŠ”ê±´ë°, ì´ê²Œ ì˜ë¯¸ì ìœ¼ë¡œ ë§ê¸´í•œê±°ëƒê³ </li>
</ul>
</li>
<li>The SUPERNI results indicate that GPT3SELF-INST out- performs GPT3 (the original model) by a large margin (+33.1%) and nearly matches the performance of InstructGPT001</li>
<li>Moreover, our human evaluation on the newly-created instruction set shows that GPT3SELF-INST demonstrates a broad range of instruction following ability, outperforming models trained on other publicly available instruction datasets and leaving only a 5% gap behind InstructGPT001.</li>
<li>In summary, our contributions are: <ul>
<li>(1) SELF-INSTRUCT, a method for inducing instruction following capability with minimal human-labeled data; </li>
<li>(2) We demonstrate its effectiveness via extensive instruction-tuning experiments; </li>
<li>(3) We release a large synthetic dataset of 52K instructions and a set of manually-written novel tasks for building and evaluating future instruction-following models.</li>
</ul>
</li>
</ul>
<h1 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h1><ul>
<li>Annotating large-scale instruction data can be challenging for humans because it requires <ul>
<li><ol>
<li>creativity to come up with novel tasks and</li>
</ol>
</li>
<li><ol start="2">
<li>expertise for writing the labeled instances for each task.</li>
</ol>
</li>
</ul>
</li>
</ul>
<h2 id="Defining-Instruction-Data"><a href="#Defining-Instruction-Data" class="headerlink" title="Defining Instruction Data"></a>Defining Instruction Data</h2><p><img src="https://user-images.githubusercontent.com/7252598/217401805-22f50a46-5f53-4479-8cbf-dbbbb292e7b8.png" alt="image"></p>
<h2 id="Automatic-Instruction-Data-Generation"><a href="#Automatic-Instruction-Data-Generation" class="headerlink" title="Automatic Instruction Data Generation"></a>Automatic Instruction Data Generation</h2><ul>
<li>Our pipeline for generating the instruction data consists of four steps: <ul>
<li><ol>
<li>instruction generation,</li>
</ol>
</li>
<li><ol start="2">
<li>identifying whether the instruction represents a classification task or not,  (ì™œ ë¶„ë¥˜ íƒœìŠ¤í¬ì¸ì§€ ì•„ë‹Œì§€ë¥¼ ì•Œì•„ë‚´ë ¤í• ê¹Œ?)</li>
</ol>
</li>
<li><ol start="3">
<li>instance generation with the input-first or the output-first approach, and</li>
</ol>
</li>
<li><ol start="4">
<li>filtering low-quality data.</li>
</ol>
</li>
</ul>
</li>
</ul>
<h3 id="Instruction-Generation"><a href="#Instruction-Generation" class="headerlink" title="Instruction Generation"></a>Instruction Generation</h3><ul>
<li>large pretrained language models can be prompted to generate new and novel instructions when presented with some existing instructions in the context<ul>
<li>This provides us with a way to grow the instruction data from a small set of seed human-written instructions</li>
<li>We propose to generate a diverse set of instructions in a bootstrapping fashion</li>
</ul>
</li>
<li>We initiate the task pool with <strong>175 tasks</strong> (1 instruction and 1 instance for each task) written by our authors</li>
<li>For every step, we sample 8 task instructions from this pool as in-context examples<ul>
<li>Of the 8 instructions, <strong>6 are from the human-written tasks, and 2 are from the model-generated tasks</strong> in previous steps to promote diversity.</li>
<li>The prompting template is shown in Table 6.</li>
<li>6ê°œëŠ” ì‚¬ëŒì´ ì“´ê±°ê³  2ê°œëŠ” ëª¨ë¸ì´ ìƒì„±í•œê±´ë°, ìŒ.. ì´ˆê¸°ì— ì €ë ‡ê²Œ í•œë‹¤ëŠ”ê±¸ê¹Œ</li>
</ul>
</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/7252598/217404161-42aa1a13-c2f6-45e1-bb30-53636a934584.png" alt="image"></p>
<h3 id="Classification-Task-Identification"><a href="#Classification-Task-Identification" class="headerlink" title="Classification Task Identification."></a>Classification Task Identification.</h3><ul>
<li>Because we need two different approaches for classification and non-classification tasks, we next <strong>identify whether the generated instruction represents a classification task or not.</strong><ul>
<li>We prompt vanilla GPT3 few-shot to determine this, using 12 classification instructions and 19 non-classification instructions from the seed tasks.<ul>
<li>few-shotìœ¼ë¡œ ì´ê²Œ classificationì¸ì§€ ì•„ë‹Œì§€ íŒë‹¨í•˜ê²Œí•¨, few-shotì´ ì¢‹ì•„ì•¼í•˜ë„¤, practicalí•˜ë‹¤ê³  í• ìˆ˜ ìˆì„ê¹Œ?</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Instance-Generation"><a href="#Instance-Generation" class="headerlink" title="Instance Generation."></a>Instance Generation.</h3><ul>
<li>Given the instructions and their task type, we generate instances for each instruction independently.<ul>
<li>ê°ê°ì— ëŒ€í•´ì„œ ìƒì„±í•˜ëŠ”ê±´ ì˜í•œë“¯</li>
</ul>
</li>
<li>This is challenging because it requires the model to understand what the target task is, based on the instruction, figure out what additional input fields are needed and generate them, and finally complete the task by <strong>producing the output.</strong> </li>
<li>pretrained language models can achieve this to a large extent when <code>prompted with instruction-input-output in-context examples</code> from other tasks</li>
<li>A natural way to do this is the <code>Input-first Approach</code><ul>
<li>language model to come up with the input fields first based on the instruction, and then produce the corresponding output.</li>
</ul>
</li>
<li>However, we found that this approach can <strong>generate inputs biased toward one label, especially for classification tasks</strong> (e.g., for grammar error detection, it usually generates grammatical input). Therefore, we additionally propose an <code>Output-first Approach</code> for classification tasks<ul>
<li>we first generate the possible class labels, and then condition the input generation on each class label.</li>
<li>We apply the <code>output-first approach</code> to the <code>classification tasks</code> identified in the former step, and the <code>input-first approach</code> to the <code>remaining non-classification tasks</code>.<ul>
<li>ë¶„ë¥˜ë¬¸ì œì™€ ë¹„ë¶„ë¥˜ë¬¸ì œì— ëŒ€í•´ì„œëŠ” ì ‘ê·¼ì„ ë‹¤ë¥´ê²Œí•¨</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Filtering-and-Postprocessing"><a href="#Filtering-and-Postprocessing" class="headerlink" title="Filtering and Postprocessing"></a>Filtering and Postprocessing</h3><ul>
<li>To encourage diversity, a new instruction is added to the task pool only when its <code>ROUGE-L overlap</code> with any existing instruction is <code>less than 0.7</code>.<ul>
<li>instructionì´ ë§ì€ë° ê²€ìˆ˜ë¥¼ ê½¤ í•´ì•¼ê² ë„¤ (ë£¨í”„í•œë²ˆì´ë©´ ë˜ì§€ë§Œ)</li>
</ul>
</li>
<li>We also exclude instructions that contain some specific keywords (e.g., images, pictures, graphs) that usually can not be processed by language models.<ul>
<li>ì´ë¯¸ì§€, ê·¸ë˜í”„ë“±ì˜ ë‹¨ì–´ëŠ” ë£°ë¡œ ë°°ì œ</li>
</ul>
</li>
<li>When generating new instances for each instruction, we filter out instances that are exactly the same or those with the same input but different outputs.</li>
<li>Q) ì´ìƒí•œ Instructionì´ë‘ Instanceê°€ ë¶„ëª… ìˆì„í…ë° ì™œ ì–˜ë„¨ í•„í„°ë§ ì•ˆí•˜ì§€?</li>
</ul>
<table>
<thead>
<tr>
<th>Table 7</th>
<th>Table 8</th>
<th>Table 9</th>
</tr>
</thead>
<tbody><tr>
<td><img src="https://user-images.githubusercontent.com/7252598/217404363-b1431caf-9783-4c96-9f8c-3f2aee0ff834.png" alt="image"></td>
<td><img src="https://user-images.githubusercontent.com/7252598/217408758-b5b4d0ac-bf4e-41cf-b0de-4a8e275ab807.png" alt="image"></td>
<td><img src="https://user-images.githubusercontent.com/7252598/217408964-38a48fa4-4b4d-403e-8519-1099be76a128.png" alt="image"></td>
</tr>
</tbody></table>
<h2 id="Finetuning-the-LM-to-Follow-Instructions"><a href="#Finetuning-the-LM-to-Follow-Instructions" class="headerlink" title="Finetuning the LM to Follow Instructions"></a>Finetuning the LM to Follow Instructions</h2><ul>
<li>After the creation of the large-scale instruction data, we use this data to finetune the original language model (i.e., SELF-INSTRUCT).</li>
<li>To do this, we <code>concatenate the instruction and instance input as a prompt</code> and <code>train the model to generate the instance output</code> in a standard <code>supervised</code> way.</li>
<li>To make the model <code>robust</code> to different formats, we use <code>multiple</code> templates to encode the instruction and instance input together.<ul>
<li>For example, the instruction can be prefixed with <code>â€œTask:â€ or not</code>, the input can be prefixed with <code>â€œInput:â€ or not</code>, <code>â€œOutput:â€ can be appended at the end of the prompt</code>, and different numbers of break lines can be put in the middle, etc.</li>
</ul>
</li>
</ul>
<h1 id="SELF-INSTRUCT-Data-from-GPT3"><a href="#SELF-INSTRUCT-Data-from-GPT3" class="headerlink" title="SELF-INSTRUCT Data from GPT3"></a>SELF-INSTRUCT Data from GPT3</h1><ul>
<li>we apply our method for inducing instruction data to GPT3 as a case study</li>
<li>We use the largest GPT3 language model (â€œdavinciâ€ engine) accessed through the OpenAI API<ul>
<li>ì•„.. API ì¨ì„œ í•œê±°êµ¬ë‚˜</li>
</ul>
</li>
</ul>
<h2 id="Statistics"><a href="#Statistics" class="headerlink" title="Statistics"></a>Statistics</h2><ul>
<li>We generate a total of over 52K instructions, and more than 82K instances corresponding to these instructions after filtering.<ul>
<li>ì¸ìŠ¤íŠ¸ëŸ­ì…˜ì´ 52,000ê°œì¸ë° ì¸ìŠ¤í„´ìŠ¤ëŠ” 82,000ì´ë„¤ ë” ë§ì´ ë§Œë“¤ê³ (í…ìŠ¤íŠ¸ì•¼ ëª¨ë¸ëŒë¦¬ë©´ ìƒì„±ë˜ë‹ˆ) í•„í„°ë§í–ˆë‹¤ëŠ” ê±¸ê¹Œ<br><img src="https://user-images.githubusercontent.com/7252598/217441947-92bc2db5-e4b5-4557-8fe9-0bd371b13e07.png" alt="image"></li>
</ul>
</li>
</ul>
<h2 id="Diversity"><a href="#Diversity" class="headerlink" title="Diversity"></a>Diversity</h2><ul>
<li>we identify the verb-noun structure in the generated instructions. We use the Berkeley Neural Parser6 (Kitaev and Klein, 2018; Kitaev et al., 2019) to parse the instructions, and then extract the verb that is closest to the root of the parse tree as well as its first direct noun object. 26,559 out of the 52,445 instructions contain such structure; other instructions usually contain more complex clauses (e.g., â€œClassify whether this tweet contains political content or not.â€) or are framed as questions (e.g., â€œWhich of these statements are true?â€).</li>
<li>We plot the top 20 most common root verbs and their top 4 direct noun objects in Figure 2, which accounts for 14% of the entire set. Overall, we see quite diverse intents and textual formats in these instructions.</li>
<li>For each generated instruction, we compute its highest ROUGE-L overlap with the 175 seed instructions. We plot the distribution of these ROUGE-L scores in Figure 3,<ul>
<li>ì‹œë“œì— ëŒ€í•´ì„œë§Œ ê³„ì‚°í–ˆêµ¬ë‚˜</li>
</ul>
</li>
<li>We also demonstrate diversity in length of the instructions, instance inputs, and instance outputs in Figure 4.</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/7252598/217443597-167b1253-8bcc-4f26-806a-77340386a197.png" alt="image"></p>
<h2 id="Quality"><a href="#Quality" class="headerlink" title="Quality"></a>Quality</h2><ul>
<li>To investigate this, we <code>randomly sample 200 instructions</code> and <code>randomly select 1 instance per instruction</code>. We asked an expert annotator (co-author of this work) to label whether each instance is correct or not, in terms of the instruction, the instance input, and the instance output. Evaluation results in Table 2 show that most of the generated instructions are meaningful, while the generated instances may contain more noise (to a reasonable extent).</li>
<li>However, we found that <code>even though the generations may contain errors, most of them are still in the correct format or even partially correct</code>, which can provide <code>useful guidance for training</code> models to follow instructions<ul>
<li>í‘œë¥¼ ë³´ë©´ ì•„ì›ƒí’‹ì´ ì¸ìŠ¤íŠ¸ëŸ­ì…˜ê³¼ ì¸í’‹ì— ëŒ€í•´ì„œ ì í•©í•˜ëƒ í–ˆì„ë•Œ 58%â€¦ ì´ê±° ì¨ë„ ë˜ëŠ”ê±¸ê¹Œ</li>
</ul>
</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/7252598/217444425-31b57ce0-218d-4eae-9ccc-4b49c13c71ad.png" alt="image"></p>
<p><img src="https://user-images.githubusercontent.com/7252598/217444909-40bb116f-f83e-4fb1-a7fd-cb94901cc2f1.png" alt="image"></p>
<h1 id="Experimental-Results"><a href="#Experimental-Results" class="headerlink" title="Experimental Results"></a>Experimental Results</h1><h2 id="GPT3SELF-INST-fine-tuning-GPT3-on-its-own-instruction-data"><a href="#GPT3SELF-INST-fine-tuning-GPT3-on-its-own-instruction-data" class="headerlink" title="GPT3SELF-INST: fine-tuning GPT3 on its own instruction data"></a>GPT3SELF-INST: fine-tuning GPT3 on its own instruction data</h2><ul>
<li>We use the default hyper-parameters, except that we set the prompt loss weight to 0, and we train the model for 2 epochs.</li>
<li>The resulting model is denoted as GPT3SELF-INST.</li>
</ul>
<h2 id="Baselines"><a href="#Baselines" class="headerlink" title="Baselines"></a>Baselines</h2><h3 id="Off-the-shelf-LMs"><a href="#Off-the-shelf-LMs" class="headerlink" title="Off-the-shelf LMs"></a>Off-the-shelf LMs</h3><ul>
<li>T5-LM, GPT3</li>
<li>These baselines will indicate the extent to which off-the-shelf LMs are capable of following instructions naturally immediately after pretraining.</li>
</ul>
<h3 id="Publicly-available-instruction-tuned-models"><a href="#Publicly-available-instruction-tuned-models" class="headerlink" title="Publicly-available instruction-tuned models"></a>Publicly-available instruction-tuned models</h3><ul>
<li>T0 and Tğ‘˜-INSTRUCT are two instruction-tuned models proposed in Sanh et al. (2022) and Wang et al. (2022)</li>
<li>For both of these models, we use their largest version with 11B parameters.</li>
</ul>
<h3 id="Instruction-tuned-GPT3-models"><a href="#Instruction-tuned-GPT3-models" class="headerlink" title="Instruction-tuned GPT3 models"></a>Instruction-tuned GPT3 models</h3><ul>
<li>We evaluate InstructGPT (Ouyang et al., 2022), which is developed by OpenAI based on GPT3 to follow human instructions better and has been found by the community to have impressive zero-shot abilities</li>
<li>(we only compare with their text-davinci-001 engine)</li>
</ul>
<h2 id="Experiment-1-Zero-Shot-Generalization-on-SUPERNI-benchmark"><a href="#Experiment-1-Zero-Shot-Generalization-on-SUPERNI-benchmark" class="headerlink" title="Experiment 1: Zero-Shot Generalization on SUPERNI benchmark"></a>Experiment 1: Zero-Shot Generalization on SUPERNI benchmark</h2><p><img src="https://user-images.githubusercontent.com/7252598/217446692-81194509-260e-46be-8025-b898ba5546df.png" alt="image"></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2204.07705.pdf">SUPERNI ë²¤ì¹˜ë§ˆí¬</a></li>
</ul>
<h2 id="Experiment-2-Generalization-to-User-oriented-Instructions-on-Novel-Tasks"><a href="#Experiment-2-Generalization-to-User-oriented-Instructions-on-Novel-Tasks" class="headerlink" title="Experiment 2: Generalization to User-oriented Instructions on Novel Tasks"></a>Experiment 2: Generalization to User-oriented Instructions on Novel Tasks</h2><ul>
<li><code>most of these NLP tasks were proposed for research purposes and skewed toward classification</code>. To better access the practical value of instruction-following models, a subset of the authors curate a new set of instructions motivated by user-oriented applications</li>
<li>craft instructions related to each domain(e.g., email writing, social media, productivity tools, entertainment, programming) along with an input-output instance (again, input is optional)</li>
<li>In total, we create <code>252 instructions</code> with 1 instance per instruction. We believe it can serve as a testbed for evaluating how instruction based models handle diverse and unfamiliar instructions. Table 4 presents a small portion of the 252 tasks.</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/7252598/217448842-58240b5e-462e-4cc2-bfea-acca63e524f0.png" alt="image"></p>
<h3 id="Human-evaluation-setup"><a href="#Human-evaluation-setup" class="headerlink" title="Human evaluation setup"></a>Human evaluation setup</h3><p><img src="https://user-images.githubusercontent.com/7252598/217449345-45bcfda6-550d-4715-bc01-7fdc2037cafa.png" alt="image"></p>
<h1 id="Discussion-and-Limitation"><a href="#Discussion-and-Limitation" class="headerlink" title="Discussion and Limitation"></a>Discussion and Limitation</h1><h2 id="Why-does-SELF-INSTRUCT-work"><a href="#Why-does-SELF-INSTRUCT-work" class="headerlink" title="Why does SELF-INSTRUCT work?"></a>Why does SELF-INSTRUCT work?</h2><ul>
<li>we conjecture that it is closer to <strong>ğ»2</strong>, <strong>particularly for larger models</strong></li>
<li>LMs already know much about language instructions, is a key motivation for SELF- INSTRUCT and is also supported by its empirical success.</li>
</ul>
<table>
<thead>
<tr>
<th>(H1) ì²«ë²ˆì§¸ ê°€ì„¤</th>
<th>(H2) ë‘ë²ˆì§¸ ê°€ì„¤</th>
</tr>
</thead>
<tbody><tr>
<td>Human feedback is a necessary and indispensable aspect of instruction-tuning as LMs need to learn about issues that were not quite learned during pre-training.</td>
<td>Human feedback is an optional aspect of instruction tuning as LMs are already quite familiar with instructions from their pre-training. Observing the human feedback is merely a lightweight process for aligning their pre-training distribution&#x2F;objective which might be replaceable with a different process.</td>
</tr>
</tbody></table>
<h2 id="Limitations-of-SELF-INSTRUCT"><a href="#Limitations-of-SELF-INSTRUCT" class="headerlink" title="Limitations of SELF-INSTRUCT"></a>Limitations of SELF-INSTRUCT</h2><h3 id="Tail-phenomena"><a href="#Tail-phenomena" class="headerlink" title="Tail phenomena"></a>Tail phenomena</h3><ul>
<li>LMsâ€™ largest gains correspond to the frequent uses of languages (head of the language use distribution), and there are minimal gains in the low-frequency contexts</li>
<li>Similarly, in the context of this work, it would not be surprising if the majority of the gains by SELF-INSTRUCT are skewed toward tasks or instructions that present <code>more frequently in the pre-training corpus</code></li>
</ul>
<h3 id="Dependence-on-large-models"><a href="#Dependence-on-large-models" class="headerlink" title="Dependence on large models."></a>Dependence on large models.</h3><ul>
<li>Because of SELF-INSTRUCTâ€™s dependence on the inductive biases extracted from LMs,  it might work best for larger models</li>
</ul>
<h3 id="Reinforcing-LM-biases"><a href="#Reinforcing-LM-biases" class="headerlink" title="Reinforcing LM biases."></a>Reinforcing LM biases.</h3><ul>
<li>the unintended consequences of this <code>iterative algorithm</code>, such as the amplification of problematic social biases (stereotypes or slurs about genders, races, etc.)</li>
<li>Relatedly, one observed <code>challenge</code> in this process is the algorithmâ€™s <code>difficulty in producing balanced labels</code>, which reflected modelsâ€™ prior biases</li>
</ul>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><ul>
<li>We introduce SELF-INSTRUCT, a task-agnostic method to improve the instruction-following capabilities of language models via its own generation of in<br><img src="https://user-images.githubusercontent.com/7252598/218369215-fb32ffdb-aea1-4145-9372-ab2c8a5fd195.gif" alt="self-instruct-á„ƒá…¦á„‹á…µá„á…¥á„‰á…¢á†¼á„‰á…¥á†¼á„á…¦á„‰á…³á„á…³"><br>struction data (instruction, input, and output samples) and bootstrapping with it</li>
</ul>
<h1 id="í•œê¸€ë„-ëœë‹¤"><a href="#í•œê¸€ë„-ëœë‹¤" class="headerlink" title="í•œê¸€ë„ ëœë‹¤?!"></a>í•œê¸€ë„ ëœë‹¤?!</h1><p><img src="https://user-images.githubusercontent.com/7252598/218369298-1e5e132d-007a-4a5e-9262-88e1f00f8022.gif" alt="self-instruct-á„ƒá…¦á„‹á…µá„á…¥á„‰á…¢á†¼á„‰á…¥á†¼á„á…¦á„‰á…³á„á…³"><br><img src="https://user-images.githubusercontent.com/7252598/218369186-12b83069-7e59-4149-9277-83e7d7aa1259.gif" alt="self-instruct-á„ƒá…¦á„‹á…µá„á…¥á„‰á…¢á†¼á„‰á…¥á†¼2"></p>
</div><div class="article-licensing box"><div class="licensing-title"><p>SELF-INSTRUCT Aligning Language Model with Self Generated Instructions</p><p><a href="https://eagle705.github.io/SELF-INSTRUCT Aligning Language Model with Self Generated Instructions/">https://eagle705.github.io/SELF-INSTRUCT Aligning Language Model with Self Generated Instructions/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Joosung Yoon</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2023-02-13</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2023-02-13</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/nlp/">nlp</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=63297c6228f9450019a5f574&amp;product=sop" defer></script></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/Toolformer/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Toolformer: Language Models Can Teach Themselves to Use Tools</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/(FLAN)%20Finetuned%20Language%20Models%20Are%20Zero-Shot%20Learners/"><span class="level-item">(FLAN) Finetuned Language Models Are Zero-Shot Learners</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">ëŒ“ê¸€</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://eagle705.github.io/SELF-INSTRUCT%20Aligning%20Language%20Model%20with%20Self%20Generated%20Instructions/';
            this.page.identifier = 'SELF-INSTRUCT Aligning Language Model with Self Generated Instructions/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'eagle705-github-io' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/eagle705-logo.png" alt="Joosung Yoon"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Joosung Yoon</p><p class="is-size-6 is-block">Machine Learning Engineer</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>There and Back Again</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">í¬ìŠ¤íŠ¸</p><a href="/archives"><p class="title">54</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">ì¹´í…Œê³ ë¦¬</p><a href="/categories"><p class="title">4</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">íƒœê·¸</p><a href="/tags"><p class="title">10</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/eagle705" target="_blank" rel="noopener">íŒ”ë¡œìš°</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/eagle705"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com/hisdevelopers"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/JSYoon53859120"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="LinkedIn" href="https://www.linkedin.com/in/joosung-yoon/"><i class="fab fa-linkedin"></i></a></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">ì¹´í…Œê³ ë¦¬</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cslog/"><span class="level-start"><span class="level-item">cslog</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/paper/"><span class="level-start"><span class="level-item">paper</span></span><span class="level-end"><span class="level-item tag">36</span></span></a></li><li><a class="level is-mobile" href="/categories/photo/"><span class="level-start"><span class="level-item">photo</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">ì•„ì¹´ì´ë¸Œ</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/05/"><span class="level-start"><span class="level-item">5ì›” 2023</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/03/"><span class="level-start"><span class="level-item">3ì›” 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">2ì›” 2023</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/01/"><span class="level-start"><span class="level-item">1ì›” 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">12ì›” 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/11/"><span class="level-start"><span class="level-item">11ì›” 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/10/"><span class="level-start"><span class="level-item">10ì›” 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/09/"><span class="level-start"><span class="level-item">9ì›” 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">8ì›” 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">7ì›” 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">6ì›” 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">5ì›” 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/01/"><span class="level-start"><span class="level-item">1ì›” 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/12/"><span class="level-start"><span class="level-item">12ì›” 2021</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/11/"><span class="level-start"><span class="level-item">11ì›” 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/10/"><span class="level-start"><span class="level-item">10ì›” 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/06/"><span class="level-start"><span class="level-item">6ì›” 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/05/"><span class="level-start"><span class="level-item">5ì›” 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/02/"><span class="level-start"><span class="level-item">2ì›” 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/12/"><span class="level-start"><span class="level-item">12ì›” 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/11/"><span class="level-start"><span class="level-item">11ì›” 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/10/"><span class="level-start"><span class="level-item">10ì›” 2019</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/09/"><span class="level-start"><span class="level-item">9ì›” 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/08/"><span class="level-start"><span class="level-item">8ì›” 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/07/"><span class="level-start"><span class="level-item">7ì›” 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/05/"><span class="level-start"><span class="level-item">5ì›” 2019</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/04/"><span class="level-start"><span class="level-item">4ì›” 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/11/"><span class="level-start"><span class="level-item">11ì›” 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/06/"><span class="level-start"><span class="level-item">6ì›” 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/05/"><span class="level-start"><span class="level-item">5ì›” 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/04/"><span class="level-start"><span class="level-item">4ì›” 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">íƒœê·¸</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/ML/"><span class="tag">ML</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/docker/"><span class="tag">docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/drone/"><span class="tag">drone</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/grpc/"><span class="tag">grpc</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/linux/"><span class="tag">linux</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/nlp/"><span class="tag">nlp</span><span class="tag">43</span></a></div><div class="control"><a class="tags has-addons" href="/tags/nlp-kb/"><span class="tag">nlp, kb</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/search/"><span class="tag">search</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/web/"><span class="tag">web</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%83%9D%EA%B0%81%EC%A0%95%EB%A6%AC/"><span class="tag">ìƒê°ì •ë¦¬</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="adsense"><div class="card-content"><div class="menu"><h3 class="menu-label">ê´‘ê³ </h3><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-2655870716902046" data-ad-slot="2764253071" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">ì¹´íƒˆë¡œê·¸</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Note"><span class="level-left"><span class="level-item">1</span><span class="level-item">Note</span></span></a></li><li><a class="level is-mobile" href="#Author"><span class="level-left"><span class="level-item">2</span><span class="level-item">Author</span></span></a></li><li><a class="level is-mobile" href="#Abstract"><span class="level-left"><span class="level-item">3</span><span class="level-item">Abstract</span></span></a></li><li><a class="level is-mobile" href="#Introduction"><span class="level-left"><span class="level-item">4</span><span class="level-item">Introduction</span></span></a></li><li><a class="level is-mobile" href="#Method"><span class="level-left"><span class="level-item">5</span><span class="level-item">Method</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Defining-Instruction-Data"><span class="level-left"><span class="level-item">5.1</span><span class="level-item">Defining Instruction Data</span></span></a></li><li><a class="level is-mobile" href="#Automatic-Instruction-Data-Generation"><span class="level-left"><span class="level-item">5.2</span><span class="level-item">Automatic Instruction Data Generation</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Instruction-Generation"><span class="level-left"><span class="level-item">5.2.1</span><span class="level-item">Instruction Generation</span></span></a></li><li><a class="level is-mobile" href="#Classification-Task-Identification"><span class="level-left"><span class="level-item">5.2.2</span><span class="level-item">Classification Task Identification.</span></span></a></li><li><a class="level is-mobile" href="#Instance-Generation"><span class="level-left"><span class="level-item">5.2.3</span><span class="level-item">Instance Generation.</span></span></a></li><li><a class="level is-mobile" href="#Filtering-and-Postprocessing"><span class="level-left"><span class="level-item">5.2.4</span><span class="level-item">Filtering and Postprocessing</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Finetuning-the-LM-to-Follow-Instructions"><span class="level-left"><span class="level-item">5.3</span><span class="level-item">Finetuning the LM to Follow Instructions</span></span></a></li></ul></li><li><a class="level is-mobile" href="#SELF-INSTRUCT-Data-from-GPT3"><span class="level-left"><span class="level-item">6</span><span class="level-item">SELF-INSTRUCT Data from GPT3</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Statistics"><span class="level-left"><span class="level-item">6.1</span><span class="level-item">Statistics</span></span></a></li><li><a class="level is-mobile" href="#Diversity"><span class="level-left"><span class="level-item">6.2</span><span class="level-item">Diversity</span></span></a></li><li><a class="level is-mobile" href="#Quality"><span class="level-left"><span class="level-item">6.3</span><span class="level-item">Quality</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Experimental-Results"><span class="level-left"><span class="level-item">7</span><span class="level-item">Experimental Results</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#GPT3SELF-INST-fine-tuning-GPT3-on-its-own-instruction-data"><span class="level-left"><span class="level-item">7.1</span><span class="level-item">GPT3SELF-INST: fine-tuning GPT3 on its own instruction data</span></span></a></li><li><a class="level is-mobile" href="#Baselines"><span class="level-left"><span class="level-item">7.2</span><span class="level-item">Baselines</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Off-the-shelf-LMs"><span class="level-left"><span class="level-item">7.2.1</span><span class="level-item">Off-the-shelf LMs</span></span></a></li><li><a class="level is-mobile" href="#Publicly-available-instruction-tuned-models"><span class="level-left"><span class="level-item">7.2.2</span><span class="level-item">Publicly-available instruction-tuned models</span></span></a></li><li><a class="level is-mobile" href="#Instruction-tuned-GPT3-models"><span class="level-left"><span class="level-item">7.2.3</span><span class="level-item">Instruction-tuned GPT3 models</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Experiment-1-Zero-Shot-Generalization-on-SUPERNI-benchmark"><span class="level-left"><span class="level-item">7.3</span><span class="level-item">Experiment 1: Zero-Shot Generalization on SUPERNI benchmark</span></span></a></li><li><a class="level is-mobile" href="#Experiment-2-Generalization-to-User-oriented-Instructions-on-Novel-Tasks"><span class="level-left"><span class="level-item">7.4</span><span class="level-item">Experiment 2: Generalization to User-oriented Instructions on Novel Tasks</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Human-evaluation-setup"><span class="level-left"><span class="level-item">7.4.1</span><span class="level-item">Human evaluation setup</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#Discussion-and-Limitation"><span class="level-left"><span class="level-item">8</span><span class="level-item">Discussion and Limitation</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Why-does-SELF-INSTRUCT-work"><span class="level-left"><span class="level-item">8.1</span><span class="level-item">Why does SELF-INSTRUCT work?</span></span></a></li><li><a class="level is-mobile" href="#Limitations-of-SELF-INSTRUCT"><span class="level-left"><span class="level-item">8.2</span><span class="level-item">Limitations of SELF-INSTRUCT</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Tail-phenomena"><span class="level-left"><span class="level-item">8.2.1</span><span class="level-item">Tail phenomena</span></span></a></li><li><a class="level is-mobile" href="#Dependence-on-large-models"><span class="level-left"><span class="level-item">8.2.2</span><span class="level-item">Dependence on large models.</span></span></a></li><li><a class="level is-mobile" href="#Reinforcing-LM-biases"><span class="level-left"><span class="level-item">8.2.3</span><span class="level-item">Reinforcing LM biases.</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#Conclusion"><span class="level-left"><span class="level-item">9</span><span class="level-item">Conclusion</span></span></a></li><li><a class="level is-mobile" href="#í•œê¸€ë„-ëœë‹¤"><span class="level-left"><span class="level-item">10</span><span class="level-item">í•œê¸€ë„ ëœë‹¤?!</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">ìµœê·¼ ê¸€</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-05-09T02:54:53.000Z">2023-05-09</time></p><p class="title"><a href="/pythia/">Pythia (A Suite for Analyzing Large Language Models Across Training and Scaling)</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-05-09T02:54:39.000Z">2023-05-09</time></p><p class="title"><a href="/llama/">LLaMA (Open and Efficient Foundation Language Models)</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-05-09T02:54:01.000Z">2023-05-09</time></p><p class="title"><a href="/ia3/">(IA3) Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-03-23T08:14:37.000Z">2023-03-23</time></p><p class="title"><a href="/Alpaca/">Alpaca (A Strong Instruction-Following Model)</a></p><p class="categories"><a href="/categories/paper/">paper</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-02-20T13:07:50.000Z">2023-02-20</time></p><p class="title"><a href="/SentencePiece%EB%A5%BC%20%ED%99%9C%EC%9A%A9%ED%95%9C%20%ED%9A%A8%EA%B3%BC%EC%A0%81%EC%9D%B8%20%ED%95%9C%EA%B5%AD%EC%96%B4%20%ED%86%A0%ED%81%AC%EB%82%98%EC%9D%B4%EC%A0%80%20%EB%A7%8C%EB%93%A4%EA%B8%B0/">SentencePieceë¥¼ í™œìš©í•œ íš¨ê³¼ì ì¸ í•œêµ­ì–´ í† í¬ë‚˜ì´ì € ë§Œë“¤ê¸°</a></p><p class="categories"><a href="/categories/ML/">ML</a></p></div></article></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/eagle705-logo.png" alt="Luke&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2023 Joosung Yoon</span>Â Â Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>Â &amp;Â <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("ko");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="ë§¨ ìœ„ë¡œ" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "ì´ ì›¹ ì‚¬ì´íŠ¸ëŠ” ê·€í•˜ì˜ ê²½í—˜ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ Cookieë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.",
          dismiss: "ë¬´ì‹œ",
          allow: "í—ˆìš©",
          deny: "ê±°ë¶€",
          link: "ë” ì•Œì•„ë³´ê¸°",
          policy: "Cookie ì •ì±…",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="ì…ë ¥ í•˜ì„¸ìš”..."></div><a class="searchbox-close" href="javascript:;">Ã—</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"ì…ë ¥ í•˜ì„¸ìš”...","untitled":"(ì œëª© ì—†ìŒ)","posts":"í¬ìŠ¤íŠ¸","pages":"í˜ì´ì§€","categories":"ì¹´í…Œê³ ë¦¬","tags":"íƒœê·¸"});
        });</script></body></html>