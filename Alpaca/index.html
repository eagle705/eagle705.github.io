<!doctype html>
<html lang="ko"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Alpaca (A Strong Instruction-Following Model) - Luke&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Luke&#039;s Blog"><meta name="msapplication-TileImage" content="/img/favicon.ico"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Luke&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Alpaca: A Strong, Replicable Instruction-Following Model Hello, Alpaca?최근 LLaMa이어서 아주 핫한 모델이 있습니다. 바로 Alpaca라는 모델인데요. 오늘은 Stanford에서 공개한 오픈소스인 Alpaca에 대해서 간단히 소개해보려합니다.Alpaca는 지난번에 포스팅된 LLaMa라는 언어모델을"><meta property="og:type" content="blog"><meta property="og:title" content="Alpaca (A Strong Instruction-Following Model)"><meta property="og:url" content="https://eagle705.github.io/Alpaca/"><meta property="og:site_name" content="Luke&#039;s Blog"><meta property="og:description" content="Alpaca: A Strong, Replicable Instruction-Following Model Hello, Alpaca?최근 LLaMa이어서 아주 핫한 모델이 있습니다. 바로 Alpaca라는 모델인데요. 오늘은 Stanford에서 공개한 오픈소스인 Alpaca에 대해서 간단히 소개해보려합니다.Alpaca는 지난번에 포스팅된 LLaMa라는 언어모델을"><meta property="og:locale" content="ko_KR"><meta property="og:image" content="https://devocean.sk.com/editorImg/2023/3/23/e61a09ac00cbff86421a28127c228355177ca171f85f2757aee6d21df3c5fdbd"><meta property="og:image" content="https://devocean.sk.com/editorImg/2023/3/23/c0b4da8b95c774dfc242df286f8ddde97cb4aef73ed9ade7233f3d6d1d3fe741"><meta property="og:image" content="https://devocean.sk.com/editorImg/2023/3/23/2f380fba30c06711bbaa1d341af34934f844f302e5a77bd94d7c17d04b12f440"><meta property="og:image" content="https://devocean.sk.com/editorImg/2023/3/23/1ea18693744d12a835878563919dca568be6bc15017abc8541cf1e969aca5e0d"><meta property="og:image" content="https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/main/assets/logo.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/225480312-53eba354-52c7-41ae-9c64-aea79b6cbd0e.png"><meta property="og:image" content="https://crfm.stanford.edu/static/img/posts/2023-03-13-alpaca/alpaca_main.jpg"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/225484685-43db7d87-2c39-4e3c-b978-f7bdc7d75782.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/225485522-f6c9a03e-2eac-4473-ba66-9d61b22217ff.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/225496927-2df4614a-8e35-4032-b65a-54e898ca61e6.gif"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/225496953-69f90efb-a20e-4147-bf4a-df623fc33e83.gif"><meta property="article:published_time" content="2023-03-23T08:14:37.000Z"><meta property="article:modified_time" content="2023-03-23T08:16:49.012Z"><meta property="article:author" content="Joosung Yoon"><meta property="article:tag" content="nlp"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://devocean.sk.com/editorImg/2023/3/23/e61a09ac00cbff86421a28127c228355177ca171f85f2757aee6d21df3c5fdbd"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://eagle705.github.io/Alpaca/"},"headline":"Alpaca (A Strong Instruction-Following Model)","image":["https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/main/assets/logo.png","https://user-images.githubusercontent.com/7252598/225480312-53eba354-52c7-41ae-9c64-aea79b6cbd0e.png","https://crfm.stanford.edu/static/img/posts/2023-03-13-alpaca/alpaca_main.jpg","https://user-images.githubusercontent.com/7252598/225484685-43db7d87-2c39-4e3c-b978-f7bdc7d75782.png","https://user-images.githubusercontent.com/7252598/225485522-f6c9a03e-2eac-4473-ba66-9d61b22217ff.png","https://user-images.githubusercontent.com/7252598/225496927-2df4614a-8e35-4032-b65a-54e898ca61e6.gif","https://user-images.githubusercontent.com/7252598/225496953-69f90efb-a20e-4147-bf4a-df623fc33e83.gif"],"datePublished":"2023-03-23T08:14:37.000Z","dateModified":"2023-03-23T08:16:49.012Z","author":{"@type":"Person","name":"Joosung Yoon"},"publisher":{"@type":"Organization","name":"Luke's Blog","logo":{"@type":"ImageObject","url":"https://eagle705.github.io/img/eagle705-logo.png"}},"description":"Alpaca: A Strong, Replicable Instruction-Following Model Hello, Alpaca?최근 LLaMa이어서 아주 핫한 모델이 있습니다. 바로 Alpaca라는 모델인데요. 오늘은 Stanford에서 공개한 오픈소스인 Alpaca에 대해서 간단히 소개해보려합니다.Alpaca는 지난번에 포스팅된 LLaMa라는 언어모델을"}</script><link rel="canonical" href="https://eagle705.github.io/Alpaca/"><link rel="icon" href="/img/favicon.ico"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/monokai.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-110980734-1" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-110980734-1');</script><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><script data-ad-client="ca-pub-2655870716902046" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" async></script><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/eagle705-logo.png" alt="Luke&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="카탈로그" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="검색" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-03-23T08:14:37.000Z" title="3/23/2023, 5:14:37 PM">2023-03-23</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2023-03-23T08:16:49.012Z" title="3/23/2023, 5:16:49 PM">2023-03-23</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/paper/">paper</a></span><span class="level-item">27분안에 읽기 (약 4078 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile">Alpaca (A Strong Instruction-Following Model)</h1><div class="content"><p><a target="_blank" rel="noopener" href="https://crfm.stanford.edu/2023/03/13/alpaca.html">Alpaca: A Strong, Replicable Instruction-Following Model</a></p>
<h2 id="Hello-Alpaca"><a href="#Hello-Alpaca" class="headerlink" title="Hello, Alpaca?"></a>Hello, Alpaca?</h2><p>최근 LLaMa이어서 아주 핫한 모델이 있습니다. 바로 Alpaca라는 모델인데요. 오늘은 Stanford에서 공개한 오픈소스인 Alpaca에 대해서 간단히 소개해보려합니다.<br>Alpaca는 지난번에 포스팅된 LLaMa라는 언어모델을 <a target="_blank" rel="noopener" href="https://devocean.sk.com/blog/techBoardDetail.do?ID=164601">Stanford 박사과정 학생들</a>이 사용자의 명령어에 언어모델이 잘 답변할 수 있도록 Instruction-following 데이터로 파인튜닝한 모델입니다.<br>언어모델은 기본적으로 다음 단어를 예측하는 문제를 풀기 때문에 일반적인 사용자의 명령어에 자연스럽게 답변하기가 어려운데요. 그럼에도 불구하고 ChatGPT 같은 모델이 답변을 잘하는 것은 사용자의 의도에 맞게 모델을 Instruction-following 데이터로 튜닝 (Alignment) 했기 때문이라고도 볼 수 있습니다. 결국 사용자가 언어모델을 잘 활용하기 위해서는 Instruction tuning은 꼭 거쳐야하는 관문이라고 할 수 있습니다.<br>LLaMa를 튜닝한 모델이니 아마 라마와 비슷한 생김새 가진 알파카라고 이름을 지은게 아닌가 싶네요🤔</p>
<p><img src="https://devocean.sk.com/editorImg/2023/3/23/e61a09ac00cbff86421a28127c228355177ca171f85f2757aee6d21df3c5fdbd" alt="image.png"></p>
<p>Alpaca는 논문이 따로 발표되진 않았지만, 어떤 데이터로 어떻게 학습을 했는지 코드와 함께 공개가 되어있어서 현재시점에서도 LLaMa와 같이 많은 변형 및 어플리케이션이 나오고 있는데요. 지금부터 한번 알아보도록 하겠습니다.</p>
<h2 id="Alpaca를-왜-만들었을까"><a href="#Alpaca를-왜-만들었을까" class="headerlink" title="Alpaca를 왜 만들었을까?"></a>Alpaca를 왜 만들었을까?</h2><p>Stanford 학생들은 ChatGPT, Claude, Bing Chat등 다양한 모델이 이미 훌륭한 성능을 보여주고 있지만 그럼에도 불구하고 아직은 부족한 점이 있다고 지적합니다. 예를 들면, 잘못된 정보를 생성하거나, 사회적인 편견 및 불편한 말들을 생성하는 것이죠. 이러한 문제를 해결하기 위해 학계와의 협업이 필요하지만 OpenAI의 <code>text-davinci-003</code>과 같은 모델은 접근하기 힘든 closed-source model이기 때문에 연구에 어려움이 있다고 말합니다🥲<br>마침 Meta에서 LLaMa를 공개했고, 기존에 알려진 연구를 바탕으로 훨씬 저렴한 비용으로 모델을 학습할 수 있도록, 데이터 및 모델 학습 방법을 재현 가능하도록 공개한 것으로 보입니다.<br>결과적으로, Alpaca는 text-davinci-003(175B)보다 훨씬 작은 7B 모델이지만 유사하게 동작한다고 합니다.<br><a target="_blank" rel="noopener" href="https://alpaca-ai.ngrok.io/">Gradio 기반 데모 페이지</a>도 공개했는데, 접속은 가끔 안되는 것 같네요🤔<br><img src="https://devocean.sk.com/editorImg/2023/3/23/c0b4da8b95c774dfc242df286f8ddde97cb4aef73ed9ade7233f3d6d1d3fe741" alt="image.png"><br>Alpaca는 academic research에 한해서만 사용이 가능하고 상업적 사용은 금지하고 있는데요.<br>이유는 LLaMa의 라이센스가 <a target="_blank" rel="noopener" href="https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform">non-commercial 라이센스</a>라는점 그리고 <a target="_blank" rel="noopener" href="https://openai.com/policies/terms-of-use">OpenAI의 tet-davinci-003에서 얻어낸 데이터를 활용했다는 점</a>등을 이유로 제시하고 있습니다.</p>
<h2 id="학습-방법"><a href="#학습-방법" class="headerlink" title="학습 방법"></a>학습 방법</h2><p>Alpaca는 기본적으로 7B 크기의 LLaMa를 Backbone으로 두고 Instruction tuning을 한 모델입니다.<br>모델은 이미 공개되어있기 때문에 가장 중요한 것은 데이터인데요. 기존에 Instruction-following 데이터를 생성하기 위한 많은 연구가 있었고 작년 12월인 최근에 공개된 <a target="_blank" rel="noopener" href="https://github.com/yizhongw/self-instruct">self-Instruct</a>라는 연구를 참고해서 데이터를 생성했습니다.<br>self-Instruct의 핵심은 LLM(Large Language Model)로 데이터를 생성해서 그 데이터로 다시 LLM을 학습한다는 것인데요, 한 마디로 튜닝을 위한 데이터도 모델이 생성하는 자가수급 시스템(?)이라고 볼 수 있습니다.<br>Alpaca에서는 self-Instruct의 방법론을 조금 단순화하되 모델은 더 좋은 모델(<a target="_blank" rel="noopener" href="https://platform.openai.com/docs/model-index-for-researchers/models-referred-to-as-gpt-3-5">GPT-3(davinci) -&gt; GPT-3.5(text-davinci-003)</a>)을 사용해서 데이터를 생성했습니다.</p>
<h6 id="데이터-생성-예시"><a href="#데이터-생성-예시" class="headerlink" title="데이터 생성 예시"></a>데이터 생성 예시</h6><p>Alpaca에서 공개한 방법대로 데이터가 생성되는지 <a target="_blank" rel="noopener" href="https://platform.openai.com/playground">OpenAI playground</a>에서 테스트를 해보았습니다.<br>아래 보이는 예시와 같이 데이터 생성이 잘 되는 것을 확인 할 수 있습니다.<br><img src="https://devocean.sk.com/editorImg/2023/3/23/2f380fba30c06711bbaa1d341af34934f844f302e5a77bd94d7c17d04b12f440" alt="스크린샷 2023-03-23 오후 3.53.58.png"><br>위와 같은 과정을 반복하면서 사람이 직접 만든 175개의 seed 데이터셋을 기반으로 데이터를 약 52,000개까지 추가 생산을 하고, 이 데이터를 학습셋으로 활용했습니다.<br><img src="https://devocean.sk.com/editorImg/2023/3/23/1ea18693744d12a835878563919dca568be6bc15017abc8541cf1e969aca5e0d" alt="image.png"><br>데이터의 품질이 매우 뛰어나다고 할 수는 없겠지만 모델을 Alignment하기에는 어느정도 충분한 데이터를 생성한 것으로 보입니다. (52,000건의 데이터를 생성하는데는 $500 정도의 비용이 들었다고 합니다)<br>self-Instruct로 생성한 데이터로 A100(80GB) 8대로 Supervised Fintuning(SFT)하면 3 epoch에 3시간정도 소요되며, 일반적인 명령어에도 잘 답변할 수 있는 모델이 탄생하게 됩니다. (이때 발생한 비용은 $100 이하로 들었다고 합니다)</p>
<h2 id="마치며"><a href="#마치며" class="headerlink" title="마치며"></a>마치며</h2><p>Stable Diffusion과 같이 LLaMa도 공개가 되면서 다양한 후속 모델들이 빠르게 나오고 있습니다.<br>벌써 8-bit 양자화와 LoRA(Low-Rank Adaption)등을 활용해서 대형언어모델을 개인 PC에서도 쉽게 사용할 수 있게 하는 프로젝트들이 개발되고 있고, 이미 한국어로 튜닝된 <a target="_blank" rel="noopener" href="https://github.com/Beomi/KoAlpaca">7B KoAlpaca 모델</a>, <a target="_blank" rel="noopener" href="https://huggingface.co/beomi/KoAlpaca-65B-LoRA?fbclid=IwAR3Damgr8gvwhqaSwwoOP-iHC5TepVhf9Gz2rlvpehOcAaplvGHjiH_RrBk">65B 모델</a>도 등장했습니다.<br>앞으로는 이전보다 더 저렴한 비용으로 더 괜찮은 성능의 모델들을 점점 더 많이 사용할 수 있게 될까요?<br>개선할 부분은 많겠지만 오픈소스 생태계에서 Alpaca의 등장은 그러한 미래에 분명 도움이 될 것으로 보입니다.<br>먼 미래가 아니라 지금이라도 조금은 더 똑똑하고 재미있는 자신만의 언어모델을 만들고 싶다면 지금 <code>Alpaca</code>를 사용해보시는건 어떨까요?🙂</p>
<h2 id="참고자료"><a href="#참고자료" class="headerlink" title="참고자료"></a>참고자료</h2><ul>
<li><a target="_blank" rel="noopener" href="https://crfm.stanford.edu/2023/03/13/alpaca.html">Alpaca: A Strong, Replicable Instruction-Following Model</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/tatsu-lab/stanford_alpaca#authors">Alpaca github</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/Beomi/KoAlpaca">KoAlpaca</a></li>
</ul>
<hr>
<h1 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h1><ul>
<li>발표자료:<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/eagle705/presentation/files/11047272/Alpaca_js.pdf">Alpaca_js.pdf</a></li>
</ul>
</li>
</ul>
<h1 id="Author"><a href="#Author" class="headerlink" title="Author"></a>Author</h1><ul>
<li><a target="_blank" rel="noopener" href="https://www.rohantaori.com/">Rohan Taori*</a> and <a target="_blank" rel="noopener" href="https://ishaan.io/">Ishaan Gulrajani*</a> and <a target="_blank" rel="noopener" href="https://tiiiger.github.io/">Tianyi Zhang*</a> and <a target="_blank" rel="noopener" href="https://yanndubs.github.io/">Yann Dubois*</a> and <a target="_blank" rel="noopener" href="https://www.lxuechen.com/">Xuechen Li*</a> and <a target="_blank" rel="noopener" href="https://guestrin.su.domains/">Carlos Guestrin</a> and <a target="_blank" rel="noopener" href="https://cs.stanford.edu/~pliang/">Percy Liang</a> and <a target="_blank" rel="noopener" href="https://thashim.github.io/">Tatsunori B. Hashimoto</a><ul>
<li>Stanford</li>
</ul>
</li>
</ul>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><ul>
<li>Meta에서 공개한 LLaMA와 Self-Instruct 조합으로 꽤 괜찮은 instruction tuning model Alpaca 개발</li>
<li>600$ 이하로 만듬<ul>
<li>52K Instruction -&gt; $500</li>
<li>3 hours 8 80GB A100s -&gt; $100</li>
</ul>
</li>
<li>HF로 FSDP 사용</li>
<li>safety나 기타 이슈는 존재하지만 공개</li>
</ul>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p><img src="https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/main/assets/logo.png" alt="alpaca"></p>
<ul>
<li>We introduce <a target="_blank" rel="noopener" href="https://crfm.stanford.edu/alpaca/">Alpaca 7B</a>, a model fine-tuned from the LLaMA 7B model on 52K instruction-following demonstrations.</li>
<li>preliminary evaluation of single-turn instruction following, Alpaca behaves qualitatively similarly to OpenAI’s text-davinci-003, <ul>
<li>surprisingly small and easy&#x2F;cheap to reproduce (&lt;600$).</li>
</ul>
</li>
</ul>
<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><ul>
<li>GPT-3.5, ChatGPT, Claude, Bing Chat등 다양한 Instruction-following 모델들이 나옴</li>
<li>해결해야될 문제들 많지만 academia는 연구가 쉽지 않다!  ex) <code>closed-source models such as OpenAI’s text-davinci-003.</code></li>
<li>LLaMA 7B짜리로 잘 튜닝해서 Alpaca라는거 만들었음<ul>
<li>52K instruction-following demonstrations generated in the style of <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2212.10560">self-instruct</a> using text-davinci-003.</li>
<li>text-davinci-003이랑 비슷</li>
<li><a target="_blank" rel="noopener" href="https://alpaca-ai-custom6.ngrok.io/">Interaction demo</a>도 공개<ul>
<li><img src="https://user-images.githubusercontent.com/7252598/225480312-53eba354-52c7-41ae-9c64-aea79b6cbd0e.png" alt="image"></li>
</ul>
</li>
</ul>
</li>
<li>Alpaca는 academic research에 한정해서 사용가능, commercial use는 금지됨<ul>
<li>First, Alpaca is based on LLaMA, which has a non-commercial <a target="_blank" rel="noopener" href="https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform">license</a></li>
<li>Second, the instruction data is based on OpenAI’s text-davinci-003, whose <a target="_blank" rel="noopener" href="https://openai.com/policies/terms-of-use">terms of use</a> prohibit developing models that compete with OpenAI.</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th>OpenAI terms of use</th>
<th>closedAI</th>
</tr>
</thead>
<tbody><tr>
<td><img width=700 src=https://user-images.githubusercontent.com/7252598/225480532-570ca8ed-a9b4-4c23-8579-8824b0dfec07.png /></td>
<td><img width=500 src=https://user-images.githubusercontent.com/7252598/225481037-96ba418b-aaee-4204-87a4-534364fe0319.jpg /></td>
</tr>
</tbody></table>
<h1 id="Training-recipe"><a href="#Training-recipe" class="headerlink" title="Training recipe"></a>Training recipe</h1><h2 id="Data-Generation-Process-self-Instruct를-단순화-해서-사용"><a href="#Data-Generation-Process-self-Instruct를-단순화-해서-사용" class="headerlink" title="Data Generation Process (self-Instruct를 단순화 해서 사용)"></a>Data Generation Process (self-Instruct를 단순화 해서 사용)</h2><ul>
<li>We built on the data generation pipeline from <a target="_blank" rel="noopener" href="https://github.com/yizhongw/self-instruct">self-instruct</a> and made the following modifications:<ul>
<li>We used text-davinci-003 to generate the instruction data instead of davinci.</li>
<li>We <code>wrote a new prompt (prompt.txt)</code> that explicitly gave the requirement of instruction generation to text-davinci-003. Note: there is a slight error in the prompt we used, and future users should incorporate the edit in <a target="_blank" rel="noopener" href="https://github.com/tatsu-lab/stanford_alpaca/pull/24">24 issue</a><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/tatsu-lab/stanford_alpaca/blob/main/prompt.txt">프롬프트를 생성할때 requirements를 줌</a></li>
</ul>
</li>
<li>We adopted much more aggressive batch decoding, i.e., generating 20 instructions at once, which significantly reduced the cost of data generation.</li>
<li>We simplified the data generation pipeline by discarding the difference between classification and non-classification instructions.<ul>
<li>분류냐 아니냐 구분하는거 삭제함</li>
</ul>
</li>
<li>We only generated a single instance for each instruction, instead of 2 to 3 instances as in LLaMA.</li>
</ul>
</li>
<li>52K unique instruction 생성에 $500정도 사용됨<br><img src="https://crfm.stanford.edu/static/img/posts/2023-03-13-alpaca/alpaca_main.jpg" alt="training"></li>
<li>we then fine-tuned the LLaMA models using Hugging Face’s training framework, taking advantage of techniques like <code>Fully Sharded Data Parallel(FSDP)</code> and <code>mixed precision training</code>.</li>
<li>For our initial run, fine-tuning a 7B LLaMA model took <code>3 hours on 8 80GB A100s</code>, which costs <code>less than $100</code> on most cloud compute providers</li>
<li>python 3.10 사용<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">torchrun --nproc_per_node=<span class="number">4</span> --master_port=&lt;your_random_port&gt; train.py \</span><br><span class="line">    --model_name_or_path &lt;your_path_to_hf_converted_llama_ckpt_and_tokenizer&gt; \</span><br><span class="line">    --data_path ./alpaca_data.json \</span><br><span class="line">    --bf16 <span class="literal">True</span> \</span><br><span class="line">    --output_dir &lt;your_output_dir&gt; \</span><br><span class="line">    --num_train_epochs <span class="number">3</span> \</span><br><span class="line">    --per_device_train_batch_size <span class="number">4</span> \</span><br><span class="line">    --per_device_eval_batch_size <span class="number">4</span> \</span><br><span class="line">    --gradient_accumulation_steps <span class="number">8</span> \</span><br><span class="line">    --evaluation_strategy <span class="string">&quot;no&quot;</span> \</span><br><span class="line">    --save_strategy <span class="string">&quot;steps&quot;</span> \</span><br><span class="line">    --save_steps <span class="number">2000</span> \</span><br><span class="line">    --save_total_limit <span class="number">1</span> \</span><br><span class="line">    --learning_rate <span class="number">2e-5</span> \</span><br><span class="line">    --weight_decay <span class="number">0.</span> \</span><br><span class="line">    --warmup_ratio <span class="number">0.03</span> \</span><br><span class="line">    --lr_scheduler_type <span class="string">&quot;cosine&quot;</span> \</span><br><span class="line">    --logging_steps <span class="number">1</span> \</span><br><span class="line">    --fsdp <span class="string">&quot;full_shard auto_wrap&quot;</span> \</span><br><span class="line">    --fsdp_transformer_layer_cls_to_wrap <span class="string">&#x27;LLaMADecoderLayer&#x27;</span> \</span><br><span class="line">    --tf32 <span class="literal">True</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="Preliminary-evaluation"><a href="#Preliminary-evaluation" class="headerlink" title="Preliminary evaluation"></a>Preliminary evaluation</h1><ul>
<li>conduct human evaluation (by the 5 student authors) on the inputs from the <a target="_blank" rel="noopener" href="https://github.com/yizhongw/self-instruct/blob/main/human_eval/user_oriented_instructions.jsonl">self-instruct evaluation set</a>.<ul>
<li>self-instruct에서 human 평가를 위한 251개의 데이터셋이 있었음 (diverse list of user-oriented instructions including email writing, social media, and productivity tools.)</li>
</ul>
</li>
<li>블라인드 테스트로 평가함, 결과는 비슷함 (90:89 &#x3D; alpaca:davinci-003)<ul>
<li>blind pairwise comparison between text-davinci-003 and Alpaca 7B</li>
<li>Alpaca wins 90 versus 89 comparisons against text-davinci-003.</li>
</ul>
</li>
<li>생성된 길이가 ChatGPT보다 짧은건, text-davinci-003이 짧게 생성해주기 때문이다로 주장<br><img src="https://user-images.githubusercontent.com/7252598/225484685-43db7d87-2c39-4e3c-b978-f7bdc7d75782.png" alt="image"></li>
</ul>
<h1 id="Known-limitations"><a href="#Known-limitations" class="headerlink" title="Known limitations"></a>Known limitations</h1><ul>
<li>hallucination, toxicity, and stereotypes. Hallucination</li>
</ul>
<h1 id="Assets-released"><a href="#Assets-released" class="headerlink" title="Assets released"></a>Assets released</h1><ul>
<li>Demo: An <a target="_blank" rel="noopener" href="https://crfm.stanford.edu/alpaca/">interactive demo</a> for everyone to try out Alpaca.</li>
<li>Data: <a target="_blank" rel="noopener" href="https://github.com/tatsu-lab/stanford_alpaca#data-release">52K demonstrations</a> used to fine-tune Alpaca.</li>
<li>Data generation process: the code for <a target="_blank" rel="noopener" href="https://github.com/tatsu-lab/stanford_alpaca#data-generation-process">generating the data</a>.</li>
<li>Hyperparameters: for <a target="_blank" rel="noopener" href="https://github.com/tatsu-lab/stanford_alpaca#fine-tuning">fine-tuning</a> the model using the Hugging Face API.</li>
</ul>
<h2 id="공개된-Data-예시"><a href="#공개된-Data-예시" class="headerlink" title="공개된 Data 예시"></a>공개된 Data 예시</h2><p><img src="https://user-images.githubusercontent.com/7252598/225485522-f6c9a03e-2eac-4473-ba66-9d61b22217ff.png" alt="image"></p>
<ul>
<li>곧 공개 예정<ul>
<li>Model weights: We have reached out to Meta to obtain guidance on releasing the Alpaca model weights, both for the 7B Alpaca and for fine-tuned versions of the larger LLaMA models.</li>
<li>Training code: our code uses the <a target="_blank" rel="noopener" href="https://github.com/huggingface/transformers/pull/21955">Hugging Face interface to LLaMA</a>. As of now, the effort to support LLaMA is still ongoing and not stable. We will give the exact training commands once Hugging Face supports LLaMA officially.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/tatsu-lab/stanford_alpaca/blob/61a3b4324505d284200a35dcbf1cc5e438ff2b46/train.py#L133">아래에서 IGNORE_INDEX 부분이 중요!</a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params"></span></span><br><span class="line"><span class="params">    sources: <span class="type">Sequence</span>[<span class="built_in">str</span>],</span></span><br><span class="line"><span class="params">    targets: <span class="type">Sequence</span>[<span class="built_in">str</span>],</span></span><br><span class="line"><span class="params">    tokenizer: transformers.PreTrainedTokenizer,</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">Dict</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Preprocess the data by tokenizing.&quot;&quot;&quot;</span></span><br><span class="line">    examples = [s + t <span class="keyword">for</span> s, t <span class="keyword">in</span> <span class="built_in">zip</span>(sources, targets)]</span><br><span class="line">    examples_tokenized, sources_tokenized = [_tokenize_fn(strings, tokenizer) <span class="keyword">for</span> strings <span class="keyword">in</span> (examples, sources)]</span><br><span class="line">    input_ids = examples_tokenized[<span class="string">&quot;input_ids&quot;</span>]</span><br><span class="line">    labels = copy.deepcopy(input_ids)</span><br><span class="line">    <span class="keyword">for</span> label, source_len <span class="keyword">in</span> <span class="built_in">zip</span>(labels, sources_tokenized[<span class="string">&quot;input_ids_lens&quot;</span>]):</span><br><span class="line">        label[:source_len] = IGNORE_INDEX</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">dict</span>(input_ids=input_ids, labels=labels)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h1 id="Future-directions"><a href="#Future-directions" class="headerlink" title="Future directions"></a>Future directions</h1><ul>
<li>Evaluation: We need to evaluate Alpaca more rigorously. We will start with <a target="_blank" rel="noopener" href="https://crfm.stanford.edu/helm/latest/">HELM</a> (Holistic Evaluation of Language Models)</li>
<li>Safety: We would like to further study the risks of Alpaca and improve its safety using methods such as automatic red teaming, auditing, and adaptive testing.</li>
<li>Understanding: We hope to better understand how capabilities arise from the training recipe. What properties of a base model do you need? What happens when you scale up? What properties of instruction data is needed? What are alternatives to using self-instruct on text-davinci-003?</li>
</ul>
<h1 id="Acknowledgements"><a href="#Acknowledgements" class="headerlink" title="Acknowledgements"></a>Acknowledgements</h1><ul>
<li>We would also like to highlight that there are many other open efforts for instruction-following LLMs and chat models, including <a target="_blank" rel="noopener" href="https://www.together.xyz/blog/openchatkit">OpenChatKit</a>, <a target="_blank" rel="noopener" href="https://open-assistant.io/">Open Assistant</a>, and <a target="_blank" rel="noopener" href="https://carper.ai/instruct-gpt-announcement/">Carper AI</a>.</li>
</ul>
<h2 id="prompt"><a href="#prompt" class="headerlink" title="prompt"></a>prompt</h2><ul>
<li>requirement 템플릿에다가 seed_task 입력해놓음 default는 3개!<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">encode_prompt</span>(<span class="params">prompt_instructions</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Encode multiple prompt instructions into a single string.&quot;&quot;&quot;</span></span><br><span class="line">    prompt = <span class="built_in">open</span>(<span class="string">&quot;./prompt.txt&quot;</span>).read() + <span class="string">&quot;\n&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> idx, task_dict <span class="keyword">in</span> <span class="built_in">enumerate</span>(prompt_instructions):</span><br><span class="line">        (instruction, <span class="built_in">input</span>, output) = task_dict[<span class="string">&quot;instruction&quot;</span>], task_dict[<span class="string">&quot;input&quot;</span>], task_dict[<span class="string">&quot;output&quot;</span>]</span><br><span class="line">        instruction = re.sub(<span class="string">r&quot;\s+&quot;</span>, <span class="string">&quot; &quot;</span>, instruction).strip().rstrip(<span class="string">&quot;:&quot;</span>)</span><br><span class="line">        <span class="built_in">input</span> = <span class="string">&quot;&lt;noinput&gt;&quot;</span> <span class="keyword">if</span> <span class="built_in">input</span>.lower() == <span class="string">&quot;&quot;</span> <span class="keyword">else</span> <span class="built_in">input</span></span><br><span class="line">        prompt += <span class="string">f&quot;###\n&quot;</span></span><br><span class="line">        prompt += <span class="string">f&quot;<span class="subst">&#123;idx + <span class="number">1</span>&#125;</span>. Instruction: <span class="subst">&#123;instruction&#125;</span>\n&quot;</span></span><br><span class="line">        prompt += <span class="string">f&quot;<span class="subst">&#123;idx + <span class="number">1</span>&#125;</span>. Input:\n<span class="subst">&#123;<span class="built_in">input</span>&#125;</span>\n&quot;</span></span><br><span class="line">        prompt += <span class="string">f&quot;<span class="subst">&#123;idx + <span class="number">1</span>&#125;</span>. Output:\n<span class="subst">&#123;output&#125;</span>\n&quot;</span></span><br><span class="line">    prompt += <span class="string">f&quot;###\n&quot;</span></span><br><span class="line">    prompt += <span class="string">f&quot;<span class="subst">&#123;idx + <span class="number">2</span>&#125;</span>. Instruction:&quot;</span></span><br><span class="line">    <span class="keyword">return</span> prompt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_instruction_following_data</span>(<span class="params"></span></span><br><span class="line"><span class="params">    output_dir=<span class="string">&quot;./&quot;</span>,</span></span><br><span class="line"><span class="params">    seed_tasks_path=<span class="string">&quot;./seed_tasks.jsonl&quot;</span>,</span></span><br><span class="line"><span class="params">    num_instructions_to_generate=<span class="number">100</span>,</span></span><br><span class="line"><span class="params">    model_name=<span class="string">&quot;text-davinci-003&quot;</span>,</span></span><br><span class="line"><span class="params">    num_prompt_instructions=<span class="number">3</span>,</span></span><br><span class="line"><span class="params">    request_batch_size=<span class="number">5</span>,</span></span><br><span class="line"><span class="params">    temperature=<span class="number">1.0</span>,</span></span><br><span class="line"><span class="params">    top_p=<span class="number">1.0</span>,</span></span><br><span class="line"><span class="params">    num_cpus=<span class="number">16</span>,</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    seed_tasks = [json.loads(l) <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">open</span>(seed_tasks_path, <span class="string">&quot;r&quot;</span>)]</span><br><span class="line">    seed_instruction_data = [</span><br><span class="line">        &#123;<span class="string">&quot;instruction&quot;</span>: t[<span class="string">&quot;instruction&quot;</span>], <span class="string">&quot;input&quot;</span>: t[<span class="string">&quot;instances&quot;</span>][<span class="number">0</span>][<span class="string">&quot;input&quot;</span>], <span class="string">&quot;output&quot;</span>: t[<span class="string">&quot;instances&quot;</span>][<span class="number">0</span>][<span class="string">&quot;output&quot;</span>]&#125;</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> seed_tasks</span><br><span class="line">    ]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Loaded <span class="subst">&#123;<span class="built_in">len</span>(seed_instruction_data)&#125;</span> human-written seed instructions&quot;</span>)</span><br><span class="line"></span><br><span class="line">    os.makedirs(output_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    request_idx = <span class="number">0</span></span><br><span class="line">    <span class="comment"># load the LM-generated instructions</span></span><br><span class="line">    machine_instruction_data = []</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(os.path.join(output_dir, <span class="string">&quot;regen.json&quot;</span>)):</span><br><span class="line">        machine_instruction_data = utils.jload(os.path.join(output_dir, <span class="string">&quot;regen.json&quot;</span>))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Loaded <span class="subst">&#123;<span class="built_in">len</span>(machine_instruction_data)&#125;</span> machine-generated instructions&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># similarities = &#123;&#125;</span></span><br><span class="line">    scorer = rouge_scorer.RougeScorer([<span class="string">&quot;rougeL&quot;</span>], use_stemmer=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># now let&#x27;s generate new instructions!</span></span><br><span class="line">    progress_bar = tqdm.tqdm(total=num_instructions_to_generate)</span><br><span class="line">    <span class="keyword">if</span> machine_instruction_data:</span><br><span class="line">        progress_bar.update(<span class="built_in">len</span>(machine_instruction_data))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># first we tokenize all the seed instructions and generated machine instructions</span></span><br><span class="line">    all_instructions = [d[<span class="string">&quot;instruction&quot;</span>] <span class="keyword">for</span> d <span class="keyword">in</span> seed_instruction_data] + [</span><br><span class="line">        d[<span class="string">&quot;instruction&quot;</span>] <span class="keyword">for</span> d <span class="keyword">in</span> machine_instruction_data</span><br><span class="line">    ]</span><br><span class="line">    all_instruction_tokens = [scorer._tokenizer.tokenize(inst) <span class="keyword">for</span> inst <span class="keyword">in</span> all_instructions]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="built_in">len</span>(machine_instruction_data) &lt; num_instructions_to_generate:</span><br><span class="line">        request_idx += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        batch_inputs = []</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(request_batch_size):</span><br><span class="line">            <span class="comment"># only sampling from the seed tasks</span></span><br><span class="line">            prompt_instructions = random.sample(seed_instruction_data, num_prompt_instructions)</span><br><span class="line">            prompt = encode_prompt(prompt_instructions)</span><br><span class="line">            batch_inputs.append(prompt)</span><br><span class="line">        decoding_args = utils.OpenAIDecodingArguments(</span><br><span class="line">            temperature=temperature,</span><br><span class="line">            n=<span class="number">1</span>,</span><br><span class="line">            max_tokens=<span class="number">3072</span>,  <span class="comment"># hard-code to maximize the length. the requests will be automatically adjusted</span></span><br><span class="line">            top_p=top_p,</span><br><span class="line">            stop=[<span class="string">&quot;\n20&quot;</span>, <span class="string">&quot;20.&quot;</span>, <span class="string">&quot;20.&quot;</span>],</span><br><span class="line">        )</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">20개의 다양한 task instruction 세트를 작성하라는 요청을 받습니다. 이러한 task instruction은 GPT 모델에 제공되며 instruction을 완료하기 위해 GPT 모델을 평가합니다.</span><br><span class="line"></span><br><span class="line">요구 사항은 다음과 같습니다.</span><br><span class="line">1. 다양성을 극대화하기 위해 각 instruction에 대해 동사를 반복하지 마십시오.</span><br><span class="line">2. instruction에 사용되는 언어도 다양해야 합니다. 예를 들어, 명령형 instruction과 질문을 결합해야 합니다.</span><br><span class="line">3. instruction의 종류가 다양해야 한다. 목록에는 open-ended 생성, 분류, 편집 등과 같은 다양한 유형의 작업이 포함되어야 합니다.</span><br><span class="line">2. GPT 언어 모델은 instruction을 완료할 수 있어야 합니다. 예를 들어 어시스턴트에게 시각적, 사진, 이미지 또는 오디오 출력과 관련된 instruction을 생성하지 마십시요. 또 다른 예를 들면 어시스턴트에게 오후 5시에 깨우라고 요청하거나 어떤 작업도 수행할 수 없기 때문에 미리 알림을 설정하지 마십시오.</span><br><span class="line">3. instruction는 한국어로 작성해야 합니다.</span><br><span class="line">4. instruction은 1~2문장이어야 합니다. 명령형 문장이나 질문이 허용됩니다.</span><br><span class="line">5. instruction에 대한 적절한 입력을 생성해야 합니다. 입력 필드에는 instruction에 대해 제공된 특정 예가 포함되어야 합니다. 현실적인 데이터를 포함해야 하며 단순한 자리 표시자를 포함해서는 안 됩니다. 입력 내용은 instruction을 어렵게 만들 수 있는 실질적인 내용을 제공해야 하지만 이상적으로는 100단어를 초과하지 않아야 합니다.</span><br><span class="line">6. 모든 instruction에 입력이 필요한 것은 아닙니다. 예를 들어, instruction이 &quot;세계에서 가장 높은 봉우리는 무엇입니까?&quot;와 같은 일반적인 정보에 대해 묻는 경우 특정 컨텍스트를 제공할 필요가 없습니다. 이 경우 입력 필드에 &quot;&lt;noinput&gt;&quot;을 넣기만 하면 됩니다.</span><br><span class="line">7. 출력은 instruction과 입력에 대한 적절한 응답이어야 합니다. 출력이 100단어 미만인지 확인하십시오.</span><br><span class="line"></span><br><span class="line">20개 Task instruction 목록:</span><br></pre></td></tr></table></figure>

<ul>
<li><p>한국어 결과<br><img src="https://user-images.githubusercontent.com/7252598/225496927-2df4614a-8e35-4032-b65a-54e898ca61e6.gif" alt="alpaca-self-gen-korean"></p>
</li>
<li><p>영어 결과<br><img src="https://user-images.githubusercontent.com/7252598/225496953-69f90efb-a20e-4147-bf4a-df623fc33e83.gif" alt="alpaca-gen-self-instruct-en"></p>
</li>
</ul>
</div><div class="article-licensing box"><div class="licensing-title"><p>Alpaca (A Strong Instruction-Following Model)</p><p><a href="https://eagle705.github.io/Alpaca/">https://eagle705.github.io/Alpaca/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Joosung Yoon</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2023-03-23</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2023-03-23</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/nlp/">nlp</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=63297c6228f9450019a5f574&amp;product=sop" defer></script></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/ia3/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">(IA3) Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/SentencePiece%EB%A5%BC%20%ED%99%9C%EC%9A%A9%ED%95%9C%20%ED%9A%A8%EA%B3%BC%EC%A0%81%EC%9D%B8%20%ED%95%9C%EA%B5%AD%EC%96%B4%20%ED%86%A0%ED%81%AC%EB%82%98%EC%9D%B4%EC%A0%80%20%EB%A7%8C%EB%93%A4%EA%B8%B0/"><span class="level-item">SentencePiece를 활용한 효과적인 한국어 토크나이저 만들기</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">댓글</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://eagle705.github.io/Alpaca/';
            this.page.identifier = 'Alpaca/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'eagle705-github-io' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/eagle705-logo.png" alt="Joosung Yoon"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Joosung Yoon</p><p class="is-size-6 is-block">Machine Learning Engineer</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>There and Back Again</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">포스트</p><a href="/archives"><p class="title">54</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">카테고리</p><a href="/categories"><p class="title">4</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">태그</p><a href="/tags"><p class="title">10</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/eagle705" target="_blank" rel="noopener">팔로우</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/eagle705"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com/hisdevelopers"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/JSYoon53859120"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="LinkedIn" href="https://www.linkedin.com/in/joosung-yoon/"><i class="fab fa-linkedin"></i></a></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">카테고리</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cslog/"><span class="level-start"><span class="level-item">cslog</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/paper/"><span class="level-start"><span class="level-item">paper</span></span><span class="level-end"><span class="level-item tag">36</span></span></a></li><li><a class="level is-mobile" href="/categories/photo/"><span class="level-start"><span class="level-item">photo</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">아카이브</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/05/"><span class="level-start"><span class="level-item">5월 2023</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/03/"><span class="level-start"><span class="level-item">3월 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">2월 2023</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/01/"><span class="level-start"><span class="level-item">1월 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">12월 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/11/"><span class="level-start"><span class="level-item">11월 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/10/"><span class="level-start"><span class="level-item">10월 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/09/"><span class="level-start"><span class="level-item">9월 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">8월 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">7월 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">6월 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">5월 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/01/"><span class="level-start"><span class="level-item">1월 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/12/"><span class="level-start"><span class="level-item">12월 2021</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/11/"><span class="level-start"><span class="level-item">11월 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/10/"><span class="level-start"><span class="level-item">10월 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/06/"><span class="level-start"><span class="level-item">6월 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/05/"><span class="level-start"><span class="level-item">5월 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/02/"><span class="level-start"><span class="level-item">2월 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/12/"><span class="level-start"><span class="level-item">12월 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/11/"><span class="level-start"><span class="level-item">11월 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/10/"><span class="level-start"><span class="level-item">10월 2019</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/09/"><span class="level-start"><span class="level-item">9월 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/08/"><span class="level-start"><span class="level-item">8월 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/07/"><span class="level-start"><span class="level-item">7월 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/05/"><span class="level-start"><span class="level-item">5월 2019</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/04/"><span class="level-start"><span class="level-item">4월 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/11/"><span class="level-start"><span class="level-item">11월 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/06/"><span class="level-start"><span class="level-item">6월 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/05/"><span class="level-start"><span class="level-item">5월 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/04/"><span class="level-start"><span class="level-item">4월 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">태그</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/ML/"><span class="tag">ML</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/docker/"><span class="tag">docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/drone/"><span class="tag">drone</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/grpc/"><span class="tag">grpc</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/linux/"><span class="tag">linux</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/nlp/"><span class="tag">nlp</span><span class="tag">43</span></a></div><div class="control"><a class="tags has-addons" href="/tags/nlp-kb/"><span class="tag">nlp, kb</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/search/"><span class="tag">search</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/web/"><span class="tag">web</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%83%9D%EA%B0%81%EC%A0%95%EB%A6%AC/"><span class="tag">생각정리</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="adsense"><div class="card-content"><div class="menu"><h3 class="menu-label">광고</h3><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-2655870716902046" data-ad-slot="2764253071" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">카탈로그</h3><ul class="menu-list"><ul class="menu-list"><li><a class="level is-mobile" href="#Hello-Alpaca"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">Hello, Alpaca?</span></span></a></li><li><a class="level is-mobile" href="#Alpaca를-왜-만들었을까"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">Alpaca를 왜 만들었을까?</span></span></a></li><li><a class="level is-mobile" href="#학습-방법"><span class="level-left"><span class="level-item">1.3</span><span class="level-item">학습 방법</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#데이터-생성-예시"><span class="level-left"><span class="level-item">1.3.1</span><span class="level-item">데이터 생성 예시</span></span></a></li></ul></li><li><a class="level is-mobile" href="#마치며"><span class="level-left"><span class="level-item">1.4</span><span class="level-item">마치며</span></span></a></li><li><a class="level is-mobile" href="#참고자료"><span class="level-left"><span class="level-item">1.5</span><span class="level-item">참고자료</span></span></a></li></ul><li><a class="level is-mobile" href="#Note"><span class="level-left"><span class="level-item">2</span><span class="level-item">Note</span></span></a></li><li><a class="level is-mobile" href="#Author"><span class="level-left"><span class="level-item">3</span><span class="level-item">Author</span></span></a></li><li><a class="level is-mobile" href="#Summary"><span class="level-left"><span class="level-item">4</span><span class="level-item">Summary</span></span></a></li><li><a class="level is-mobile" href="#Abstract"><span class="level-left"><span class="level-item">5</span><span class="level-item">Abstract</span></span></a></li><li><a class="level is-mobile" href="#Overview"><span class="level-left"><span class="level-item">6</span><span class="level-item">Overview</span></span></a></li><li><a class="level is-mobile" href="#Training-recipe"><span class="level-left"><span class="level-item">7</span><span class="level-item">Training recipe</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Data-Generation-Process-self-Instruct를-단순화-해서-사용"><span class="level-left"><span class="level-item">7.1</span><span class="level-item">Data Generation Process (self-Instruct를 단순화 해서 사용)</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Preliminary-evaluation"><span class="level-left"><span class="level-item">8</span><span class="level-item">Preliminary evaluation</span></span></a></li><li><a class="level is-mobile" href="#Known-limitations"><span class="level-left"><span class="level-item">9</span><span class="level-item">Known limitations</span></span></a></li><li><a class="level is-mobile" href="#Assets-released"><span class="level-left"><span class="level-item">10</span><span class="level-item">Assets released</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#공개된-Data-예시"><span class="level-left"><span class="level-item">10.1</span><span class="level-item">공개된 Data 예시</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Future-directions"><span class="level-left"><span class="level-item">11</span><span class="level-item">Future directions</span></span></a></li><li><a class="level is-mobile" href="#Acknowledgements"><span class="level-left"><span class="level-item">12</span><span class="level-item">Acknowledgements</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#prompt"><span class="level-left"><span class="level-item">12.1</span><span class="level-item">prompt</span></span></a></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">최근 글</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-05-09T02:54:53.000Z">2023-05-09</time></p><p class="title"><a href="/pythia/">Pythia (A Suite for Analyzing Large Language Models Across Training and Scaling)</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-05-09T02:54:39.000Z">2023-05-09</time></p><p class="title"><a href="/llama/">LLaMA (Open and Efficient Foundation Language Models)</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-05-09T02:54:01.000Z">2023-05-09</time></p><p class="title"><a href="/ia3/">(IA3) Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-03-23T08:14:37.000Z">2023-03-23</time></p><p class="title"><a href="/Alpaca/">Alpaca (A Strong Instruction-Following Model)</a></p><p class="categories"><a href="/categories/paper/">paper</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-02-20T13:07:50.000Z">2023-02-20</time></p><p class="title"><a href="/SentencePiece%EB%A5%BC%20%ED%99%9C%EC%9A%A9%ED%95%9C%20%ED%9A%A8%EA%B3%BC%EC%A0%81%EC%9D%B8%20%ED%95%9C%EA%B5%AD%EC%96%B4%20%ED%86%A0%ED%81%AC%EB%82%98%EC%9D%B4%EC%A0%80%20%EB%A7%8C%EB%93%A4%EA%B8%B0/">SentencePiece를 활용한 효과적인 한국어 토크나이저 만들기</a></p><p class="categories"><a href="/categories/ML/">ML</a></p></div></article></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/eagle705-logo.png" alt="Luke&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2023 Joosung Yoon</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("ko");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="맨 위로" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "이 웹 사이트는 귀하의 경험을 향상시키기 위해 Cookie를 사용합니다.",
          dismiss: "무시",
          allow: "허용",
          deny: "거부",
          link: "더 알아보기",
          policy: "Cookie 정책",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="입력 하세요..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"입력 하세요...","untitled":"(제목 없음)","posts":"포스트","pages":"페이지","categories":"카테고리","tags":"태그"});
        });</script></body></html>