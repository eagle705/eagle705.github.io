<!doctype html>
<html lang="ko"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>태그: nlp - Luke&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Luke&#039;s Blog"><meta name="msapplication-TileImage" content="/img/favicon.ico"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Luke&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Luke&#039;s Blog"><meta property="og:url" content="https://eagle705.github.io/"><meta property="og:site_name" content="Luke&#039;s Blog"><meta property="og:locale" content="ko_KR"><meta property="og:image" content="https://eagle705.github.io/img/og_image.png"><meta property="article:author" content="Joosung Yoon"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://eagle705.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://eagle705.github.io"},"headline":"Luke's Blog","image":["https://eagle705.github.io/img/og_image.png"],"author":{"@type":"Person","name":"Joosung Yoon"},"publisher":{"@type":"Organization","name":"Luke's Blog","logo":{"@type":"ImageObject","url":"https://eagle705.github.io/img/eagle705-logo.png"}},"description":null}</script><link rel="icon" href="/img/favicon.ico"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/monokai.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-110980734-1" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-110980734-1');</script><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><script data-ad-client="ca-pub-2655870716902046" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" async></script><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/eagle705-logo.png" alt="Luke&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="검색" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">태그</a></li><li class="is-active"><a href="#" aria-current="page">nlp</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-02-20T13:07:50.000Z" title="2/20/2023, 10:07:50 PM">2023-02-20</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2023-02-20T13:08:42.637Z" title="2/20/2023, 10:08:42 PM">2023-02-20</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/ML/">ML</a></span><span class="level-item">19분안에 읽기 (약 2924 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/SetencePiece%EB%A5%BC%20%ED%99%9C%EC%9A%A9%ED%95%9C%20%ED%9A%A8%EA%B3%BC%EC%A0%81%EC%9D%B8%20%ED%95%9C%EA%B5%AD%EC%96%B4%20%ED%86%A0%ED%81%AC%EB%82%98%EC%9D%B4%EC%A0%80%20%EB%A7%8C%EB%93%A4%EA%B8%B0/">sentencepice</a></h1><div class="content"><h1 id="소개"><a href="#소개" class="headerlink" title="소개"></a>소개</h1><p>자연어 문장을 컴퓨터가 쉽게 이해하게 만들기 위해서는 다양한 전처리 과정을 거쳐야합니다.<br>그중 하나는 문장을 토큰 단위로 쪼개는 토크나이징 방법입니다.<br>오늘은 SentencePiece를 활용하여 한국어 텍스트를 효과적으로 토크나이징 하는 방법을 소개합니다.</p>
<p><a target="_blank" rel="noopener" href="https://github.com/google/sentencepiece">SentencePiece</a>는 Google에서 <a target="_blank" rel="noopener" href="https://aclanthology.org/D18-2012/">2018년도에 공개한</a> 오픈소스 라이브러리로, 다양한 자연어처리 태스크에서 널리 사용되고 있습니다.<br>최근에는 <a target="_blank" rel="noopener" href="https://github.com/huggingface/tokenizers">Huggingface에서 공개한 Tokenizers</a>도 자주 사용되고 있지만 오늘은 Sentencepiece에 대한 내용을 주로 다루도록 하겠습니다.</p>
<h1 id="설치방법"><a href="#설치방법" class="headerlink" title="설치방법"></a>설치방법</h1><ul>
<li>pyenv를 통해 sentencepiece를 설치할 환경을 구성합니다</li>
<li>작성시점 기준 비교적 최신인 3.11.x 버전을 설치해줍니다</li>
<li>설치는 pyenv 기준으로 진행하겠습니다</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ pyenv install -list</span><br><span class="line">Available versions:</span><br><span class="line">  ....</span><br><span class="line">  3.11.1</span><br><span class="line">  3.12.0a4</span><br><span class="line">  3.12-dev</span><br><span class="line">  activepython-3.6.0</span><br><span class="line">  anaconda-1.4.0</span><br></pre></td></tr></table></figure>

<ul>
<li>pyenv로 파이썬 가상환경을 구성 후 필요한 패키지를 설치합니다</li>
</ul></div><a class="article-more button is-small is-size-7" href="/SetencePiece%EB%A5%BC%20%ED%99%9C%EC%9A%A9%ED%95%9C%20%ED%9A%A8%EA%B3%BC%EC%A0%81%EC%9D%B8%20%ED%95%9C%EA%B5%AD%EC%96%B4%20%ED%86%A0%ED%81%AC%EB%82%98%EC%9D%B4%EC%A0%80%20%EB%A7%8C%EB%93%A4%EA%B8%B0/#more">자세히 보기</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-02-16T08:24:12.000Z" title="2/16/2023, 5:24:12 PM">2023-02-16</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2023-02-16T08:25:22.220Z" title="2/16/2023, 5:25:22 PM">2023-02-16</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/paper/">paper</a></span><span class="level-item">20분안에 읽기 (약 3031 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Toolformer/">Toolformer: Language Models Can Teach Themselves to Use Tools</a></h1><div class="content"><h1 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h1><ul>
<li>미리 학습데이터를 API 기반으로 생성해놓되, 생성할때는 loss에 도움이 되는 방향으로 구성해놓고, 실제 인퍼런스할때 API콜과 관련된 토큰이 나오면 잠시 디코딩 중지 후 API콜하고 결과 받아온다음에 다시 이어서하는 방식!</li>
<li>API종류가 많진 않아서, 완전 범용적인 평가라 하기엔 애매하고 약간 무거운것 같기도하나(학습과정이), 실제 사용할땐 편할수도</li>
<li>공개된 레포는 없지만, lucidrains가 만들기 시도 (<a target="_blank" rel="noopener" href="https://github.com/lucidrains/toolformer-pytorch">https://github.com/lucidrains/toolformer-pytorch</a>)</li>
<li>paper: <a target="_blank" rel="noopener" href="https://github.com/eagle705/presentation/files/10753629/Toolformer-.Language.Models.Can.Teach.Themselves.to.Use.Tools.pdf">Toolformer Language Models Can Teach Themselves to Use Tools.pdf</a></li>
<li>자세한 내용은 slide 참고: <a target="_blank" rel="noopener" href="https://github.com/eagle705/presentation/files/10753635/Toolformer.pdf">Toolformer.pdf</a></li>
</ul>
<h1 id="Author"><a href="#Author" class="headerlink" title="Author"></a>Author</h1><ul>
<li>Timo Schick Jane Dwivedi-Yu Roberto Dessì† Roberta Raileanu Maria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom<ul>
<li><code>Meta AI Research</code> †Universitat Pompeu Fabra</li>
</ul>
</li>
</ul>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul>
<li>They also, <strong>paradoxically</strong>, struggle with basic functionality, such as arithmetic or factual lookup, where much simpler and smaller models excel.</li>
<li>In this paper, we show that <strong>LMs can teach themselves</strong> to use <code>external tools via simple APIs</code> and achieve the best of both worlds.</li>
<li>We introduce <code>Toolformer</code>, a model <code>trained to decide which APIs to call</code>, <code>when to call</code> them, <code>what arguments to pass</code>, and <code>how to best incorporate the results into future token prediction</code>.<ul>
<li>이게 이 논문의 핵심이네, 어떤 API를 콜할지, 언제 콜할지, 어떤 args를 넣을지 어떻게 future token 예측에 쓸건지를 고르는 것!</li>
</ul>
</li>
<li>This is done in a self-supervised way, <code>requiring nothing more than a handful of demonstrations for each API</code></li>
<li>We incorporate a range of tools, including a calculator, a Q&amp;A system, a search engine, a translation system, and a calendar.</li>
<li>Toolformer achieves substantially improved zero-shot performance across a variety of downstream tasks, often competitive with much larger models, without sacrificing its core language modeling abilities.</li>
</ul>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1></div><a class="article-more button is-small is-size-7" href="/Toolformer/#more">자세히 보기</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-02-13T04:18:48.000Z" title="2/13/2023, 1:18:48 PM">2023-02-13</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2023-02-13T04:19:27.901Z" title="2/13/2023, 1:19:27 PM">2023-02-13</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/paper/">paper</a></span><span class="level-item">20분안에 읽기 (약 3026 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/SELF-INSTRUCT%20Aligning%20Language%20Model%20with%20Self%20Generated%20Instructions/">SELF-INSTRUCT Aligning Language Model with Self Generated Instructions</a></h1><div class="content"><h1 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h1><ul>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/yizhongw/self-instruct">https://github.com/yizhongw/self-instruct</a></li>
<li>slide: <a target="_blank" rel="noopener" href="https://github.com/eagle705/presentation/files/10718545/SELF-INSTRUCT.pdf">SELF-INSTRUCT.pdf</a></li>
<li>여기 있는 Instruction은 NLP task쪽이라기보다 InstructGPT에서의 prompt중에 명령관련 표현을 의미하는 듯</li>
<li>Instruction뿐만 아니라 Instance도 생성하기 때문에 challenge하고, LLM에 내재되어있는 능력을 꺼내되 꺼낸 컨텐츠도 LLM안에 있는거라서, human의 개입이 잘안들어간 self-Instruct+Instance라고 할 수 있을듯<ul>
<li>Because of SELF-INSTRUCT’s dependence on the inductive biases extracted from LMs</li>
</ul>
</li>
<li>InstructGPT_001 정도의 모델을 휴먼리소스 적게해서 만드는 방법</li>
<li><a target="_blank" rel="noopener" href="https://github.com/yizhongw/self-instruct/blob/main/data/seed_tasks.jsonl">175개 시드 템플릿</a></li>
</ul>
<table>
<thead>
<tr>
<th>예시1</th>
<th>예시2</th>
</tr>
</thead>
<tbody><tr>
<td><img src="https://user-images.githubusercontent.com/7252598/217453282-8fc30591-2633-473a-b157-e08abb47596d.png" alt="image"></td>
<td><img src="https://user-images.githubusercontent.com/7252598/217465744-c1fcb396-cbc1-468b-86e4-d72d5d005e9d.png" alt="두번째예시"></td>
</tr>
</tbody></table>
<h1 id="Author"><a href="#Author" class="headerlink" title="Author"></a>Author</h1><ul>
<li>Yizhong Wang♣ Yeganeh Kordi♢ Swaroop Mishra♡ Alisa Liu♣ Noah A. Smith♣+ Daniel Khashabi♠ Hannaneh Hajishirzi♣+ </li>
<li>♣University of Washington ♢Tehran Polytechnic ♡Arizona State University ♠Johns Hopkins University +Allen Institute for AI</li>
</ul>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul>
<li>Large “instruction-tuned” language models (finetuned to respond to instructions) have demonstrated a remarkable ability to generalize zero-shot to new tasks.<ul>
<li>Nevertheless, they depend heavily on human-written instruction data that is limited in quantity, diversity, and creativity, therefore hindering the generality of the tuned model.</li>
</ul>
</li>
<li>We introduce SELF-INSTRUCT, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off its own generations.</li>
<li>Our pipeline <ul>
<li>generates <ul>
<li>instruction, </li>
<li>input, and </li>
<li>output samples</li>
</ul>
</li>
<li>from a language model, then prunes them before using them to finetune the original model.</li>
</ul>
</li>
<li>Applying our method to vanilla GPT3, we demonstrate a 33% absolute improvement over the original model on SUPERNATURALINSTRUCTIONS, on par with the performance of InstructGPT001</li>
<li>we curate a set of expert-written instructions for novel tasks, and show through human evaluation that tuning GPT3 with SELF-INSTRUCT outperforms using existing public instruction datasets by a large margin, leaving only a 5% absolute gap behind InstructGPT001</li>
<li>SELF-INSTRUCT provides an almost annotation-free method for aligning pretrained language models with instructions, and we <a target="_blank" rel="noopener" href="https://github.com/yizhongw/self-instruct">release our large synthetic dataset to facilitate future studies on instruction tuning</a>.</li>
</ul></div><a class="article-more button is-small is-size-7" href="/SELF-INSTRUCT%20Aligning%20Language%20Model%20with%20Self%20Generated%20Instructions/#more">자세히 보기</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-02-06T04:15:12.000Z" title="2/6/2023, 1:15:12 PM">2023-02-06</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2023-02-06T04:15:59.816Z" title="2/6/2023, 1:15:59 PM">2023-02-06</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/paper/">paper</a></span><span class="level-item">14분안에 읽기 (약 2138 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/(FLAN)%20Finetuned%20Language%20Models%20Are%20Zero-Shot%20Learners/">(FLAN) Finetuned Language Models Are Zero-Shot Learners</a></h1><div class="content"><h1 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h1><ul>
<li>2022년 2월 구글 리서치쪽 논문</li>
<li>github: <a target="_blank" rel="noopener" href="https://github.com/google-research/flan">https://github.com/google-research/flan</a></li>
<li>참고할 데이터 mixture code: <a target="_blank" rel="noopener" href="https://github.com/google-research/FLAN/blob/main/flan/v2/mixtures.py">https://github.com/google-research/FLAN/blob/main/flan/v2/mixtures.py</a></li>
<li>논문 pdf:<br><a target="_blank" rel="noopener" href="https://github.com/eagle705/presentation/files/10659673/FLAN.FINETUNED.LANGUAGE.MODELS.ARE.ZERO-SHOT.LEARNERS.pdf">(FLAN)FINETUNED LANGUAGE MODELS ARE ZERO-SHOT LEARNERS.pdf</a></li>
</ul>
<h1 id="Author"><a href="#Author" class="headerlink" title="Author"></a>Author</h1><ul>
<li>Jason Wei∗, Maarten Bosma∗, Vincent Y. Zhao∗, Kelvin Guu∗, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, and Quoc V. Le<ul>
<li><strong>Google Research</strong></li>
</ul>
</li>
</ul>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul>
<li>explores a simple method for improving the zero-shot learning abilities of language models.</li>
<li>instruction tuning—finetuning language models on a collection of datasets described via instructions—substantially improves zero-shot performance on unseen tasks.</li>
<li><strong>137B</strong> parameter pretrained language model and instruction tune it on over 60 NLP datasets verbalized via natural language instruction templates. We evaluate this instruction-tuned model, which we call FLAN, on unseen task types.<br><img src="https://user-images.githubusercontent.com/7252598/216854220-97b06f92-1c9b-4bac-996d-f4de2bf9c5fd.png" alt="image"></li>
</ul>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1></div><a class="article-more button is-small is-size-7" href="/(FLAN)%20Finetuned%20Language%20Models%20Are%20Zero-Shot%20Learners/#more">자세히 보기</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-02-03T07:44:54.000Z" title="2/3/2023, 4:44:54 PM">2023-02-03</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2023-02-03T07:45:54.565Z" title="2/3/2023, 4:45:54 PM">2023-02-03</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/paper/">paper</a></span><span class="level-item">14분안에 읽기 (약 2025 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/(T0)%20Multitask%20Prompted%20Training%20Enables%20Zero-Shot%20Task%20Generalization/">(T0) Multitask Prompted Training Enables Zero-Shot Task Generalization</a></h1><div class="content"><h1 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h1><ul>
<li>Zero-Shot의 가능성 열어줌</li>
<li>T5의 마무리 논문격</li>
<li>All trained models are available at <a target="_blank" rel="noopener" href="https://github.com/bigscience-workshop/t-zero">https://github.com/bigscience-workshop/t-zero</a></li>
<li>all prompts are available at <a target="_blank" rel="noopener" href="https://github.com/bigscience-workshop/promptsource">https://github.com/bigscience-workshop/promptsource</a>.</li>
<li>논문 pdf 파일: <a target="_blank" rel="noopener" href="https://github.com/eagle705/presentation/files/10576665/T0.MULTITASK.PROMPTED.TRAINING.ENABLES.ZERO-SHOT.TASK.GENERALIZATION.pdf">(T0)MULTITASK PROMPTED TRAINING ENABLES ZERO-SHOT TASK GENERALIZATION.pdf</a></li>
</ul>
<h1 id="Author"><a href="#Author" class="headerlink" title="Author"></a>Author</h1><ul>
<li>V Sanh (Hugging Face) 저술 · 2021</li>
</ul>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul>
<li>Q) Can zero-shot generalization instead be directly induced by explicit multitask learning?</li>
<li>we develop a system for easily mapping any natural language tasks into a human-readable prompted form. <ul>
<li>convert a large set of supervised datasets, each with multiple prompts with diverse wording</li>
<li>fine-tune a pre-trained encoder-decoder model (Raffel et al., 2020; Lester et al., 2021) on this multi-task mixture covering a wide variety of tasks</li>
<li>The model attains strong zero-shot performance on several standard datasets, often outperforming models up to 16× its size.</li>
</ul>
</li>
</ul>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1></div><a class="article-more button is-small is-size-7" href="/(T0)%20Multitask%20Prompted%20Training%20Enables%20Zero-Shot%20Task%20Generalization/#more">자세히 보기</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-01-20T14:21:17.000Z" title="1/20/2023, 11:21:17 PM">2023-01-20</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2023-01-20T14:24:23.531Z" title="1/20/2023, 11:24:23 PM">2023-01-20</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/paper/">paper</a></span><span class="level-item">33분안에 읽기 (약 5011 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/InstructGPT/">(InstructGPT) Training language models to follow instructions with human feedback</a></h1><div class="content"><h1 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h1><ul>
<li>ChatGPT를 가기 위한 기초논문</li>
<li>paper: <a target="_blank" rel="noopener" href="https://github.com/eagle705/presentation/files/10467006/Training.language.models.to.follow.instructions.with.human.feedback.pdf">Training language models to follow instructions with human feedback.pdf</a></li>
<li>결국 real-world의 prompts가 엄청 중요하고, 그걸 labelers를 통해 잘 demonstration을 적어놔야되고, output rankings을 통해 RM을 잘 굽고 plm obj를 특정 비율로 유지시키면서 PPO를 잘 굽는게 핵심..!</li>
</ul>
<h1 id="Author"><a href="#Author" class="headerlink" title="Author"></a>Author</h1><ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Ouyang,+L">Long Ouyang</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Wu,+J">Jeff Wu</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Jiang,+X">Xu Jiang</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Almeida,+D">Diogo Almeida</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Wainwright,+C+L">Carroll L. Wainwright</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Mishkin,+P">Pamela Mishkin</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Zhang,+C">Chong Zhang</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Agarwal,+S">Sandhini Agarwal</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Slama,+K">Katarina Slama</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Ray,+A">Alex Ray</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Schulman,+J">John Schulman</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Hilton,+J">Jacob Hilton</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Kelton,+F">Fraser Kelton</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Miller,+L">Luke Miller</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Simens,+M">Maddie Simens</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Askell,+A">Amanda Askell</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Welinder,+P">Peter Welinder</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Christiano,+P">Paul Christiano</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Leike,+J">Jan Leike</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Lowe,+R">Ryan Lowe</a><ul>
<li>OpenAI</li>
</ul>
</li>
</ul>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul>
<li>Making language models bigger does not inherently make them better at following a user’s intent<ul>
<li>모델 크기만 키우는게 유저의 의도를 따라가는 관점에서는 더 낫게해주진 않음</li>
</ul>
</li>
<li>large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user<ul>
<li>믿기 어렵거나 toxic하거나 하는 문장도 생성해내기 때문</li>
</ul>
</li>
<li>이런 모델들은 <strong>not aligned</strong> with their users!</li>
<li>show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback.<ul>
<li>이 논문에서 LM을 유저의 의도에 맞게 파인튜닝하고 human feedback을 줘서 align했을때 효과를 보여줄 것임</li>
</ul>
</li>
<li>Starting with a set of labeler-written prompts and prompts submitted through the OpenAI API, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune GPT-3 using supervised learning.<ul>
<li>GPT-3 튜닝할 목적으로 labeler demonstrations 데이터셋 수집</li>
</ul>
</li>
<li>collect a dataset of rankings of model outputs<ul>
<li>모델 아웃풋에 대한 랭킹으로 수집함</li>
</ul>
</li>
<li>which we use to further fine-tune this supervised model using reinforcement learning from human feedback<ul>
<li>RLHF로 파인튜닝하기 위해서 사용할 것</li>
</ul>
</li>
<li>call the resulting models InstructGPT<ul>
<li>학습한 모델을 InstructGPT로 부를 것임</li>
</ul>
</li>
<li>In human evaluations on our prompt distribution, outputs from the 1.3B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters.<ul>
<li>Human 평가에서 보면 1.3B InstructGPT가 175 GPT-3보다 결과가 좋음</li>
</ul>
</li>
<li>InstructGPT models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public NLP datasets<ul>
<li>truthfulness나 toxic 관점에서도 꽤 개선이 보였음</li>
</ul>
</li>
<li>RLHF기반 finetuning이 aligning LMs with human intents 관점에서 꽤 promising direction임을 보임</li>
</ul>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1></div><a class="article-more button is-small is-size-7" href="/InstructGPT/#more">자세히 보기</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-01-09T07:34:18.000Z" title="1/9/2023, 4:34:18 PM">2023-01-09</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2023-01-09T07:34:37.397Z" title="1/9/2023, 4:34:37 PM">2023-01-09</time>&nbsp;업데이트 됨</span><span class="level-item">11분안에 읽기 (약 1598 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Chinchilla-Training-Compute-Optimal-Large-Language-Models/">(Chinchilla) Training Compute-Optimal Large Language Models</a></h1><div class="content"><h1 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h1><ul>
<li>paper file: <a target="_blank" rel="noopener" href="https://github.com/eagle705/presentation/files/10371283/Training.Compute-Optimal.Large.Language.Models.pdf">Training Compute-Optimal Large Language Models.pdf</a></li>
<li>최적 모델 크기와 데이터 크기, FLOPs를 알기위한 함수를 estimate했던 논문</li>
<li>데이터 스케일링도 모델스케일링만큼 중요하다!</li>
</ul>
<h1 id="Author"><a href="#Author" class="headerlink" title="Author"></a>Author</h1><ul>
<li>Jordan Hoffmann★, Sebastian Borgeaud★, Arthur Mensch★, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican, George van den Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich Elsen, Jack W. Rae, Oriol Vinyals and Laurent Sifre★ (★Equal contributions)<ul>
<li>DeepMind</li>
</ul>
</li>
</ul>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul>
<li>investigate the optimal model size and number of tokens for training a transformer language model</li>
<li>By training over 400 language models ranging from 70 million to over 16 billion parameters on 5 to 500 billion tokens, find that for compute-optimal training, <strong>the model size and the number of training tokens should be scaled equally</strong><ul>
<li>모델 사이즈와 학습 토큰의 스케일은 비례함</li>
</ul>
</li>
<li>for every <strong>doubling</strong> of model size the number of training tokens should also be <strong>doubled</strong></li>
<li>test this hypothesis by training a predicted compute-optimal model, <code>Chinchilla</code>, that uses the <code>same compute budget as Gopher</code> but with <code>70B parameters and 4× more more data</code></li>
<li>Chinchilla uniformly and significantly outperforms Gopher (280B), GPT-3 (175B), Jurassic-1 (178B), and Megatron-Turing NLG (530B) on a large range of downstream evaluation tasks.<ul>
<li>친칠라가 다운스트림태스크에서 다 이겼다?</li>
</ul>
</li>
<li>Chinchilla reaches a state-of-the-art average accuracy of <code>67.5% on the MMLU benchmark</code>, greater than a 7% improvement over Gopher</li>
</ul>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1></div><a class="article-more button is-small is-size-7" href="/Chinchilla-Training-Compute-Optimal-Large-Language-Models/#more">자세히 보기</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-12-12T06:45:59.000Z" title="12/12/2022, 3:45:59 PM">2022-12-12</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-12-12T06:46:28.958Z" title="12/12/2022, 3:46:28 PM">2022-12-12</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/paper/">paper</a></span><span class="level-item">18분안에 읽기 (약 2743 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Robust-Conversational-Agents-against-Imperceptible-Toxicity-Triggers/">Robust Conversational Agents against Imperceptible Toxicity Triggers</a></h1><div class="content"><h1 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h1><ul>
<li>Github: <a target="_blank" rel="noopener" href="https://github.com/Ninarehm/Robust-Agents">https://github.com/Ninarehm/Robust-Agents</a></li>
<li>발표자료: <a target="_blank" rel="noopener" href="https://github.com/eagle705/presentation/files/10205206/pdf_2_Robust.Conversational.Agents.against.Imperceptible.Toxicity.Triggers.pdf">Robust Conversational Agents against Imperceptible Toxicity Triggers.pdf</a></li>
</ul>
<h1 id="Author"><a href="#Author" class="headerlink" title="Author"></a>Author</h1><ul>
<li>Ninareh Mehrabi1, Ahmad Beirami2∗, Fred Morstatter1, Aram Galstyan1 </li>
<li>1University of Southern California - Information Sciences Institute 2Meta AI</li>
</ul>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul>
<li>최근 NLP 연구는 다양한 toxicity detection에 개선이 있었음<ul>
<li>toxicity detection models with the intention of identifying and mitigating toxic language from existing systems.</li>
</ul>
</li>
<li>기존 연구가 많긴하나 adversarial attacks과 defense에 대한 연구는 부족했음<ul>
<li>adversarial attacks that force the system to generate toxic language and the defense against them</li>
</ul>
</li>
<li>기존의 연구는 대부분 사람이 attack 용 문장을 생성해왔음, 비용이 비싸고 확장가능하지 않음</li>
<li>반면에 자동화해서 만든 attack인 경우 attack vector가 human-like language와 맞지 않음, 이는 LM loss로 detecting이 가능함<ul>
<li>Existing work to generate such attacks is either based on human-generated attacks which is costly and not scalable or, in case of automatic attacks, the attack vector does not conform to human-like language, which can be detected using a language model loss</li>
</ul>
</li>
<li>본 연구에서는 conversational agents를 눈에 띄지 않게 공격(앞서 자동화한 공격과 달리 인식되지 못하게) 하는 방법을 coherency, relevancy, fluency 관점에서 제안함<ul>
<li>propose attacks against conversational agents that are imperceptible, i.e., they fit the conversation in terms of coherency, relevancy, and fluency, while they are effective and scalable, i.e., they can automatically trigger the system into generating toxic language</li>
</ul>
</li>
<li>본 연구에서는 제안한 attack에 대한 defense mechanism도 제안함. 공격을 완화시킬뿐만 아니라 conversational flow도 유지시킬 수 있는 방법을 제안함<ul>
<li>propose a defense mechanism against such attacks which not only mitigates the attack but also attempts to maintain the conversational flow</li>
</ul>
</li>
<li>결론적으로 공격이 잘들어와도 잘 막을 수 있는 방법에 대해 automaitc and human evaluations했고 효과적임을 보였음<ul>
<li>our defense is effective at avoiding toxic language generation even against imperceptible toxicity triggers while the generated language fits the conversation in terms of coherency and relevancy</li>
</ul>
</li>
</ul>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1></div><a class="article-more button is-small is-size-7" href="/Robust-Conversational-Agents-against-Imperceptible-Toxicity-Triggers/#more">자세히 보기</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-11-02T06:27:15.000Z" title="11/2/2022, 3:27:15 PM">2022-11-02</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-11-02T06:29:32.403Z" title="11/2/2022, 3:29:32 PM">2022-11-02</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/paper/">paper</a></span><span class="level-item">30분안에 읽기 (약 4456 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/SOCIAL-CHEMISTRY-101/">SOCIAL CHEMISTRY 101 - Learning to Reason about Social and Moral Norms</a></h1><div class="content"><h1 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h1><ul>
<li>web site: <a target="_blank" rel="noopener" href="https://maxwellforbes.com/social-chemistry/">https://maxwellforbes.com/social-chemistry/</a></li>
<li>paper: <a target="_blank" rel="noopener" href="https://github.com/eagle705/presentation/files/9916874/SOCIAL.CHEMISTRY.101-.Learning.to.Reason.about.Social.and.Moral.Norms.pdf">SOCIAL CHEMISTRY 101- Learning to Reason about Social and Moral Norms.pdf</a></li>
<li>데이터셋 수집 순서<ul>
<li>상황 수집 필요 (여기선 레딧, 고민상담, 찬반좌등이 있을법한 상황설정된곳에서 가져옴) </li>
<li>→ 상황마다 RoT를 1~5개 생성 </li>
<li>→  RoT마다 multiple annotation 작성 (같은 RoT를 다르게 볼 수 있으니..) </li>
<li>→ RoT Breakdown, Action Breakdown (Action도 해야되나.. RoT안에 포함된거아닌가.. attribute 자체는 다르긴한데? 정답은! RoT는 도덕적인 관점에서 따지고, Action은 법이나 문화적인 관점에서 따짐) </li>
<li>→ 추가적인 태깅도 진행 불분명한 상황이거나, 19금상황이거나, 너무불편한주제(학대나,…); 이런 경우는 스킵가능</li>
</ul>
</li>
<li>RoT가이드라인등은 비슷하게 가져가면 될 것으로 보임</li>
<li>137명이 태깅함</li>
<li>split our dataset into 80&#x2F;10&#x2F;10% train&#x2F;dev&#x2F;test partitions by situation</li>
<li>데이터 예시</li>
</ul>
<table>
<thead>
<tr>
<th>area</th>
<th>m</th>
<th>split</th>
<th>rot-agree</th>
<th>rot-categorization</th>
<th>rot-moral-foundations</th>
<th>rot-char-targeting</th>
<th>rot-bad</th>
<th>rot-judgment</th>
<th>action</th>
<th>action-agency</th>
<th>action-moral-judgment</th>
<th>action-agree</th>
<th>action-legal</th>
<th>action-pressure</th>
<th>action-char-involved</th>
<th>action-hypothetical</th>
<th>situation</th>
<th>situation-short-id</th>
<th>rot</th>
<th>rot-id</th>
<th>rot-worker-id</th>
<th>breakdown-worker-id</th>
<th>n-characters</th>
<th>characters</th>
</tr>
</thead>
<tbody><tr>
<td>amitheasshole</td>
<td>1</td>
<td>train</td>
<td>4</td>
<td>advice</td>
<td>loyalty-betrayal</td>
<td>char-1</td>
<td>0</td>
<td>it’s bad</td>
<td>doing something that causes other people to lose trust in you.</td>
<td>agency</td>
<td>-1</td>
<td>3</td>
<td>legal</td>
<td>-2</td>
<td>char-1</td>
<td>hypothetical</td>
<td>losing trust in my friend</td>
<td>reddit&#x2F;amitheasshole&#x2F;aypvmz</td>
<td>It’s bad to do something that causes other people to lose trust in you.</td>
<td>rot&#x2F;reddit&#x2F;amitheasshole&#x2F;aypvmz&#x2F;3K5TEWLKGYQFYAIY0H6JQMIY5MEIVM&#x2F;127&#x2F;2</td>
<td>127</td>
<td>0</td>
<td>2</td>
<td>narrator|my friend</td>
</tr>
<tr>
<td>amitheasshole</td>
<td>1</td>
<td>dev</td>
<td>3</td>
<td>social-norms</td>
<td>loyalty-betrayal</td>
<td>char-0</td>
<td>0</td>
<td>expected</td>
<td>people participating in the big events in their friends’ lives if asked.</td>
<td>agency</td>
<td>0</td>
<td>3</td>
<td>legal</td>
<td>2</td>
<td>char-0</td>
<td>explicit-no</td>
<td>saying no to being a bridesmaid at a friend’s wedding</td>
<td>reddit&#x2F;amitheasshole&#x2F;9tzn0z</td>
<td>People are expected to participate in the big events in their friends’ lives if asked.</td>
<td>rot&#x2F;reddit&#x2F;amitheasshole&#x2F;9tzn0z&#x2F;3EG49X351XRR9FSSYVYCH4PEC656XX&#x2F;89&#x2F;1</td>
<td>89</td>
<td>39</td>
<td>3</td>
<td>narrator|a bridesmaid|a friend</td>
</tr>
<tr>
<td>amitheasshole</td>
<td>1</td>
<td>test</td>
<td>3</td>
<td>social-norms</td>
<td>care-harm|loyalty-betrayal</td>
<td>char-1</td>
<td>0</td>
<td>Partners should</td>
<td>Listening to each other’s issues.</td>
<td>agency</td>
<td>2</td>
<td>3</td>
<td>legal</td>
<td>2</td>
<td>char-1</td>
<td>probable</td>
<td>telling my boyfriend I am bored and unhappy at my job</td>
<td>reddit&#x2F;amitheasshole&#x2F;a1311q</td>
<td>Partners should listen to each other’s issues.</td>
<td>rot&#x2F;reddit&#x2F;amitheasshole&#x2F;a1311q&#x2F;3JV9LGBJWWT6CZ369HK2AIBAUGUGOV&#x2F;111&#x2F;2</td>
<td>111</td>
<td>145</td>
<td>2</td>
<td>narrator|my boyfriend</td>
</tr>
</tbody></table>
<h1 id="Author"><a href="#Author" class="headerlink" title="Author"></a>Author</h1><p>Maxwell Forbes†‡ Jena D. Hwang‡ Vered Shwartz†‡ Maarten Sap† Yejin Choi†‡<br>†Paul G. Allen School of Computer Science &amp; Engineering, University of Washington ‡Allen Institute for AI</p>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul>
<li>introduce SOCIAL-CHEM- 101, a large-scale corpus that catalogs <code>292k rules-of-thumb</code> such as <code>“It is rude to run a blender at 5am”</code> as the basic conceptual units.</li>
<li>Each <code>rule-of-thumb</code> is further broken down with <code>12 different dimensions</code> of people’s judgments, including <code>social judgments of good and bad, moral foundations, expected cultural pressure, and assumed legality</code><ul>
<li>which together amount to over <code>4.5 million annotations</code> of categorical labels and free-text descriptions.</li>
</ul>
</li>
<li>NEURAL NORM TRANSFORMER, learns and generalizes SOCIAL-CHEM-101 to successfully reason about previously unseen situations, generating relevant (and potentially novel) attribute-aware social rules-of-thumb</li>
</ul></div><a class="article-more button is-small is-size-7" href="/SOCIAL-CHEMISTRY-101/#more">자세히 보기</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-10-05T07:16:45.000Z" title="10/5/2022, 4:16:45 PM">2022-10-05</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-10-05T07:17:17.065Z" title="10/5/2022, 4:17:17 PM">2022-10-05</time>&nbsp;업데이트 됨</span><span class="level-item">15분안에 읽기 (약 2266 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/A-Contrastive-Framework-for-Neural-Text-Generation-NeurIPS-2022/">A Contrastive Framework for Neural Text Generation (NeurIPS 2022)</a></h1><div class="content"><h1 id="발표자료"><a href="#발표자료" class="headerlink" title="발표자료"></a>발표자료</h1><ul>
<li>논문: <a target="_blank" rel="noopener" href="https://github.com/eagle705/presentation/files/9709326/A.Contrastive.Framework.for.Neural.Text.Generation.pdf">A Contrastive Framework for Neural Text Generation.pdf</a></li>
<li>발표자료: <a target="_blank" rel="noopener" href="https://github.com/eagle705/presentation/files/9713502/A.Contrastive.Framework.for.Neural.Text.Generation.pdf">A Contrastive Framework for Neural Text Generation.pdf</a></li>
</ul>
<h1 id="느낀점"><a href="#느낀점" class="headerlink" title="느낀점"></a>느낀점</h1><ul>
<li>잘 쓴 논문 같다</li>
<li>간단한 아이디어지만 효과적</li>
<li>decoding 시간이 생각보다 덜 걸려서 신기했음</li>
<li>contrastive 방법론이 결국 비슷한 토큰 안나오게 하겠다인데, simCTG는 MLE 로 보완되지만 디코딩 부분은 아예 비슷한걸 견제하는 식으로 나오는데도 결과가 좋게 나오는게 신기 (물론 기존의 확률아 있어서 보완이 되지만) -&gt; degeneration penalty를 크게 줘도 ppl 결과가 좋길래 신기했음)</li>
</ul>
<h1 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h1><h1 id="Author"><a href="#Author" class="headerlink" title="Author"></a>Author</h1><p>Yixuan Su* Tian Lan** Yan Wang** Dani Yogatama+ Lingpeng Kong++ Nigel Collier*<br>*Language Technology Lab, University of Cambridge<br>**Tencent AI Lab +DeepMind<br>++Department of Computer Science, The University of Hong Kong</p></div><a class="article-more button is-small is-size-7" href="/A-Contrastive-Framework-for-Neural-Text-Generation-NeurIPS-2022/#more">자세히 보기</a></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/tags/nlp/page/0/">이전</a></div><div class="pagination-next"><a href="/tags/nlp/page/2/">다음</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/tags/nlp/">1</a></li><li><a class="pagination-link" href="/tags/nlp/page/2/">2</a></li><li><a class="pagination-link" href="/tags/nlp/page/3/">3</a></li><li><a class="pagination-link" href="/tags/nlp/page/4/">4</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/eagle705-logo.png" alt="Joosung Yoon"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Joosung Yoon</p><p class="is-size-6 is-block">Machine Learning Engineer</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>There and Back Again</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">포스트</p><a href="/archives"><p class="title">50</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">카테고리</p><a href="/categories"><p class="title">4</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">태그</p><a href="/tags"><p class="title">10</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/eagle705" target="_blank" rel="noopener">팔로우</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/eagle705"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com/hisdevelopers"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/JSYoon53859120"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="LinkedIn" href="https://www.linkedin.com/in/joosung-yoon/"><i class="fab fa-linkedin"></i></a></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">카테고리</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cslog/"><span class="level-start"><span class="level-item">cslog</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/paper/"><span class="level-start"><span class="level-item">paper</span></span><span class="level-end"><span class="level-item tag">35</span></span></a></li><li><a class="level is-mobile" href="/categories/photo/"><span class="level-start"><span class="level-item">photo</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">아카이브</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">2월 2023</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/01/"><span class="level-start"><span class="level-item">1월 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">12월 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/11/"><span class="level-start"><span class="level-item">11월 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/10/"><span class="level-start"><span class="level-item">10월 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/09/"><span class="level-start"><span class="level-item">9월 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">8월 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">7월 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">6월 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">5월 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/01/"><span class="level-start"><span class="level-item">1월 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/12/"><span class="level-start"><span class="level-item">12월 2021</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/11/"><span class="level-start"><span class="level-item">11월 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/10/"><span class="level-start"><span class="level-item">10월 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/06/"><span class="level-start"><span class="level-item">6월 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/05/"><span class="level-start"><span class="level-item">5월 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/02/"><span class="level-start"><span class="level-item">2월 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/12/"><span class="level-start"><span class="level-item">12월 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/11/"><span class="level-start"><span class="level-item">11월 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/10/"><span class="level-start"><span class="level-item">10월 2019</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/09/"><span class="level-start"><span class="level-item">9월 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/08/"><span class="level-start"><span class="level-item">8월 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/07/"><span class="level-start"><span class="level-item">7월 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/05/"><span class="level-start"><span class="level-item">5월 2019</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/04/"><span class="level-start"><span class="level-item">4월 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/11/"><span class="level-start"><span class="level-item">11월 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/06/"><span class="level-start"><span class="level-item">6월 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/05/"><span class="level-start"><span class="level-item">5월 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/04/"><span class="level-start"><span class="level-item">4월 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">태그</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/ML/"><span class="tag">ML</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/docker/"><span class="tag">docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/drone/"><span class="tag">drone</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/grpc/"><span class="tag">grpc</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/linux/"><span class="tag">linux</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/nlp/"><span class="tag">nlp</span><span class="tag">39</span></a></div><div class="control"><a class="tags has-addons" href="/tags/nlp-kb/"><span class="tag">nlp, kb</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/search/"><span class="tag">search</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/web/"><span class="tag">web</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%83%9D%EA%B0%81%EC%A0%95%EB%A6%AC/"><span class="tag">생각정리</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="adsense"><div class="card-content"><div class="menu"><h3 class="menu-label">광고</h3><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-2655870716902046" data-ad-slot="2764253071" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><!--!--><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">최근 글</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-02-20T13:07:50.000Z">2023-02-20</time></p><p class="title"><a href="/SetencePiece%EB%A5%BC%20%ED%99%9C%EC%9A%A9%ED%95%9C%20%ED%9A%A8%EA%B3%BC%EC%A0%81%EC%9D%B8%20%ED%95%9C%EA%B5%AD%EC%96%B4%20%ED%86%A0%ED%81%AC%EB%82%98%EC%9D%B4%EC%A0%80%20%EB%A7%8C%EB%93%A4%EA%B8%B0/">sentencepice</a></p><p class="categories"><a href="/categories/ML/">ML</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-02-16T08:24:12.000Z">2023-02-16</time></p><p class="title"><a href="/Toolformer/">Toolformer: Language Models Can Teach Themselves to Use Tools</a></p><p class="categories"><a href="/categories/paper/">paper</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-02-13T04:18:48.000Z">2023-02-13</time></p><p class="title"><a href="/SELF-INSTRUCT%20Aligning%20Language%20Model%20with%20Self%20Generated%20Instructions/">SELF-INSTRUCT Aligning Language Model with Self Generated Instructions</a></p><p class="categories"><a href="/categories/paper/">paper</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-02-06T04:15:12.000Z">2023-02-06</time></p><p class="title"><a href="/(FLAN)%20Finetuned%20Language%20Models%20Are%20Zero-Shot%20Learners/">(FLAN) Finetuned Language Models Are Zero-Shot Learners</a></p><p class="categories"><a href="/categories/paper/">paper</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-02-03T07:44:54.000Z">2023-02-03</time></p><p class="title"><a href="/(T0)%20Multitask%20Prompted%20Training%20Enables%20Zero-Shot%20Task%20Generalization/">(T0) Multitask Prompted Training Enables Zero-Shot Task Generalization</a></p><p class="categories"><a href="/categories/paper/">paper</a></p></div></article></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/eagle705-logo.png" alt="Luke&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2023 Joosung Yoon</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("ko");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="맨 위로" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "이 웹 사이트는 귀하의 경험을 향상시키기 위해 Cookie를 사용합니다.",
          dismiss: "무시",
          allow: "허용",
          deny: "거부",
          link: "더 알아보기",
          policy: "Cookie 정책",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="입력 하세요..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"입력 하세요...","untitled":"(제목 없음)","posts":"포스트","pages":"페이지","categories":"카테고리","tags":"태그"});
        });</script></body></html>