<!doctype html>
<html lang="ko"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>태그: nlp - Luke&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Luke&#039;s Blog"><meta name="msapplication-TileImage" content="/img/favicon.ico"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Luke&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Luke&#039;s Blog"><meta property="og:url" content="https://eagle705.github.io/"><meta property="og:site_name" content="Luke&#039;s Blog"><meta property="og:locale" content="ko_KR"><meta property="og:image" content="https://eagle705.github.io/img/og_image.png"><meta property="article:author" content="Joosung Yoon"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://eagle705.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://eagle705.github.io"},"headline":"Luke's Blog","image":["https://eagle705.github.io/img/og_image.png"],"author":{"@type":"Person","name":"Joosung Yoon"},"publisher":{"@type":"Organization","name":"Luke's Blog","logo":{"@type":"ImageObject","url":"https://eagle705.github.io/img/eagle705-logo.png"}},"description":null}</script><link rel="icon" href="/img/favicon.ico"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/monokai.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-110980734-1" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-110980734-1');</script><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><script data-ad-client="ca-pub-2655870716902046" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" async></script><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/eagle705-logo.png" alt="Luke&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="검색" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">태그</a></li><li class="is-active"><a href="#" aria-current="page">nlp</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-02-06T04:15:12.000Z" title="2/6/2023, 1:15:12 PM">2023-02-06</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2023-02-06T04:15:59.816Z" title="2/6/2023, 1:15:59 PM">2023-02-06</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/paper/">paper</a></span><span class="level-item">14분안에 읽기 (약 2138 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/(FLAN)%20Finetuned%20Language%20Models%20Are%20Zero-Shot%20Learners/">(FLAN) Finetuned Language Models Are Zero-Shot Learners</a></h1><div class="content"><h1 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h1><ul>
<li>2022년 2월 구글 리서치쪽 논문</li>
<li>github: <a target="_blank" rel="noopener" href="https://github.com/google-research/flan">https://github.com/google-research/flan</a></li>
<li>참고할 데이터 mixture code: <a target="_blank" rel="noopener" href="https://github.com/google-research/FLAN/blob/main/flan/v2/mixtures.py">https://github.com/google-research/FLAN/blob/main/flan/v2/mixtures.py</a></li>
<li>논문 pdf:<br><a target="_blank" rel="noopener" href="https://github.com/eagle705/presentation/files/10659673/FLAN.FINETUNED.LANGUAGE.MODELS.ARE.ZERO-SHOT.LEARNERS.pdf">(FLAN)FINETUNED LANGUAGE MODELS ARE ZERO-SHOT LEARNERS.pdf</a></li>
</ul>
<h1 id="Author"><a href="#Author" class="headerlink" title="Author"></a>Author</h1><ul>
<li>Jason Wei∗, Maarten Bosma∗, Vincent Y. Zhao∗, Kelvin Guu∗, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, and Quoc V. Le<ul>
<li><strong>Google Research</strong></li>
</ul>
</li>
</ul>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul>
<li>explores a simple method for improving the zero-shot learning abilities of language models.</li>
<li>instruction tuning—finetuning language models on a collection of datasets described via instructions—substantially improves zero-shot performance on unseen tasks.</li>
<li><strong>137B</strong> parameter pretrained language model and instruction tune it on over 60 NLP datasets verbalized via natural language instruction templates. We evaluate this instruction-tuned model, which we call FLAN, on unseen task types.<br><img src="https://user-images.githubusercontent.com/7252598/216854220-97b06f92-1c9b-4bac-996d-f4de2bf9c5fd.png" alt="image"></li>
</ul>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1></div><a class="article-more button is-small is-size-7" href="/(FLAN)%20Finetuned%20Language%20Models%20Are%20Zero-Shot%20Learners/#more">자세히 보기</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-02-03T07:44:54.000Z" title="2/3/2023, 4:44:54 PM">2023-02-03</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2023-02-03T07:45:54.565Z" title="2/3/2023, 4:45:54 PM">2023-02-03</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/paper/">paper</a></span><span class="level-item">14분안에 읽기 (약 2025 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/(T0)%20Multitask%20Prompted%20Training%20Enables%20Zero-Shot%20Task%20Generalization/">(T0) Multitask Prompted Training Enables Zero-Shot Task Generalization</a></h1><div class="content"><h1 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h1><ul>
<li>Zero-Shot의 가능성 열어줌</li>
<li>T5의 마무리 논문격</li>
<li>All trained models are available at <a target="_blank" rel="noopener" href="https://github.com/bigscience-workshop/t-zero">https://github.com/bigscience-workshop/t-zero</a></li>
<li>all prompts are available at <a target="_blank" rel="noopener" href="https://github.com/bigscience-workshop/promptsource">https://github.com/bigscience-workshop/promptsource</a>.</li>
<li>논문 pdf 파일: <a target="_blank" rel="noopener" href="https://github.com/eagle705/presentation/files/10576665/T0.MULTITASK.PROMPTED.TRAINING.ENABLES.ZERO-SHOT.TASK.GENERALIZATION.pdf">(T0)MULTITASK PROMPTED TRAINING ENABLES ZERO-SHOT TASK GENERALIZATION.pdf</a></li>
</ul>
<h1 id="Author"><a href="#Author" class="headerlink" title="Author"></a>Author</h1><ul>
<li>V Sanh (Hugging Face) 저술 · 2021</li>
</ul>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul>
<li>Q) Can zero-shot generalization instead be directly induced by explicit multitask learning?</li>
<li>we develop a system for easily mapping any natural language tasks into a human-readable prompted form. <ul>
<li>convert a large set of supervised datasets, each with multiple prompts with diverse wording</li>
<li>fine-tune a pre-trained encoder-decoder model (Raffel et al., 2020; Lester et al., 2021) on this multi-task mixture covering a wide variety of tasks</li>
<li>The model attains strong zero-shot performance on several standard datasets, often outperforming models up to 16× its size.</li>
</ul>
</li>
</ul>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1></div><a class="article-more button is-small is-size-7" href="/(T0)%20Multitask%20Prompted%20Training%20Enables%20Zero-Shot%20Task%20Generalization/#more">자세히 보기</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-01-20T14:21:17.000Z" title="1/20/2023, 11:21:17 PM">2023-01-20</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2023-01-20T14:24:23.531Z" title="1/20/2023, 11:24:23 PM">2023-01-20</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/paper/">paper</a></span><span class="level-item">33분안에 읽기 (약 5011 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/InstructGPT/">(InstructGPT) Training language models to follow instructions with human feedback</a></h1><div class="content"><h1 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h1><ul>
<li>ChatGPT를 가기 위한 기초논문</li>
<li>paper: <a target="_blank" rel="noopener" href="https://github.com/eagle705/presentation/files/10467006/Training.language.models.to.follow.instructions.with.human.feedback.pdf">Training language models to follow instructions with human feedback.pdf</a></li>
<li>결국 real-world의 prompts가 엄청 중요하고, 그걸 labelers를 통해 잘 demonstration을 적어놔야되고, output rankings을 통해 RM을 잘 굽고 plm obj를 특정 비율로 유지시키면서 PPO를 잘 굽는게 핵심..!</li>
</ul>
<h1 id="Author"><a href="#Author" class="headerlink" title="Author"></a>Author</h1><ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Ouyang,+L">Long Ouyang</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Wu,+J">Jeff Wu</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Jiang,+X">Xu Jiang</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Almeida,+D">Diogo Almeida</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Wainwright,+C+L">Carroll L. Wainwright</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Mishkin,+P">Pamela Mishkin</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Zhang,+C">Chong Zhang</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Agarwal,+S">Sandhini Agarwal</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Slama,+K">Katarina Slama</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Ray,+A">Alex Ray</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Schulman,+J">John Schulman</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Hilton,+J">Jacob Hilton</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Kelton,+F">Fraser Kelton</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Miller,+L">Luke Miller</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Simens,+M">Maddie Simens</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Askell,+A">Amanda Askell</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Welinder,+P">Peter Welinder</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Christiano,+P">Paul Christiano</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Leike,+J">Jan Leike</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Lowe,+R">Ryan Lowe</a><ul>
<li>OpenAI</li>
</ul>
</li>
</ul>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul>
<li>Making language models bigger does not inherently make them better at following a user’s intent<ul>
<li>모델 크기만 키우는게 유저의 의도를 따라가는 관점에서는 더 낫게해주진 않음</li>
</ul>
</li>
<li>large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user<ul>
<li>믿기 어렵거나 toxic하거나 하는 문장도 생성해내기 때문</li>
</ul>
</li>
<li>이런 모델들은 <strong>not aligned</strong> with their users!</li>
<li>show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback.<ul>
<li>이 논문에서 LM을 유저의 의도에 맞게 파인튜닝하고 human feedback을 줘서 align했을때 효과를 보여줄 것임</li>
</ul>
</li>
<li>Starting with a set of labeler-written prompts and prompts submitted through the OpenAI API, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune GPT-3 using supervised learning.<ul>
<li>GPT-3 튜닝할 목적으로 labeler demonstrations 데이터셋 수집</li>
</ul>
</li>
<li>collect a dataset of rankings of model outputs<ul>
<li>모델 아웃풋에 대한 랭킹으로 수집함</li>
</ul>
</li>
<li>which we use to further fine-tune this supervised model using reinforcement learning from human feedback<ul>
<li>RLHF로 파인튜닝하기 위해서 사용할 것</li>
</ul>
</li>
<li>call the resulting models InstructGPT<ul>
<li>학습한 모델을 InstructGPT로 부를 것임</li>
</ul>
</li>
<li>In human evaluations on our prompt distribution, outputs from the 1.3B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters.<ul>
<li>Human 평가에서 보면 1.3B InstructGPT가 175 GPT-3보다 결과가 좋음</li>
</ul>
</li>
<li>InstructGPT models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public NLP datasets<ul>
<li>truthfulness나 toxic 관점에서도 꽤 개선이 보였음</li>
</ul>
</li>
<li>RLHF기반 finetuning이 aligning LMs with human intents 관점에서 꽤 promising direction임을 보임</li>
</ul>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1></div><a class="article-more button is-small is-size-7" href="/InstructGPT/#more">자세히 보기</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-01-09T07:34:18.000Z" title="1/9/2023, 4:34:18 PM">2023-01-09</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2023-01-09T07:34:37.397Z" title="1/9/2023, 4:34:37 PM">2023-01-09</time>&nbsp;업데이트 됨</span><span class="level-item">11분안에 읽기 (약 1598 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Chinchilla-Training-Compute-Optimal-Large-Language-Models/">(Chinchilla) Training Compute-Optimal Large Language Models</a></h1><div class="content"><h1 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h1><ul>
<li>paper file: <a target="_blank" rel="noopener" href="https://github.com/eagle705/presentation/files/10371283/Training.Compute-Optimal.Large.Language.Models.pdf">Training Compute-Optimal Large Language Models.pdf</a></li>
<li>최적 모델 크기와 데이터 크기, FLOPs를 알기위한 함수를 estimate했던 논문</li>
<li>데이터 스케일링도 모델스케일링만큼 중요하다!</li>
</ul>
<h1 id="Author"><a href="#Author" class="headerlink" title="Author"></a>Author</h1><ul>
<li>Jordan Hoffmann★, Sebastian Borgeaud★, Arthur Mensch★, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican, George van den Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich Elsen, Jack W. Rae, Oriol Vinyals and Laurent Sifre★ (★Equal contributions)<ul>
<li>DeepMind</li>
</ul>
</li>
</ul>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul>
<li>investigate the optimal model size and number of tokens for training a transformer language model</li>
<li>By training over 400 language models ranging from 70 million to over 16 billion parameters on 5 to 500 billion tokens, find that for compute-optimal training, <strong>the model size and the number of training tokens should be scaled equally</strong><ul>
<li>모델 사이즈와 학습 토큰의 스케일은 비례함</li>
</ul>
</li>
<li>for every <strong>doubling</strong> of model size the number of training tokens should also be <strong>doubled</strong></li>
<li>test this hypothesis by training a predicted compute-optimal model, <code>Chinchilla</code>, that uses the <code>same compute budget as Gopher</code> but with <code>70B parameters and 4× more more data</code></li>
<li>Chinchilla uniformly and significantly outperforms Gopher (280B), GPT-3 (175B), Jurassic-1 (178B), and Megatron-Turing NLG (530B) on a large range of downstream evaluation tasks.<ul>
<li>친칠라가 다운스트림태스크에서 다 이겼다?</li>
</ul>
</li>
<li>Chinchilla reaches a state-of-the-art average accuracy of <code>67.5% on the MMLU benchmark</code>, greater than a 7% improvement over Gopher</li>
</ul>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1></div><a class="article-more button is-small is-size-7" href="/Chinchilla-Training-Compute-Optimal-Large-Language-Models/#more">자세히 보기</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-12-12T06:45:59.000Z" title="12/12/2022, 3:45:59 PM">2022-12-12</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-12-12T06:46:28.958Z" title="12/12/2022, 3:46:28 PM">2022-12-12</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/paper/">paper</a></span><span class="level-item">18분안에 읽기 (약 2743 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Robust-Conversational-Agents-against-Imperceptible-Toxicity-Triggers/">Robust Conversational Agents against Imperceptible Toxicity Triggers</a></h1><div class="content"><h1 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h1><ul>
<li>Github: <a target="_blank" rel="noopener" href="https://github.com/Ninarehm/Robust-Agents">https://github.com/Ninarehm/Robust-Agents</a></li>
<li>발표자료: <a target="_blank" rel="noopener" href="https://github.com/eagle705/presentation/files/10205206/pdf_2_Robust.Conversational.Agents.against.Imperceptible.Toxicity.Triggers.pdf">Robust Conversational Agents against Imperceptible Toxicity Triggers.pdf</a></li>
</ul>
<h1 id="Author"><a href="#Author" class="headerlink" title="Author"></a>Author</h1><ul>
<li>Ninareh Mehrabi1, Ahmad Beirami2∗, Fred Morstatter1, Aram Galstyan1 </li>
<li>1University of Southern California - Information Sciences Institute 2Meta AI</li>
</ul>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul>
<li>최근 NLP 연구는 다양한 toxicity detection에 개선이 있었음<ul>
<li>toxicity detection models with the intention of identifying and mitigating toxic language from existing systems.</li>
</ul>
</li>
<li>기존 연구가 많긴하나 adversarial attacks과 defense에 대한 연구는 부족했음<ul>
<li>adversarial attacks that force the system to generate toxic language and the defense against them</li>
</ul>
</li>
<li>기존의 연구는 대부분 사람이 attack 용 문장을 생성해왔음, 비용이 비싸고 확장가능하지 않음</li>
<li>반면에 자동화해서 만든 attack인 경우 attack vector가 human-like language와 맞지 않음, 이는 LM loss로 detecting이 가능함<ul>
<li>Existing work to generate such attacks is either based on human-generated attacks which is costly and not scalable or, in case of automatic attacks, the attack vector does not conform to human-like language, which can be detected using a language model loss</li>
</ul>
</li>
<li>본 연구에서는 conversational agents를 눈에 띄지 않게 공격(앞서 자동화한 공격과 달리 인식되지 못하게) 하는 방법을 coherency, relevancy, fluency 관점에서 제안함<ul>
<li>propose attacks against conversational agents that are imperceptible, i.e., they fit the conversation in terms of coherency, relevancy, and fluency, while they are effective and scalable, i.e., they can automatically trigger the system into generating toxic language</li>
</ul>
</li>
<li>본 연구에서는 제안한 attack에 대한 defense mechanism도 제안함. 공격을 완화시킬뿐만 아니라 conversational flow도 유지시킬 수 있는 방법을 제안함<ul>
<li>propose a defense mechanism against such attacks which not only mitigates the attack but also attempts to maintain the conversational flow</li>
</ul>
</li>
<li>결론적으로 공격이 잘들어와도 잘 막을 수 있는 방법에 대해 automaitc and human evaluations했고 효과적임을 보였음<ul>
<li>our defense is effective at avoiding toxic language generation even against imperceptible toxicity triggers while the generated language fits the conversation in terms of coherency and relevancy</li>
</ul>
</li>
</ul>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1></div><a class="article-more button is-small is-size-7" href="/Robust-Conversational-Agents-against-Imperceptible-Toxicity-Triggers/#more">자세히 보기</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-11-02T06:27:15.000Z" title="11/2/2022, 3:27:15 PM">2022-11-02</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-11-02T06:29:32.403Z" title="11/2/2022, 3:29:32 PM">2022-11-02</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/paper/">paper</a></span><span class="level-item">30분안에 읽기 (약 4456 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/SOCIAL-CHEMISTRY-101/">SOCIAL CHEMISTRY 101 - Learning to Reason about Social and Moral Norms</a></h1><div class="content"><h1 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h1><ul>
<li>web site: <a target="_blank" rel="noopener" href="https://maxwellforbes.com/social-chemistry/">https://maxwellforbes.com/social-chemistry/</a></li>
<li>paper: <a target="_blank" rel="noopener" href="https://github.com/eagle705/presentation/files/9916874/SOCIAL.CHEMISTRY.101-.Learning.to.Reason.about.Social.and.Moral.Norms.pdf">SOCIAL CHEMISTRY 101- Learning to Reason about Social and Moral Norms.pdf</a></li>
<li>데이터셋 수집 순서<ul>
<li>상황 수집 필요 (여기선 레딧, 고민상담, 찬반좌등이 있을법한 상황설정된곳에서 가져옴) </li>
<li>→ 상황마다 RoT를 1~5개 생성 </li>
<li>→  RoT마다 multiple annotation 작성 (같은 RoT를 다르게 볼 수 있으니..) </li>
<li>→ RoT Breakdown, Action Breakdown (Action도 해야되나.. RoT안에 포함된거아닌가.. attribute 자체는 다르긴한데? 정답은! RoT는 도덕적인 관점에서 따지고, Action은 법이나 문화적인 관점에서 따짐) </li>
<li>→ 추가적인 태깅도 진행 불분명한 상황이거나, 19금상황이거나, 너무불편한주제(학대나,…); 이런 경우는 스킵가능</li>
</ul>
</li>
<li>RoT가이드라인등은 비슷하게 가져가면 될 것으로 보임</li>
<li>137명이 태깅함</li>
<li>split our dataset into 80&#x2F;10&#x2F;10% train&#x2F;dev&#x2F;test partitions by situation</li>
<li>데이터 예시</li>
</ul>
<table>
<thead>
<tr>
<th>area</th>
<th>m</th>
<th>split</th>
<th>rot-agree</th>
<th>rot-categorization</th>
<th>rot-moral-foundations</th>
<th>rot-char-targeting</th>
<th>rot-bad</th>
<th>rot-judgment</th>
<th>action</th>
<th>action-agency</th>
<th>action-moral-judgment</th>
<th>action-agree</th>
<th>action-legal</th>
<th>action-pressure</th>
<th>action-char-involved</th>
<th>action-hypothetical</th>
<th>situation</th>
<th>situation-short-id</th>
<th>rot</th>
<th>rot-id</th>
<th>rot-worker-id</th>
<th>breakdown-worker-id</th>
<th>n-characters</th>
<th>characters</th>
</tr>
</thead>
<tbody><tr>
<td>amitheasshole</td>
<td>1</td>
<td>train</td>
<td>4</td>
<td>advice</td>
<td>loyalty-betrayal</td>
<td>char-1</td>
<td>0</td>
<td>it’s bad</td>
<td>doing something that causes other people to lose trust in you.</td>
<td>agency</td>
<td>-1</td>
<td>3</td>
<td>legal</td>
<td>-2</td>
<td>char-1</td>
<td>hypothetical</td>
<td>losing trust in my friend</td>
<td>reddit&#x2F;amitheasshole&#x2F;aypvmz</td>
<td>It’s bad to do something that causes other people to lose trust in you.</td>
<td>rot&#x2F;reddit&#x2F;amitheasshole&#x2F;aypvmz&#x2F;3K5TEWLKGYQFYAIY0H6JQMIY5MEIVM&#x2F;127&#x2F;2</td>
<td>127</td>
<td>0</td>
<td>2</td>
<td>narrator|my friend</td>
</tr>
<tr>
<td>amitheasshole</td>
<td>1</td>
<td>dev</td>
<td>3</td>
<td>social-norms</td>
<td>loyalty-betrayal</td>
<td>char-0</td>
<td>0</td>
<td>expected</td>
<td>people participating in the big events in their friends’ lives if asked.</td>
<td>agency</td>
<td>0</td>
<td>3</td>
<td>legal</td>
<td>2</td>
<td>char-0</td>
<td>explicit-no</td>
<td>saying no to being a bridesmaid at a friend’s wedding</td>
<td>reddit&#x2F;amitheasshole&#x2F;9tzn0z</td>
<td>People are expected to participate in the big events in their friends’ lives if asked.</td>
<td>rot&#x2F;reddit&#x2F;amitheasshole&#x2F;9tzn0z&#x2F;3EG49X351XRR9FSSYVYCH4PEC656XX&#x2F;89&#x2F;1</td>
<td>89</td>
<td>39</td>
<td>3</td>
<td>narrator|a bridesmaid|a friend</td>
</tr>
<tr>
<td>amitheasshole</td>
<td>1</td>
<td>test</td>
<td>3</td>
<td>social-norms</td>
<td>care-harm|loyalty-betrayal</td>
<td>char-1</td>
<td>0</td>
<td>Partners should</td>
<td>Listening to each other’s issues.</td>
<td>agency</td>
<td>2</td>
<td>3</td>
<td>legal</td>
<td>2</td>
<td>char-1</td>
<td>probable</td>
<td>telling my boyfriend I am bored and unhappy at my job</td>
<td>reddit&#x2F;amitheasshole&#x2F;a1311q</td>
<td>Partners should listen to each other’s issues.</td>
<td>rot&#x2F;reddit&#x2F;amitheasshole&#x2F;a1311q&#x2F;3JV9LGBJWWT6CZ369HK2AIBAUGUGOV&#x2F;111&#x2F;2</td>
<td>111</td>
<td>145</td>
<td>2</td>
<td>narrator|my boyfriend</td>
</tr>
</tbody></table>
<h1 id="Author"><a href="#Author" class="headerlink" title="Author"></a>Author</h1><p>Maxwell Forbes†‡ Jena D. Hwang‡ Vered Shwartz†‡ Maarten Sap† Yejin Choi†‡<br>†Paul G. Allen School of Computer Science &amp; Engineering, University of Washington ‡Allen Institute for AI</p>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul>
<li>introduce SOCIAL-CHEM- 101, a large-scale corpus that catalogs <code>292k rules-of-thumb</code> such as <code>“It is rude to run a blender at 5am”</code> as the basic conceptual units.</li>
<li>Each <code>rule-of-thumb</code> is further broken down with <code>12 different dimensions</code> of people’s judgments, including <code>social judgments of good and bad, moral foundations, expected cultural pressure, and assumed legality</code><ul>
<li>which together amount to over <code>4.5 million annotations</code> of categorical labels and free-text descriptions.</li>
</ul>
</li>
<li>NEURAL NORM TRANSFORMER, learns and generalizes SOCIAL-CHEM-101 to successfully reason about previously unseen situations, generating relevant (and potentially novel) attribute-aware social rules-of-thumb</li>
</ul></div><a class="article-more button is-small is-size-7" href="/SOCIAL-CHEMISTRY-101/#more">자세히 보기</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-10-05T07:16:45.000Z" title="10/5/2022, 4:16:45 PM">2022-10-05</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-10-05T07:17:17.065Z" title="10/5/2022, 4:17:17 PM">2022-10-05</time>&nbsp;업데이트 됨</span><span class="level-item">15분안에 읽기 (약 2266 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/A-Contrastive-Framework-for-Neural-Text-Generation-NeurIPS-2022/">A Contrastive Framework for Neural Text Generation (NeurIPS 2022)</a></h1><div class="content"><h1 id="발표자료"><a href="#발표자료" class="headerlink" title="발표자료"></a>발표자료</h1><ul>
<li>논문: <a target="_blank" rel="noopener" href="https://github.com/eagle705/presentation/files/9709326/A.Contrastive.Framework.for.Neural.Text.Generation.pdf">A Contrastive Framework for Neural Text Generation.pdf</a></li>
<li>발표자료: <a target="_blank" rel="noopener" href="https://github.com/eagle705/presentation/files/9713502/A.Contrastive.Framework.for.Neural.Text.Generation.pdf">A Contrastive Framework for Neural Text Generation.pdf</a></li>
</ul>
<h1 id="느낀점"><a href="#느낀점" class="headerlink" title="느낀점"></a>느낀점</h1><ul>
<li>잘 쓴 논문 같다</li>
<li>간단한 아이디어지만 효과적</li>
<li>decoding 시간이 생각보다 덜 걸려서 신기했음</li>
<li>contrastive 방법론이 결국 비슷한 토큰 안나오게 하겠다인데, simCTG는 MLE 로 보완되지만 디코딩 부분은 아예 비슷한걸 견제하는 식으로 나오는데도 결과가 좋게 나오는게 신기 (물론 기존의 확률아 있어서 보완이 되지만) -&gt; degeneration penalty를 크게 줘도 ppl 결과가 좋길래 신기했음)</li>
</ul>
<h1 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h1><h1 id="Author"><a href="#Author" class="headerlink" title="Author"></a>Author</h1><p>Yixuan Su* Tian Lan** Yan Wang** Dani Yogatama+ Lingpeng Kong++ Nigel Collier*<br>*Language Technology Lab, University of Cambridge<br>**Tencent AI Lab +DeepMind<br>++Department of Computer Science, The University of Hong Kong</p></div><a class="article-more button is-small is-size-7" href="/A-Contrastive-Framework-for-Neural-Text-Generation-NeurIPS-2022/#more">자세히 보기</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-09-20T05:18:10.000Z" title="9/20/2022, 2:18:10 PM">2022-09-20</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-09-20T05:45:05.199Z" title="9/20/2022, 2:45:05 PM">2022-09-20</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/paper/">paper</a></span><span class="level-item">5분안에 읽기 (약 812 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Learning-rate-warmup-scheduling/">Learning rate &amp; warmup step &amp; LR scheduling</a></h1><div class="content"><h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>요즘 딥러닝을 하다보면 수도없이 접하게 되는 단어 중 하나는 learning rate, warmup, LR scheduler와 같은 것들입니다.<br>이미 시중에 여러가지 기법들이 나와있고 한번은 정리해야겠다 생각했는데, 우연히 좋은 스레드를 발견하게 되서 공유해봅니다.</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/google-research/bert/issues/425">원문: What is exactly the learning rate warmup described in the paper?</a></li>
</ul>
<p>버트 논문에는 다음과 같은 그림이 있습니다. 여기서 밑줄쳐진 learning rate warmup과 linear decay에 대한 내용입니다.<br><img src="https://user-images.githubusercontent.com/17574157/52538453-a9333700-2d6a-11e9-831d-ec71c3a5cb15.png"></p>
<h2 id="Warmup"><a href="#Warmup" class="headerlink" title="Warmup"></a>Warmup</h2><p>일반적으로 lr warmup은 말그대로 천천히 lr을 올리는 작업을 뜻합니다.<br>lr을 <code>2e-5</code>로 셋팅하고 warmup step을 <code>10,000</code>으로 셋팅한다면, (linear 일 경우) lr은 10,000 스텝동안 <code>0</code>에서 <code>2e-5</code> 까지 증가하게 됩니다.<br><a target="_blank" rel="noopener" href="https://github.com/google-research/bert/blob/ffbda2a1aafe530525212d13194cc84d92ed0313/optimization.py#L29-L65">코드 구현을 보면 다음과 같습니다</a><br>현재 스텝(global step)이 warmup 스텝 대비 어느정도이지 비율을 구하고 (<code>warmup_percent_done = global_steps_float / warmup_steps_float</code>)그에 맞는 warmup_lr을 구하는 방식으로 lr을 조절해갑니다. (<code>warmup_learning_rate = init_lr * warmup_percent_done</code>)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">create_optimizer</span>(<span class="params">loss, init_lr, num_train_steps, num_warmup_steps, use_tpu</span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot;Creates an optimizer training op.&quot;&quot;&quot;</span></span><br><span class="line">  global_step = tf.train.get_or_create_global_step()</span><br><span class="line"></span><br><span class="line">  learning_rate = tf.constant(value=init_lr, shape=[], dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Implements linear decay of the learning rate.</span></span><br><span class="line">  learning_rate = tf.train.polynomial_decay(</span><br><span class="line">      learning_rate,</span><br><span class="line">      global_step,</span><br><span class="line">      num_train_steps,</span><br><span class="line">      end_learning_rate=<span class="number">0.0</span>,</span><br><span class="line">      power=<span class="number">1.0</span>,</span><br><span class="line">      cycle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Implements linear warmup. I.e., if global_step &lt; num_warmup_steps, the</span></span><br><span class="line">  <span class="comment"># learning rate will be `global_step/num_warmup_steps * init_lr`.</span></span><br><span class="line">  <span class="keyword">if</span> num_warmup_steps:</span><br><span class="line">    global_steps_int = tf.cast(global_step, tf.int32)</span><br><span class="line">    warmup_steps_int = tf.constant(num_warmup_steps, dtype=tf.int32)</span><br><span class="line"></span><br><span class="line">    global_steps_float = tf.cast(global_steps_int, tf.float32)</span><br><span class="line">    warmup_steps_float = tf.cast(warmup_steps_int, tf.float32)</span><br><span class="line"></span><br><span class="line">    warmup_percent_done = global_steps_float / warmup_steps_float</span><br><span class="line">    warmup_learning_rate = init_lr * warmup_percent_done</span><br><span class="line"></span><br><span class="line">    is_warmup = tf.cast(global_steps_int &lt; warmup_steps_int, tf.float32)</span><br><span class="line">    learning_rate = (</span><br><span class="line">        (<span class="number">1.0</span> - is_warmup) * learning_rate + is_warmup * warmup_learning_rate)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># It is recommended that you use this optimizer for fine tuning, since this</span></span><br><span class="line">  <span class="comment"># is how the model was trained (note that the Adam m/v variables are NOT</span></span><br><span class="line">  <span class="comment"># loaded from init_checkpoint.)</span></span><br><span class="line">  optimizer = AdamWeightDecayOptimizer(</span><br><span class="line">      learning_rate=learning_rate,</span><br><span class="line">      weight_decay_rate=<span class="number">0.01</span>,</span><br><span class="line">      beta_1=<span class="number">0.9</span>,</span><br><span class="line">      beta_2=<span class="number">0.999</span>,</span><br><span class="line">      epsilon=<span class="number">1e-6</span>,</span><br><span class="line">      exclude_from_weight_decay=[<span class="string">&quot;LayerNorm&quot;</span>, <span class="string">&quot;layer_norm&quot;</span>, <span class="string">&quot;bias&quot;</span>])</span><br></pre></td></tr></table></figure></div><a class="article-more button is-small is-size-7" href="/Learning-rate-warmup-scheduling/#more">자세히 보기</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-08-30T03:00:00.000Z" title="8/30/2022, 12:00:00 PM">2022-08-30</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-09-14T04:50:17.158Z" title="9/14/2022, 1:50:17 PM">2022-09-14</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/paper/">paper</a></span><span class="level-item">20분안에 읽기 (약 3045 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/LLM%EC%9D%84%20%EC%9C%84%ED%95%9C%20%EB%84%93%EA%B3%A0%20%EC%96%95%EC%9D%80%20%EC%A7%80%EC%8B%9D%EB%93%A4%20%EC%A7%80%EC%8B%9D%EB%93%A4/">LLM(Large-Scale Language Model)을 위한 넓고 얕은 지식들</a></h1><div class="content"><p>최근 LLM 관련 일을 하면서 익혀야할게 너무나 많다는 사실을 새삼스럽게 알게 되었다. 예전엔 아 그냥 하면 되지~ 정도로 생각했는데.. 디테일한게 생각보다 많구나 싶어서 이것 저것 많이 보기야 봤는데 머리에 남는게 없는 것 같아서 글로 간단하게 그리고 약간 어쩔수 없이 파편화된 상태로 정리해놓으려한다. 나 포함 누군가에게 도움이 되기를 바라며</p>
<h1 id="PyTorch로-분산-어플리케이션-개발하기"><a href="#PyTorch로-분산-어플리케이션-개발하기" class="headerlink" title="PyTorch로 분산 어플리케이션 개발하기"></a>PyTorch로 분산 어플리케이션 개발하기</h1><ul>
<li>제일 먼저 볼 것!</li>
<li><a target="_blank" rel="noopener" href="https://tutorials.pytorch.kr/intermediate/dist_tuto.html">참고</a> </li>
<li><a target="_blank" rel="noopener" href="https://better-tomorrow.tistory.com/entry/Pytorch-Multi-GPU-%EC%A0%95%EB%A6%AC-%EC%A4%91">Pytorch Multi-GPU 정리 중</a></li>
<li><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/UlnWG/btrokp3bPou/Yqnd5qX9eDEOPMFmtAwFs0/img.png" alt="node_gpu"></li>
<li>분산학습을 할때 로그를 찍으면 프로세스 개수만큼 찍힌다 -&gt; 따로 처리가 필요해짐! <code>if rank==0</code>일때만 찍게 한다던지</li>
</ul>
<h1 id="code-snippet"><a href="#code-snippet" class="headerlink" title="code snippet"></a>code snippet</h1><h2 id="all-reduce"><a href="#all-reduce" class="headerlink" title="all-reduce"></a>all-reduce</h2><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/EleutherAI/gpt-neox/blob/0bf472e91d3823b6a5be42c31d2a419f69f8e5c1/megatron/utils.py#L40">EleutherAI gpt-neox</a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">reduce_losses</span>(<span class="params">losses</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Reduce a tensor of losses across all GPUs.&quot;&quot;&quot;</span></span><br><span class="line">    reduced_losses = torch.cat([loss.clone().detach().view(<span class="number">1</span>) <span class="keyword">for</span> loss <span class="keyword">in</span> losses])</span><br><span class="line">    torch.distributed.all_reduce(reduced_losses)</span><br><span class="line">    reduced_losses = reduced_losses / torch.distributed.get_world_size()</span><br><span class="line">    <span class="keyword">return</span> reduced_losses</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="Multi-GPU-amp-Node"><a href="#Multi-GPU-amp-Node" class="headerlink" title="Multi GPU &amp; Node"></a>Multi GPU &amp; Node</h1></div><a class="article-more button is-small is-size-7" href="/LLM%EC%9D%84%20%EC%9C%84%ED%95%9C%20%EB%84%93%EA%B3%A0%20%EC%96%95%EC%9D%80%20%EC%A7%80%EC%8B%9D%EB%93%A4%20%EC%A7%80%EC%8B%9D%EB%93%A4/#more">자세히 보기</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-08-01T03:00:00.000Z" title="8/1/2022, 12:00:00 PM">2022-08-01</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-08-30T04:37:42.591Z" title="8/30/2022, 1:37:42 PM">2022-08-30</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/paper/">paper</a></span><span class="level-item">32분안에 읽기 (약 4759 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Efficient%20Training%20of%20Language%20Models%20to%20Fill%20in%20the%20Middle%20(FIM)/">Efficient Training of Language Models to Fill in the Middle (FIM)</a></h1><div class="content"><h1 id="발표자료"><a href="#발표자료" class="headerlink" title="발표자료"></a>발표자료</h1><p><a target="_blank" rel="noopener" href="https://github.com/eagle705/presentation/files/9248738/Efficient.Training.of.Language.Models.to.Fill.in.the.Middle.pdf">(발표)Efficient Training of Language Models to Fill in the Middle.pdf</a></p>
<h1 id="느낀점"><a href="#느낀점" class="headerlink" title="느낀점"></a>느낀점</h1><ul>
<li>첫인상은 data augmentation 기법에 관련된 내용을 extensive하게 검증했다정도..?</li>
<li>free-form generation을 하고 싶다에 초점을 두고 논문 전개</li>
</ul>
<h1 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h1><ul>
<li>50%란게 어떤걸까<ul>
<li>데이터셋에서 FIM으로 transformation하는 비율 (FIM 자체는 랜덤하게 짜르니까)</li>
</ul>
</li>
<li>SPM에서 캐싱이 무슨 의미 일까</li>
</ul>
<h1 id="Author"><a href="#Author" class="headerlink" title="Author"></a>Author</h1></div><a class="article-more button is-small is-size-7" href="/Efficient%20Training%20of%20Language%20Models%20to%20Fill%20in%20the%20Middle%20(FIM)/#more">자세히 보기</a></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/tags/nlp/page/0/">이전</a></div><div class="pagination-next"><a href="/tags/nlp/page/2/">다음</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/tags/nlp/">1</a></li><li><a class="pagination-link" href="/tags/nlp/page/2/">2</a></li><li><a class="pagination-link" href="/tags/nlp/page/3/">3</a></li><li><a class="pagination-link" href="/tags/nlp/page/4/">4</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/eagle705-logo.png" alt="Joosung Yoon"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Joosung Yoon</p><p class="is-size-6 is-block">Machine Learning Engineer</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>There and Back Again</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">포스트</p><a href="/archives"><p class="title">47</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">카테고리</p><a href="/categories"><p class="title">4</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">태그</p><a href="/tags"><p class="title">10</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/eagle705" target="_blank" rel="noopener">팔로우</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/eagle705"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com/hisdevelopers"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/JSYoon53859120"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="LinkedIn" href="https://www.linkedin.com/in/joosung-yoon/"><i class="fab fa-linkedin"></i></a></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">카테고리</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/cslog/"><span class="level-start"><span class="level-item">cslog</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/paper/"><span class="level-start"><span class="level-item">paper</span></span><span class="level-end"><span class="level-item tag">33</span></span></a></li><li><a class="level is-mobile" href="/categories/photo/"><span class="level-start"><span class="level-item">photo</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">아카이브</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">2월 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/01/"><span class="level-start"><span class="level-item">1월 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">12월 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/11/"><span class="level-start"><span class="level-item">11월 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/10/"><span class="level-start"><span class="level-item">10월 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/09/"><span class="level-start"><span class="level-item">9월 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">8월 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">7월 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">6월 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">5월 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/01/"><span class="level-start"><span class="level-item">1월 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/12/"><span class="level-start"><span class="level-item">12월 2021</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/11/"><span class="level-start"><span class="level-item">11월 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/10/"><span class="level-start"><span class="level-item">10월 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/06/"><span class="level-start"><span class="level-item">6월 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/05/"><span class="level-start"><span class="level-item">5월 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/02/"><span class="level-start"><span class="level-item">2월 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/12/"><span class="level-start"><span class="level-item">12월 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/11/"><span class="level-start"><span class="level-item">11월 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/10/"><span class="level-start"><span class="level-item">10월 2019</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/09/"><span class="level-start"><span class="level-item">9월 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/08/"><span class="level-start"><span class="level-item">8월 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/07/"><span class="level-start"><span class="level-item">7월 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/05/"><span class="level-start"><span class="level-item">5월 2019</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/04/"><span class="level-start"><span class="level-item">4월 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/11/"><span class="level-start"><span class="level-item">11월 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/06/"><span class="level-start"><span class="level-item">6월 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/05/"><span class="level-start"><span class="level-item">5월 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/04/"><span class="level-start"><span class="level-item">4월 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">태그</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/ML/"><span class="tag">ML</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/docker/"><span class="tag">docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/drone/"><span class="tag">drone</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/grpc/"><span class="tag">grpc</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/linux/"><span class="tag">linux</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/nlp/"><span class="tag">nlp</span><span class="tag">36</span></a></div><div class="control"><a class="tags has-addons" href="/tags/nlp-kb/"><span class="tag">nlp, kb</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/search/"><span class="tag">search</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/web/"><span class="tag">web</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%83%9D%EA%B0%81%EC%A0%95%EB%A6%AC/"><span class="tag">생각정리</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="adsense"><div class="card-content"><div class="menu"><h3 class="menu-label">광고</h3><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-2655870716902046" data-ad-slot="2764253071" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><!--!--><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">최근 글</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-02-06T04:15:12.000Z">2023-02-06</time></p><p class="title"><a href="/(FLAN)%20Finetuned%20Language%20Models%20Are%20Zero-Shot%20Learners/">(FLAN) Finetuned Language Models Are Zero-Shot Learners</a></p><p class="categories"><a href="/categories/paper/">paper</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-02-03T07:44:54.000Z">2023-02-03</time></p><p class="title"><a href="/(T0)%20Multitask%20Prompted%20Training%20Enables%20Zero-Shot%20Task%20Generalization/">(T0) Multitask Prompted Training Enables Zero-Shot Task Generalization</a></p><p class="categories"><a href="/categories/paper/">paper</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-01-20T14:21:17.000Z">2023-01-20</time></p><p class="title"><a href="/InstructGPT/">(InstructGPT) Training language models to follow instructions with human feedback</a></p><p class="categories"><a href="/categories/paper/">paper</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-01-09T07:34:18.000Z">2023-01-09</time></p><p class="title"><a href="/Chinchilla-Training-Compute-Optimal-Large-Language-Models/">(Chinchilla) Training Compute-Optimal Large Language Models</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-12-12T06:45:59.000Z">2022-12-12</time></p><p class="title"><a href="/Robust-Conversational-Agents-against-Imperceptible-Toxicity-Triggers/">Robust Conversational Agents against Imperceptible Toxicity Triggers</a></p><p class="categories"><a href="/categories/paper/">paper</a></p></div></article></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/eagle705-logo.png" alt="Luke&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2023 Joosung Yoon</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("ko");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="맨 위로" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "이 웹 사이트는 귀하의 경험을 향상시키기 위해 Cookie를 사용합니다.",
          dismiss: "무시",
          allow: "허용",
          deny: "거부",
          link: "더 알아보기",
          policy: "Cookie 정책",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="입력 하세요..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"입력 하세요...","untitled":"(제목 없음)","posts":"포스트","pages":"페이지","categories":"카테고리","tags":"태그"});
        });</script></body></html>