<!doctype html>
<html lang="ko"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>(Chinchilla) Training Compute-Optimal Large Language Models - Luke&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Luke&#039;s Blog"><meta name="msapplication-TileImage" content="/img/favicon.ico"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Luke&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Note paper file: Training Compute-Optimal Large Language Models.pdf ìµœì  ëª¨ë¸ í¬ê¸°ì™€ ë°ì´í„° í¬ê¸°, FLOPsë¥¼ ì•Œê¸°ìœ„í•œ í•¨ìˆ˜ë¥¼ estimateí–ˆë˜ ë…¼ë¬¸ ë°ì´í„° ìŠ¤ì¼€ì¼ë§ë„ ëª¨ë¸ìŠ¤ì¼€ì¼ë§ë§Œí¼ ì¤‘ìš”í•˜ë‹¤!  Author Jordan Hoffmannâ˜…, Sebastian Borgeaudâ˜…, Arthur Mensc"><meta property="og:type" content="blog"><meta property="og:title" content="(Chinchilla) Training Compute-Optimal Large Language Models"><meta property="og:url" content="https://eagle705.github.io/Chinchilla-Training-Compute-Optimal-Large-Language-Models/"><meta property="og:site_name" content="Luke&#039;s Blog"><meta property="og:description" content="Note paper file: Training Compute-Optimal Large Language Models.pdf ìµœì  ëª¨ë¸ í¬ê¸°ì™€ ë°ì´í„° í¬ê¸°, FLOPsë¥¼ ì•Œê¸°ìœ„í•œ í•¨ìˆ˜ë¥¼ estimateí–ˆë˜ ë…¼ë¬¸ ë°ì´í„° ìŠ¤ì¼€ì¼ë§ë„ ëª¨ë¸ìŠ¤ì¼€ì¼ë§ë§Œí¼ ì¤‘ìš”í•˜ë‹¤!  Author Jordan Hoffmannâ˜…, Sebastian Borgeaudâ˜…, Arthur Mensc"><meta property="og:locale" content="ko_KR"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/209597324-638983ca-fe6f-4815-9f3d-54fc0b0f33de.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/209597971-6e27cea7-b6d7-494e-a10e-b12e64bf36d9.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/209598534-c9ee49ed-85bd-48b1-84bd-efa3251eecde.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/209598557-572408c5-2443-43d9-9478-93e95608d8f5.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/211252937-53301335-5653-479b-8ec7-b2634a423418.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/211255227-afe2390b-1748-4008-9f02-865da593e02f.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/211256057-9aa5e6db-f848-4d6c-81ea-96d2f6168b84.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/211256619-a737684d-46c7-4558-a0f3-df3bd9c8dd44.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/211256954-9200a06b-3871-4d4e-b355-54a93b5ae493.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/211256780-6734b4cc-6bd1-487f-a936-8a6916ecc7ee.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/211257449-b9d0edf1-2cff-4612-8a90-23b9e0792056.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/211257516-02468291-528d-4444-a4ff-92b817c18e25.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/211257691-72b9ec61-9e26-4ca7-9b97-8515441fb48d.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/211258708-2bca2577-eb55-4f56-bd6d-1435e2ebd9ea.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/211258824-c70d15df-b81a-4f57-8b9b-c129c27874c8.png"><meta property="og:image" content="https://user-images.githubusercontent.com/7252598/211259037-c9da3e07-9c1c-4e9d-99a8-8e23f36866c9.png"><meta property="article:published_time" content="2023-01-09T07:34:18.000Z"><meta property="article:modified_time" content="2023-01-09T07:34:37.397Z"><meta property="article:author" content="Joosung Yoon"><meta property="article:tag" content="nlp"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://user-images.githubusercontent.com/7252598/209597324-638983ca-fe6f-4815-9f3d-54fc0b0f33de.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://eagle705.github.io/Chinchilla-Training-Compute-Optimal-Large-Language-Models/"},"headline":"(Chinchilla) Training Compute-Optimal Large Language Models","image":["https://user-images.githubusercontent.com/7252598/209597324-638983ca-fe6f-4815-9f3d-54fc0b0f33de.png","https://user-images.githubusercontent.com/7252598/209597971-6e27cea7-b6d7-494e-a10e-b12e64bf36d9.png","https://user-images.githubusercontent.com/7252598/209598534-c9ee49ed-85bd-48b1-84bd-efa3251eecde.png","https://user-images.githubusercontent.com/7252598/209598557-572408c5-2443-43d9-9478-93e95608d8f5.png","https://user-images.githubusercontent.com/7252598/211252937-53301335-5653-479b-8ec7-b2634a423418.png","https://user-images.githubusercontent.com/7252598/211255227-afe2390b-1748-4008-9f02-865da593e02f.png","https://user-images.githubusercontent.com/7252598/211256057-9aa5e6db-f848-4d6c-81ea-96d2f6168b84.png","https://user-images.githubusercontent.com/7252598/211256619-a737684d-46c7-4558-a0f3-df3bd9c8dd44.png","https://user-images.githubusercontent.com/7252598/211256954-9200a06b-3871-4d4e-b355-54a93b5ae493.png","https://user-images.githubusercontent.com/7252598/211256780-6734b4cc-6bd1-487f-a936-8a6916ecc7ee.png","https://user-images.githubusercontent.com/7252598/211257449-b9d0edf1-2cff-4612-8a90-23b9e0792056.png","https://user-images.githubusercontent.com/7252598/211257516-02468291-528d-4444-a4ff-92b817c18e25.png","https://user-images.githubusercontent.com/7252598/211257691-72b9ec61-9e26-4ca7-9b97-8515441fb48d.png","https://user-images.githubusercontent.com/7252598/211258708-2bca2577-eb55-4f56-bd6d-1435e2ebd9ea.png","https://user-images.githubusercontent.com/7252598/211258824-c70d15df-b81a-4f57-8b9b-c129c27874c8.png","https://user-images.githubusercontent.com/7252598/211259037-c9da3e07-9c1c-4e9d-99a8-8e23f36866c9.png"],"datePublished":"2023-01-09T07:34:18.000Z","dateModified":"2023-01-09T07:34:37.397Z","author":{"@type":"Person","name":"Joosung Yoon"},"publisher":{"@type":"Organization","name":"Luke's Blog","logo":{"@type":"ImageObject","url":"https://eagle705.github.io/img/eagle705-logo.png"}},"description":"Note paper file: Training Compute-Optimal Large Language Models.pdf ìµœì  ëª¨ë¸ í¬ê¸°ì™€ ë°ì´í„° í¬ê¸°, FLOPsë¥¼ ì•Œê¸°ìœ„í•œ í•¨ìˆ˜ë¥¼ estimateí–ˆë˜ ë…¼ë¬¸ ë°ì´í„° ìŠ¤ì¼€ì¼ë§ë„ ëª¨ë¸ìŠ¤ì¼€ì¼ë§ë§Œí¼ ì¤‘ìš”í•˜ë‹¤!  Author Jordan Hoffmannâ˜…, Sebastian Borgeaudâ˜…, Arthur Mensc"}</script><link rel="canonical" href="https://eagle705.github.io/Chinchilla-Training-Compute-Optimal-Large-Language-Models/"><link rel="icon" href="/img/favicon.ico"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/monokai.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-110980734-1" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-110980734-1');</script><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><script data-ad-client="ca-pub-2655870716902046" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" async></script><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/eagle705-logo.png" alt="Luke&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="ì¹´íƒˆë¡œê·¸" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="ê²€ìƒ‰" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-01-09T07:34:18.000Z" title="1/9/2023, 4:34:18â€¯PM">2023-01-09</time>&nbsp;ê²Œì‹œ ë¨</span><span class="level-item"><time dateTime="2023-01-09T07:34:37.397Z" title="1/9/2023, 4:34:37â€¯PM">2023-01-09</time>&nbsp;ì—…ë°ì´íŠ¸ ë¨</span><span class="level-item">11ë¶„ì•ˆì— ì½ê¸° (ì•½ 1598 ë‹¨ì–´)</span></div></div><h1 class="title is-3 is-size-4-mobile">(Chinchilla) Training Compute-Optimal Large Language Models</h1><div class="content"><h1 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h1><ul>
<li>paper file: <a target="_blank" rel="noopener" href="https://github.com/eagle705/presentation/files/10371283/Training.Compute-Optimal.Large.Language.Models.pdf">Training Compute-Optimal Large Language Models.pdf</a></li>
<li>ìµœì  ëª¨ë¸ í¬ê¸°ì™€ ë°ì´í„° í¬ê¸°, FLOPsë¥¼ ì•Œê¸°ìœ„í•œ í•¨ìˆ˜ë¥¼ estimateí–ˆë˜ ë…¼ë¬¸</li>
<li>ë°ì´í„° ìŠ¤ì¼€ì¼ë§ë„ ëª¨ë¸ìŠ¤ì¼€ì¼ë§ë§Œí¼ ì¤‘ìš”í•˜ë‹¤!</li>
</ul>
<h1 id="Author"><a href="#Author" class="headerlink" title="Author"></a>Author</h1><ul>
<li>Jordan Hoffmannâ˜…, Sebastian Borgeaudâ˜…, Arthur Menschâ˜…, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican, George van den Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich Elsen, Jack W. Rae, Oriol Vinyals and Laurent Sifreâ˜… (â˜…Equal contributions)<ul>
<li>DeepMind</li>
</ul>
</li>
</ul>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul>
<li>investigate the optimal model size and number of tokens for training a transformer language model</li>
<li>By training over 400 language models ranging from 70 million to over 16 billion parameters on 5 to 500 billion tokens, find that for compute-optimal training, <strong>the model size and the number of training tokens should be scaled equally</strong><ul>
<li>ëª¨ë¸ ì‚¬ì´ì¦ˆì™€ í•™ìŠµ í† í°ì˜ ìŠ¤ì¼€ì¼ì€ ë¹„ë¡€í•¨</li>
</ul>
</li>
<li>for every <strong>doubling</strong> of model size the number of training tokens should also be <strong>doubled</strong></li>
<li>test this hypothesis by training a predicted compute-optimal model, <code>Chinchilla</code>, that uses the <code>same compute budget as Gopher</code> but with <code>70B parameters and 4Ã— more more data</code></li>
<li>Chinchilla uniformly and significantly outperforms Gopher (280B), GPT-3 (175B), Jurassic-1 (178B), and Megatron-Turing NLG (530B) on a large range of downstream evaluation tasks.<ul>
<li>ì¹œì¹ ë¼ê°€ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼íƒœìŠ¤í¬ì—ì„œ ë‹¤ ì´ê²¼ë‹¤?</li>
</ul>
</li>
<li>Chinchilla reaches a state-of-the-art average accuracy of <code>67.5% on the MMLU benchmark</code>, greater than a 7% improvement over Gopher</li>
</ul>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><ul>
<li>LLMsì„ í•™ìŠµí•˜ë©´ì„œ ìƒê¸°ëŠ” ì´ìŠˆë“¤<ul>
<li>accurately estimating the best model hyperparameters for a given compute budget is critical<ul>
<li>ChinchillaëŠ” ì´ë²ˆì— ì•Œê²Œëœ ì—°êµ¬ ë‚´ìš©ì„ í† ëŒ€ë¡œ Gopherë³´ë‹¤ ëª¨ë¸ 4ë°° ì¤„ì´ê³  í† í° 4ë°° ëŠ˜ë ¸ë‹¤!<br><img src="https://user-images.githubusercontent.com/7252598/209597324-638983ca-fe6f-4815-9f3d-54fc0b0f33de.png" alt="image"></li>
</ul>
</li>
</ul>
</li>
<li>revisit the question: <em>Given a fixed FLOPs budget,1 how should one trade-off model size and the number of training tokens?</em></li>
<li>400ê°œ ì´ìƒì˜ ëª¨ë¸ì— ëŒ€í•´ì„œ ì—¬ëŸ¬ íŒŒë¼ë¯¸í„°ì™€ ë°ì´í„° ì‚¬ì´ì¦ˆë¡œ ì‹¤í—˜í•´ì„œ FLOPs(N,D)&#x3D;C ì œí•œ ì•„ë˜ì„œ L(N, D)ë¥¼ ê°€ì¥ ë‚®ì¶”ëŠ” ëª¨ë¸íŒŒë¼ë¯¸í„°_N, í•™ìŠµí† í°_Dì— ëŒ€í•œ í•¨ìˆ˜ë¥¼ ì¸¡ì •í•¨<br><img src="https://user-images.githubusercontent.com/7252598/209597971-6e27cea7-b6d7-494e-a10e-b12e64bf36d9.png" alt="image"></li>
<li>we <strong>predict</strong> that for the compute budget used to train Gopher, an optimal model should be <strong>4 times smaller, while being training on 4 times more tokens</strong></li>
<li>verify this by training a more <code>compute-optimal 70B model</code>, called Chinchilla, on <strong>1.4 trillion tokens</strong></li>
</ul>
<table>
<thead>
<tr>
<th>Figure 1</th>
<th>Figure A3</th>
</tr>
</thead>
<tbody><tr>
<td><img src="https://user-images.githubusercontent.com/7252598/209598534-c9ee49ed-85bd-48b1-84bd-efa3251eecde.png" alt="image"></td>
<td><img src="https://user-images.githubusercontent.com/7252598/209598557-572408c5-2443-43d9-9478-93e95608d8f5.png" alt="image"></td>
</tr>
</tbody></table>
<h1 id="Estimating-the-optimal-parameter-x2F-training-tokens-allocation"><a href="#Estimating-the-optimal-parameter-x2F-training-tokens-allocation" class="headerlink" title="Estimating the optimal parameter&#x2F;training tokens allocation"></a>Estimating the optimal parameter&#x2F;training tokens allocation</h1><ul>
<li>Research Question) <code>Given a fixed FLOPs budget, how should one trade-off model size and the number of training tokens?</code><ul>
<li>ì‚¬ì‹¤ ë‚œ ì´ê²Œ ë” ê¶ê¸ˆí•˜ê¸´í•¨</li>
</ul>
</li>
<li>ëª¨ë¸ íŒŒë¼ë¯¸í„°ì™€ í† í°ì€ ë™ì¼í•˜ê²Œ ë¹„ìœ¨ì ìœ¼ë¡œ ì˜¬ë¼ê°€ì•¼<ul>
<li>parameter count and number of training tokens should be increased equally with more compute3â€” with proportions reported in Table 2</li>
</ul>
</li>
</ul>
<h2 id="3-1-Approach-1-Fix-model-sizes-and-vary-number-of-training-tokens"><a href="#3-1-Approach-1-Fix-model-sizes-and-vary-number-of-training-tokens" class="headerlink" title="3.1. Approach 1: Fix model sizes and vary number of training tokens"></a>3.1. Approach 1: Fix model sizes and vary number of training tokens</h2><ul>
<li>ì‹œê°„ì„ íŒŒë¼ë¯¸í„°ë¡œ ì“°ê¸° ì• ë§¤í•˜ë‹ˆê¹Œ FLOPsë¡œ ì²˜ë¦¬ í•´ë²„ë¦°ê±¸ê¹Œ? ì™œ êµ³ì´ FLOPsë¥¼ ì¨ì•¼í•˜ëŠ”ì§€ ì˜ë¬¸ì´ë‹¤</li>
<li>ëª¨ë¸ ì‚¬ì´ì¦ˆ ë²”ìœ„ë‚´ì—ì„œ í”½ìŠ¤í•´ë†“ê³  (ranging from 70M to over 10B parameters), FLOPs(ğ‘, ğ·) &#x3D; ğ¶ ì¸¡ì •</li>
<li>At 1500 logarithmically spaced FLOP values, we find which model size <code>achieves the lowest loss</code> of all models <code>along with the required number of training tokens</code></li>
<li>fit power laws to estimate the optimal model size and number of training tokens for any given amount of compute<br>(see the center and right panels of Figure 2)<ul>
<li>obtaining a relationship ğ‘ğ‘œğ‘ğ‘¡ âˆ ğ¶^ğ‘ and ğ·ğ‘œğ‘ğ‘¡ âˆ ğ¶^ğ‘</li>
<li>We find that ğ‘ &#x3D; 0.50 and ğ‘ &#x3D; 0.50 â€”as summarized in Table 2.<br><img src="https://user-images.githubusercontent.com/7252598/211252937-53301335-5653-479b-8ec7-b2634a423418.png" alt="image"></li>
</ul>
</li>
</ul>
<h2 id="3-2-Approach-2-IsoFLOP-profiles"><a href="#3-2-Approach-2-IsoFLOP-profiles" class="headerlink" title="3.2. Approach 2: IsoFLOP profiles"></a>3.2. Approach 2: IsoFLOP profiles</h2><ul>
<li>vary the model size for a <code>fixed set of 9 different training FLOP counts</code> (ranging from 6 Ã— 1018 to 3 Ã— 1021 FLOPs), and consider the final training loss for each point</li>
<li>in contrast with Approach 1 that considered points (ğ‘, ğ·, ğ¿) along the entire training runs. This allows us to directly answer the question: For a given FLOP budget, what is the optimal parameter count?</li>
<li>í† í°ì´ ë§ì„ ìˆ˜ë¡ Lossê°€ ë‚®ì•„ì§„ë‹¤ (ê°™ì€ FLOPs ì¼ì§€ë¼ë„!)</li>
<li>fit a parabola to each IsoFLOPs curve to directly estimate at what model size the minimum loss is achieved (Figure 3 (left))</li>
<li>fit a power law between FLOPs and loss-optimal model size and number of training tokens, shown in<br>Figure 3 (center, right). Again, we fit exponents of the form ğ‘ğ‘œğ‘ğ‘¡ âˆ ğ¶^ğ‘ and ğ·ğ‘œğ‘ğ‘¡ âˆ ğ¶^ğ‘.  ğ‘ &#x3D; 0.49 and ğ‘ &#x3D; 0.51â€”as summarized in Table 2.</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/7252598/211255227-afe2390b-1748-4008-9f02-865da593e02f.png" alt="image"></p>
<h2 id="3-3-Approach-3-Fitting-a-parametric-loss-function"><a href="#3-3-Approach-3-Fitting-a-parametric-loss-function" class="headerlink" title="3.3. Approach 3: Fitting a parametric loss function"></a>3.3. Approach 3: Fitting a parametric loss function</h2><ul>
<li>model all final losses from experiments in Approach 1 &amp; 2 as a parametric function of model parameter count and the number of seen tokens<br><img src="https://user-images.githubusercontent.com/7252598/211256057-9aa5e6db-f848-4d6c-81ea-96d2f6168b84.png" alt="image"><br><img src="https://user-images.githubusercontent.com/7252598/211256619-a737684d-46c7-4558-a0f3-df3bd9c8dd44.png" alt="image"></li>
</ul>
<h2 id="3-4-Optimal-model-scaling"><a href="#3-4-Optimal-model-scaling" class="headerlink" title="3.4. Optimal model scaling"></a>3.4. Optimal model scaling</h2><ul>
<li><p>ê¸°ì¡´ ë…¼ë¬¸(Kaplan et al.(2020) ê³¼ëŠ” ë‹¬ë¦¬ íŒŒë¼ë¯¸í„°ì™€ ë°ì´í„°ê°€ ê±°ì˜ equalí•œ ìŠ¤ì¼€ì¼ë§ì„ ë³´ì„<br><img src="https://user-images.githubusercontent.com/7252598/211256954-9200a06b-3871-4d4e-b355-54a93b5ae493.png" alt="image"></p>
</li>
<li><p>ì‚¬ì‹¤ ì´ ë…¼ë¬¸ì—ì„œëŠ” ì•„ë˜í‘œê°€ ì œì¼ ì¤‘ìš”í–ˆë‹¤<br><img src="https://user-images.githubusercontent.com/7252598/211256780-6734b4cc-6bd1-487f-a936-8a6916ecc7ee.png" alt="image"></p>
</li>
</ul>
<h1 id="4-Chinchilla"><a href="#4-Chinchilla" class="headerlink" title="4. Chinchilla"></a>4. Chinchilla</h1><h2 id="4-1-Model-and-training-details"><a href="#4-1-Model-and-training-details" class="headerlink" title="4.1. Model and training details"></a>4.1. Model and training details</h2><ul>
<li>train Chinchilla on MassiveText (the same dataset as Gopher) but use a slightly different subset distribution (shown in Table A1) to account for the increased number of training tokens</li>
<li>AdamW (Loshchilov and Hutter, 2019) for Chinchilla</li>
<li>train Chinchilla with a slightly modified SentencePiece (Kudo and Richardson, 2018)<br>tokenizer that <code>does not apply NFKC normalisation</code> (ì´ê±° ì™œ ì•ˆí–ˆì§€?)<ul>
<li>find that this particularly helps with the representation of <code>mathematics and chemistry</code> (MMLU ê°™ì€ ê³³ì—ëŠ” ë„ì›€ë ìˆ˜ë„?!)</li>
<li>vocabulary is very similarâ€“ 94.15% of tokens are the same as those used for training Gopher</li>
</ul>
</li>
<li>forward and backward pass are <code>computed in bfloat16</code>, we <code>store a float32</code> copy of the weights<br><img src="https://user-images.githubusercontent.com/7252598/211257449-b9d0edf1-2cff-4612-8a90-23b9e0792056.png" alt="image"></li>
</ul>
<h2 id="4-2-Results"><a href="#4-2-Results" class="headerlink" title="4.2. Results"></a>4.2. Results</h2><p><img src="https://user-images.githubusercontent.com/7252598/211257516-02468291-528d-4444-a4ff-92b817c18e25.png" alt="image"></p>
<h3 id="4-2-1-Lanugage-modeling"><a href="#4-2-1-Lanugage-modeling" class="headerlink" title="4.2.1. Lanugage modeling"></a>4.2.1. Lanugage modeling</h3><ul>
<li>bits-per-byte(bpb)ê°€ ë­ì§€<br><img src="https://user-images.githubusercontent.com/7252598/211257691-72b9ec61-9e26-4ca7-9b97-8515441fb48d.png" alt="image"></li>
</ul>
<h3 id="4-2-2-MMLU"><a href="#4-2-2-MMLU" class="headerlink" title="4.2.2. MMLU"></a>4.2.2. MMLU</h3><ul>
<li>ì´í•˜ ìƒëµ</li>
</ul>
<h1 id="Discussion-amp-Conclusion"><a href="#Discussion-amp-Conclusion" class="headerlink" title="Discussion &amp; Conclusion"></a>Discussion &amp; Conclusion</h1><ul>
<li>The trend so far in large language model training has been to increase the model size, often without increasing the number of training tokens<ul>
<li>ëª¨ë¸í¬ê¸°ë§Œ í‚¤ìš°ê³  í† í°ì€ ì•ˆí‚¤ì› ë˜ íŠ¸ë Œë“œê°€ ìˆì—ˆìŒ, ê·¼ë° ì˜ëª»ë¨</li>
</ul>
</li>
<li>propose three predictive approaches towards optimally setting model size and training dura- tion, based on the outcome of over 400 training runs<ul>
<li>ì‹¤í—˜ ë§ì´í•¨</li>
</ul>
</li>
<li>Though there has been significant recent work allowing larger and larger models to be trained, our analysis suggests an increased focus on dataset scaling is needed<ul>
<li>ë°ì´í„° ìŠ¤ì¼€ì¼ë§ë„ í•„ìš”í•˜ë‹¤ê³ ! (ë¬¼ë¡  í€„ë¦¬í‹°ê°€ ë’·ë°›ì¹¨ë˜ì•¼í•¨)</li>
</ul>
</li>
<li>Larger datasets will require extra care to ensure train-test set overlap is properly accounted for, both in the language modelling loss but also with downstream tasks<ul>
<li>LM lossì™€ downstream task ë‹¤ ì˜ë˜ê²Œ í•˜ë ¤ë©´ ë°ì´í„° ì–‘ ì‹ ê²½ì“°ì</li>
</ul>
</li>
<li>Chinchilla does suffer from bias and toxicity but interestingly it seems less affected than Gopher<ul>
<li>ì¹œì¹ ë¼ë„ biasì™€ toxicity ë¬¸ì œê°€ ìˆì—ˆì§€ë§Œ ê³ í¼ë³´ë‹¤ ëœí–ˆë‹¤.</li>
</ul>
</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/7252598/211258708-2bca2577-eb55-4f56-bd6d-1435e2ebd9ea.png" alt="image"></p>
<h1 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h1><h2 id="í•™ìŠµì…‹"><a href="#í•™ìŠµì…‹" class="headerlink" title="í•™ìŠµì…‹"></a>í•™ìŠµì…‹</h2><p><img src="https://user-images.githubusercontent.com/7252598/211258824-c70d15df-b81a-4f57-8b9b-c129c27874c8.png" alt="image"></p>
<h2 id="D-3-Predicted-compute-optimal-frontier-for-all-three-methods"><a href="#D-3-Predicted-compute-optimal-frontier-for-all-three-methods" class="headerlink" title="D.3. Predicted compute optimal frontier for all three methods"></a>D.3. Predicted compute optimal frontier for all three methods</h2><p><img src="https://user-images.githubusercontent.com/7252598/211259037-c9da3e07-9c1c-4e9d-99a8-8e23f36866c9.png" alt="image"></p>
</div><div class="article-licensing box"><div class="licensing-title"><p>(Chinchilla) Training Compute-Optimal Large Language Models</p><p><a href="https://eagle705.github.io/Chinchilla-Training-Compute-Optimal-Large-Language-Models/">https://eagle705.github.io/Chinchilla-Training-Compute-Optimal-Large-Language-Models/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Joosung Yoon</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2023-01-09</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2023-01-09</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/nlp/">nlp</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=63297c6228f9450019a5f574&amp;product=sop" defer></script></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/InstructGPT/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">(InstructGPT) Training language models to follow instructions with human feedback</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/Robust-Conversational-Agents-against-Imperceptible-Toxicity-Triggers/"><span class="level-item">Robust Conversational Agents against Imperceptible Toxicity Triggers</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">ëŒ“ê¸€</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://eagle705.github.io/Chinchilla-Training-Compute-Optimal-Large-Language-Models/';
            this.page.identifier = 'Chinchilla-Training-Compute-Optimal-Large-Language-Models/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'eagle705-github-io' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/eagle705-logo.png" alt="Joosung Yoon"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Joosung Yoon</p><p class="is-size-6 is-block">Machine Learning Engineer</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>There and Back Again</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">í¬ìŠ¤íŠ¸</p><a href="/archives"><p class="title">51</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">ì¹´í…Œê³ ë¦¬</p><a href="/categories"><p class="title">4</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">íƒœê·¸</p><a href="/tags"><p class="title">10</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/eagle705" target="_blank" rel="noopener">íŒ”ë¡œìš°</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/eagle705"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com/hisdevelopers"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/JSYoon53859120"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="LinkedIn" href="https://www.linkedin.com/in/joosung-yoon/"><i class="fab fa-linkedin"></i></a></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">ì¹´í…Œê³ ë¦¬</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/cslog/"><span class="level-start"><span class="level-item">cslog</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/paper/"><span class="level-start"><span class="level-item">paper</span></span><span class="level-end"><span class="level-item tag">36</span></span></a></li><li><a class="level is-mobile" href="/categories/photo/"><span class="level-start"><span class="level-item">photo</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">ì•„ì¹´ì´ë¸Œ</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/03/"><span class="level-start"><span class="level-item">3ì›” 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">2ì›” 2023</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/01/"><span class="level-start"><span class="level-item">1ì›” 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">12ì›” 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/11/"><span class="level-start"><span class="level-item">11ì›” 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/10/"><span class="level-start"><span class="level-item">10ì›” 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/09/"><span class="level-start"><span class="level-item">9ì›” 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">8ì›” 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">7ì›” 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">6ì›” 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">5ì›” 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/01/"><span class="level-start"><span class="level-item">1ì›” 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/12/"><span class="level-start"><span class="level-item">12ì›” 2021</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/11/"><span class="level-start"><span class="level-item">11ì›” 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/10/"><span class="level-start"><span class="level-item">10ì›” 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/06/"><span class="level-start"><span class="level-item">6ì›” 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/05/"><span class="level-start"><span class="level-item">5ì›” 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/02/"><span class="level-start"><span class="level-item">2ì›” 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/12/"><span class="level-start"><span class="level-item">12ì›” 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/11/"><span class="level-start"><span class="level-item">11ì›” 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/10/"><span class="level-start"><span class="level-item">10ì›” 2019</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/09/"><span class="level-start"><span class="level-item">9ì›” 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/08/"><span class="level-start"><span class="level-item">8ì›” 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/07/"><span class="level-start"><span class="level-item">7ì›” 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/05/"><span class="level-start"><span class="level-item">5ì›” 2019</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/04/"><span class="level-start"><span class="level-item">4ì›” 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/11/"><span class="level-start"><span class="level-item">11ì›” 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/06/"><span class="level-start"><span class="level-item">6ì›” 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/05/"><span class="level-start"><span class="level-item">5ì›” 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/04/"><span class="level-start"><span class="level-item">4ì›” 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">íƒœê·¸</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/ML/"><span class="tag">ML</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/docker/"><span class="tag">docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/drone/"><span class="tag">drone</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/grpc/"><span class="tag">grpc</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/linux/"><span class="tag">linux</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/nlp/"><span class="tag">nlp</span><span class="tag">40</span></a></div><div class="control"><a class="tags has-addons" href="/tags/nlp-kb/"><span class="tag">nlp, kb</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/search/"><span class="tag">search</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/web/"><span class="tag">web</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%83%9D%EA%B0%81%EC%A0%95%EB%A6%AC/"><span class="tag">ìƒê°ì •ë¦¬</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="adsense"><div class="card-content"><div class="menu"><h3 class="menu-label">ê´‘ê³ </h3><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-2655870716902046" data-ad-slot="2764253071" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">ì¹´íƒˆë¡œê·¸</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Note"><span class="level-left"><span class="level-item">1</span><span class="level-item">Note</span></span></a></li><li><a class="level is-mobile" href="#Author"><span class="level-left"><span class="level-item">2</span><span class="level-item">Author</span></span></a></li><li><a class="level is-mobile" href="#Abstract"><span class="level-left"><span class="level-item">3</span><span class="level-item">Abstract</span></span></a></li><li><a class="level is-mobile" href="#Introduction"><span class="level-left"><span class="level-item">4</span><span class="level-item">Introduction</span></span></a></li><li><a class="level is-mobile" href="#Estimating-the-optimal-parameter-x2F-training-tokens-allocation"><span class="level-left"><span class="level-item">5</span><span class="level-item">Estimating the optimal parameter/training tokens allocation</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#3-1-Approach-1-Fix-model-sizes-and-vary-number-of-training-tokens"><span class="level-left"><span class="level-item">5.1</span><span class="level-item">3.1. Approach 1: Fix model sizes and vary number of training tokens</span></span></a></li><li><a class="level is-mobile" href="#3-2-Approach-2-IsoFLOP-profiles"><span class="level-left"><span class="level-item">5.2</span><span class="level-item">3.2. Approach 2: IsoFLOP profiles</span></span></a></li><li><a class="level is-mobile" href="#3-3-Approach-3-Fitting-a-parametric-loss-function"><span class="level-left"><span class="level-item">5.3</span><span class="level-item">3.3. Approach 3: Fitting a parametric loss function</span></span></a></li><li><a class="level is-mobile" href="#3-4-Optimal-model-scaling"><span class="level-left"><span class="level-item">5.4</span><span class="level-item">3.4. Optimal model scaling</span></span></a></li></ul></li><li><a class="level is-mobile" href="#4-Chinchilla"><span class="level-left"><span class="level-item">6</span><span class="level-item">4. Chinchilla</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#4-1-Model-and-training-details"><span class="level-left"><span class="level-item">6.1</span><span class="level-item">4.1. Model and training details</span></span></a></li><li><a class="level is-mobile" href="#4-2-Results"><span class="level-left"><span class="level-item">6.2</span><span class="level-item">4.2. Results</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#4-2-1-Lanugage-modeling"><span class="level-left"><span class="level-item">6.2.1</span><span class="level-item">4.2.1. Lanugage modeling</span></span></a></li><li><a class="level is-mobile" href="#4-2-2-MMLU"><span class="level-left"><span class="level-item">6.2.2</span><span class="level-item">4.2.2. MMLU</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#Discussion-amp-Conclusion"><span class="level-left"><span class="level-item">7</span><span class="level-item">Discussion &amp; Conclusion</span></span></a></li><li><a class="level is-mobile" href="#Appendix"><span class="level-left"><span class="level-item">8</span><span class="level-item">Appendix</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#í•™ìŠµì…‹"><span class="level-left"><span class="level-item">8.1</span><span class="level-item">í•™ìŠµì…‹</span></span></a></li><li><a class="level is-mobile" href="#D-3-Predicted-compute-optimal-frontier-for-all-three-methods"><span class="level-left"><span class="level-item">8.2</span><span class="level-item">D.3. Predicted compute optimal frontier for all three methods</span></span></a></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">ìµœê·¼ ê¸€</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-03-23T08:14:37.000Z">2023-03-23</time></p><p class="title"><a href="/Alpaca/">Alpaca (A Strong Instruction-Following Model)</a></p><p class="categories"><a href="/categories/paper/">paper</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-02-20T13:07:50.000Z">2023-02-20</time></p><p class="title"><a href="/SentencePiece%EB%A5%BC%20%ED%99%9C%EC%9A%A9%ED%95%9C%20%ED%9A%A8%EA%B3%BC%EC%A0%81%EC%9D%B8%20%ED%95%9C%EA%B5%AD%EC%96%B4%20%ED%86%A0%ED%81%AC%EB%82%98%EC%9D%B4%EC%A0%80%20%EB%A7%8C%EB%93%A4%EA%B8%B0/">SentencePieceë¥¼ í™œìš©í•œ íš¨ê³¼ì ì¸ í•œêµ­ì–´ í† í¬ë‚˜ì´ì € ë§Œë“¤ê¸°</a></p><p class="categories"><a href="/categories/ML/">ML</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-02-16T08:24:12.000Z">2023-02-16</time></p><p class="title"><a href="/Toolformer/">Toolformer: Language Models Can Teach Themselves to Use Tools</a></p><p class="categories"><a href="/categories/paper/">paper</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-02-13T04:18:48.000Z">2023-02-13</time></p><p class="title"><a href="/SELF-INSTRUCT%20Aligning%20Language%20Model%20with%20Self%20Generated%20Instructions/">SELF-INSTRUCT Aligning Language Model with Self Generated Instructions</a></p><p class="categories"><a href="/categories/paper/">paper</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-02-06T04:15:12.000Z">2023-02-06</time></p><p class="title"><a href="/(FLAN)%20Finetuned%20Language%20Models%20Are%20Zero-Shot%20Learners/">(FLAN) Finetuned Language Models Are Zero-Shot Learners</a></p><p class="categories"><a href="/categories/paper/">paper</a></p></div></article></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/eagle705-logo.png" alt="Luke&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2023 Joosung Yoon</span>Â Â Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>Â &amp;Â <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("ko");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="ë§¨ ìœ„ë¡œ" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "ì´ ì›¹ ì‚¬ì´íŠ¸ëŠ” ê·€í•˜ì˜ ê²½í—˜ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ Cookieë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.",
          dismiss: "ë¬´ì‹œ",
          allow: "í—ˆìš©",
          deny: "ê±°ë¶€",
          link: "ë” ì•Œì•„ë³´ê¸°",
          policy: "Cookie ì •ì±…",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="ì…ë ¥ í•˜ì„¸ìš”..."></div><a class="searchbox-close" href="javascript:;">Ã—</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"ì…ë ¥ í•˜ì„¸ìš”...","untitled":"(ì œëª© ì—†ìŒ)","posts":"í¬ìŠ¤íŠ¸","pages":"í˜ì´ì§€","categories":"ì¹´í…Œê³ ë¦¬","tags":"íƒœê·¸"});
        });</script></body></html>